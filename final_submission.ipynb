{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7588622",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97347f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4965366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Govind S\\Downloads\\ds\\kaggle\\knowledge\\titanic\\spaceship-titanic\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f6477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['total_expense']=data.RoomService+data.FoodCourt+data.ShoppingMall+data.Spa+data.VRDeck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f450002",
   "metadata": {},
   "source": [
    "### Cleaning the data, Since There are a lt of categories for cabin column, only taking the first letter, which seems to represent a section of cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5cc23b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>False</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  CryoSleep Cabin    Destination   Age    VIP  RoomService  \\\n",
       "0        Europa      False     B    TRAPPIST-1e  39.0  False          0.0   \n",
       "1         Earth      False     F    TRAPPIST-1e  24.0  False        109.0   \n",
       "2        Europa      False     A    TRAPPIST-1e  58.0   True         43.0   \n",
       "3        Europa      False     A    TRAPPIST-1e  33.0  False          0.0   \n",
       "4         Earth      False     F    TRAPPIST-1e  16.0  False        303.0   \n",
       "...         ...        ...   ...            ...   ...    ...          ...   \n",
       "8688     Europa      False     A    55 Cancri e  41.0   True          0.0   \n",
       "8689      Earth       True     G  PSO J318.5-22  18.0  False          0.0   \n",
       "8690      Earth      False     G    TRAPPIST-1e  26.0  False          0.0   \n",
       "8691     Europa      False     E    55 Cancri e  32.0  False          0.0   \n",
       "8692     Europa      False     E    TRAPPIST-1e  44.0  False        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0        False       P  \n",
       "1           9.0          25.0   549.0    44.0         True       S  \n",
       "2        3576.0           0.0  6715.0    49.0        False       S  \n",
       "3        1283.0         371.0  3329.0   193.0        False       S  \n",
       "4          70.0         151.0   565.0     2.0         True       S  \n",
       "...         ...           ...     ...     ...          ...     ...  \n",
       "8688     6819.0           0.0  1643.0    74.0        False       P  \n",
       "8689        0.0           0.0     0.0     0.0        False       S  \n",
       "8690        0.0        1872.0     1.0     0.0         True       S  \n",
       "8691     1049.0           0.0   353.0  3235.0        False       S  \n",
       "8692     4688.0           0.0     0.0    12.0         True       S  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['PassengerId'],axis=1,inplace=True)\n",
    "data.drop(['Name'],axis=1,inplace=True)\n",
    "data_1=data.copy()\n",
    "data_1['Cabin_s']=data_1.Cabin.str[-1]\n",
    "data_1.Cabin=data_1.Cabin.str[0]\n",
    "categorical_columns=['HomePlanet', 'CryoSleep', 'Cabin', 'Destination','VIP','Cabin_s']\n",
    "for i in categorical_columns:\n",
    "    data_1[i].fillna(data_1[i].mode()[0],inplace=True)\n",
    "\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6079a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    8693 non-null   object \n",
      " 1   CryoSleep     8693 non-null   bool   \n",
      " 2   Cabin         8693 non-null   object \n",
      " 3   Destination   8693 non-null   object \n",
      " 4   Age           8514 non-null   float64\n",
      " 5   VIP           8693 non-null   bool   \n",
      " 6   RoomService   8512 non-null   float64\n",
      " 7   FoodCourt     8510 non-null   float64\n",
      " 8   ShoppingMall  8485 non-null   float64\n",
      " 9   Spa           8510 non-null   float64\n",
      " 10  VRDeck        8505 non-null   float64\n",
      " 11  Transported   8693 non-null   bool   \n",
      " 12  Cabin_s       8693 non-null   object \n",
      "dtypes: bool(3), float64(6), object(4)\n",
      "memory usage: 704.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29aca407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.82793046746535"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152d9919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    8693 non-null   object \n",
      " 1   CryoSleep     8693 non-null   bool   \n",
      " 2   Cabin         8693 non-null   object \n",
      " 3   Destination   8693 non-null   object \n",
      " 4   Age           8693 non-null   float64\n",
      " 5   VIP           8693 non-null   bool   \n",
      " 6   RoomService   8693 non-null   float64\n",
      " 7   FoodCourt     8693 non-null   float64\n",
      " 8   ShoppingMall  8693 non-null   float64\n",
      " 9   Spa           8693 non-null   float64\n",
      " 10  VRDeck        8693 non-null   float64\n",
      " 11  Transported   8693 non-null   bool   \n",
      " 12  Cabin_s       8693 non-null   object \n",
      "dtypes: bool(3), float64(6), object(4)\n",
      "memory usage: 704.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1['Age'].fillna(data_1['Age'].mean(),inplace=True)\n",
    "cont_columns=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for i in cont_columns:\n",
    "    data_1[i].fillna(data_1[i].median(),inplace=True)\n",
    "\n",
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a09b38d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  CryoSleep Cabin    Destination   Age  VIP  RoomService  \\\n",
       "0        Europa      False     B    TRAPPIST-1e  39.0    0          0.0   \n",
       "1         Earth      False     F    TRAPPIST-1e  24.0    0        109.0   \n",
       "2        Europa      False     A    TRAPPIST-1e  58.0    1         43.0   \n",
       "3        Europa      False     A    TRAPPIST-1e  33.0    0          0.0   \n",
       "4         Earth      False     F    TRAPPIST-1e  16.0    0        303.0   \n",
       "...         ...        ...   ...            ...   ...  ...          ...   \n",
       "8688     Europa      False     A    55 Cancri e  41.0    1          0.0   \n",
       "8689      Earth       True     G  PSO J318.5-22  18.0    0          0.0   \n",
       "8690      Earth      False     G    TRAPPIST-1e  26.0    0          0.0   \n",
       "8691     Europa      False     E    55 Cancri e  32.0    0          0.0   \n",
       "8692     Europa      False     E    TRAPPIST-1e  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0            0       P  \n",
       "1           9.0          25.0   549.0    44.0            1       S  \n",
       "2        3576.0           0.0  6715.0    49.0            0       S  \n",
       "3        1283.0         371.0  3329.0   193.0            0       S  \n",
       "4          70.0         151.0   565.0     2.0            1       S  \n",
       "...         ...           ...     ...     ...          ...     ...  \n",
       "8688     6819.0           0.0  1643.0    74.0            0       P  \n",
       "8689        0.0           0.0     0.0     0.0            0       S  \n",
       "8690        0.0        1872.0     1.0     0.0            1       S  \n",
       "8691     1049.0           0.0   353.0  3235.0            0       S  \n",
       "8692     4688.0           0.0     0.0    12.0            1       S  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.VIP=data_1.VIP.astype('int')\n",
    "data_1.Transported=data_1.Transported.astype('int')\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b15d3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VIP'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns.pop(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "868edaa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Cabin_s']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9866190",
   "metadata": {},
   "source": [
    "### Using labelencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "542c35a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              1          0      1            2  39.0    0          0.0   \n",
       "1              0          0      5            2  24.0    0        109.0   \n",
       "2              1          0      0            2  58.0    1         43.0   \n",
       "3              1          0      0            2  33.0    0          0.0   \n",
       "4              0          0      5            2  16.0    0        303.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "8688           1          0      0            0  41.0    1          0.0   \n",
       "8689           0          1      6            1  18.0    0          0.0   \n",
       "8690           0          0      6            2  26.0    0          0.0   \n",
       "8691           1          0      4            0  32.0    0          0.0   \n",
       "8692           1          0      4            2  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported  Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0            0        0  \n",
       "1           9.0          25.0   549.0    44.0            1        1  \n",
       "2        3576.0           0.0  6715.0    49.0            0        1  \n",
       "3        1283.0         371.0  3329.0   193.0            0        1  \n",
       "4          70.0         151.0   565.0     2.0            1        1  \n",
       "...         ...           ...     ...     ...          ...      ...  \n",
       "8688     6819.0           0.0  1643.0    74.0            0        0  \n",
       "8689        0.0           0.0     0.0     0.0            0        1  \n",
       "8690        0.0        1872.0     1.0     0.0            1        1  \n",
       "8691     1049.0           0.0   353.0  3235.0            0        1  \n",
       "8692     4688.0           0.0     0.0    12.0            1        1  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for i in categorical_columns:\n",
    "    le=LabelEncoder()\n",
    "    data_1[i]=le.fit_transform(data_1[i])\n",
    "\n",
    "data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bdb13c",
   "metadata": {},
   "source": [
    "### Saving the cleaned dataframe for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92528890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleaned_dataframe.sav']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'cleaned_dataframe.sav'\n",
    "joblib.dump(data_1,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63baacf",
   "metadata": {},
   "source": [
    "### Using randome forest for model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f37eaf",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5843cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn import preprocessing\n",
    "df=data.copy()\n",
    "x=data_1.drop(['Transported'],axis=1)\n",
    "ss=preprocessing.StandardScaler()\n",
    "x=ss.fit_transform(x)\n",
    "y=data_1.iloc[:,-2]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2,random_state=0)\n",
    "kfold=KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3875e7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 8, 'max_features': 5, 'n_estimators': 70}, 0.8025649135863724)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid=[{'n_estimators':range(64,125),'max_depth':[2,3,4,5,6,7,8,9,10,11,12],'max_features':[3,4,5,6]}]\n",
    "rf = RandomForestClassifier(criterion='gini',random_state=23)\n",
    "gsrf = GridSearchCV(rf,param_grid,n_jobs=-1,cv=kfold)\n",
    "gsrf.fit(x_train,y_train)\n",
    "gsrf.best_params_ , gsrf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7249b",
   "metadata": {},
   "source": [
    "### Building a model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee9c6705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79700977573318\n",
      "0.8310502283105022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       863\n",
      "           1       0.78      0.83      0.80       876\n",
      "\n",
      "    accuracy                           0.80      1739\n",
      "   macro avg       0.80      0.80      0.80      1739\n",
      "weighted avg       0.80      0.80      0.80      1739\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[658 205]\n",
      " [148 728]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "model_rf = RandomForestClassifier(n_estimators=70,max_depth=8,max_features=5,criterion='gini',random_state=23)\n",
    "model_rf.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,model_rf.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,model_rf.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,model_rf.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,model_rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce555e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44038529, -0.73277002, -1.31837333, ..., -0.28357863,\n",
       "        13.26827196,  2.20511752],\n",
       "       [-0.81725903, -0.73277002,  0.38547017, ..., -0.28190632,\n",
       "         0.34776712, -0.26300329],\n",
       "       [ 1.6980296 , -0.73277002,  0.38547017, ..., -0.20497974,\n",
       "        -0.24485953, -0.26300329],\n",
       "       ...,\n",
       "       [ 1.6980296 , -0.73277002, -0.18247766, ..., -0.24845998,\n",
       "        -0.26707192,  0.45212568],\n",
       "       [-0.81725903, -0.73277002,  0.95341801, ..., -0.28357863,\n",
       "        -0.2706259 , -0.26300329],\n",
       "       [-0.81725903, -0.73277002,  0.95341801, ..., -0.28357863,\n",
       "         0.49081493, -0.2488947 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72290890",
   "metadata": {},
   "source": [
    "### lgbm hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab7fcb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Govind S\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1487: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.07, 'max_depth': 5}, 0.8008397419995038)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "param_grid=[{'max_depth':[2,3,4,5,6,7,8,9,10,11,12],'learning_rate':[0.01,0.03,0.05,0.07,0.09,0.10,0.20]}]\n",
    "model_lgb = lgb.LGBMClassifier(learning_rate=0.09,random_state=42,categorical_feature=[0,1,2,3,5,11])\n",
    "gslgb = GridSearchCV(model_lgb,param_grid,n_jobs=-1,cv=kfold)\n",
    "gslgb.fit(x_train,y_train)\n",
    "gslgb.best_params_ , gslgb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02438b",
   "metadata": {},
   "source": [
    "### Building a model with lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "396e70f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7906843013225991\n",
      "0.839041095890411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       863\n",
      "           1       0.77      0.84      0.80       876\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.79      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[640 223]\n",
      " [141 735]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Govind S\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Govind S\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "model_lgb = lgb.LGBMClassifier(learning_rate=0.07,random_state=42,max_depth=5)\n",
    "model_lgb.fit(x_train,y_train,categorical_feature=[0,1,2,3,5,11],verbose=20)\n",
    "print(metrics.accuracy_score(y_test,model_lgb.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,model_lgb.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,model_lgb.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,model_lgb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4efcb08",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c351d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 13, 'gamma': 0.01, 'kernel': 'rbf'}, 0.7969529893326718)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "param_grid = [{'kernel':['rbf'],'gamma':[100,50,0.5,0.1,0.01,0.001,0.0001],\n",
    "               'C':[15,14,13,12,11,10,0.1,0.001,0.0001]}]\n",
    "gsv = GridSearchCV(svm,param_grid,n_jobs=-1,cv=kfold)\n",
    "gsv.fit(x_train,y_train)\n",
    "gsv.best_params_ , gsv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb617d",
   "metadata": {},
   "source": [
    "### Building a model with the best arameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4811541c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7786083956296722\n",
      "0.7968036529680366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77       863\n",
      "           1       0.77      0.80      0.78       876\n",
      "\n",
      "    accuracy                           0.78      1739\n",
      "   macro avg       0.78      0.78      0.78      1739\n",
      "weighted avg       0.78      0.78      0.78      1739\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[656 207]\n",
      " [178 698]]\n"
     ]
    }
   ],
   "source": [
    "model_svm = SVC(kernel='rbf',gamma=0.1,C=15)\n",
    "model_svm.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,model_svm.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,model_svm.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,model_svm.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,model_svm.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5880d3",
   "metadata": {},
   "source": [
    "### For logistic regression categorical variables to be encoded using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ef58986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet CryoSleep     Cabin    Destination   Age    VIP  RoomService  \\\n",
       "0        Europa     False     B/0/P    TRAPPIST-1e  39.0  False          0.0   \n",
       "1         Earth     False     F/0/S    TRAPPIST-1e  24.0  False        109.0   \n",
       "2        Europa     False     A/0/S    TRAPPIST-1e  58.0   True         43.0   \n",
       "3        Europa     False     A/0/S    TRAPPIST-1e  33.0  False          0.0   \n",
       "4         Earth     False     F/1/S    TRAPPIST-1e  16.0  False        303.0   \n",
       "...         ...       ...       ...            ...   ...    ...          ...   \n",
       "8688     Europa     False    A/98/P    55 Cancri e  41.0   True          0.0   \n",
       "8689      Earth      True  G/1499/S  PSO J318.5-22  18.0  False          0.0   \n",
       "8690      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False          0.0   \n",
       "8691     Europa     False   E/608/S    55 Cancri e  32.0  False          0.0   \n",
       "8692     Europa     False   E/608/S    TRAPPIST-1e  44.0  False        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported  \n",
       "0           0.0           0.0     0.0     0.0        False  \n",
       "1           9.0          25.0   549.0    44.0         True  \n",
       "2        3576.0           0.0  6715.0    49.0        False  \n",
       "3        1283.0         371.0  3329.0   193.0        False  \n",
       "4          70.0         151.0   565.0     2.0         True  \n",
       "...         ...           ...     ...     ...          ...  \n",
       "8688     6819.0           0.0  1643.0    74.0        False  \n",
       "8689        0.0           0.0     0.0     0.0        False  \n",
       "8690        0.0        1872.0     1.0     0.0         True  \n",
       "8691     1049.0           0.0   353.0  3235.0        False  \n",
       "8692     4688.0           0.0     0.0    12.0         True  \n",
       "\n",
       "[8693 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25af1287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet CryoSleep     Cabin    Destination   Age    VIP  RoomService  \\\n",
       "0        Europa     False     B/0/P    TRAPPIST-1e  39.0  False          0.0   \n",
       "1         Earth     False     F/0/S    TRAPPIST-1e  24.0  False        109.0   \n",
       "2        Europa     False     A/0/S    TRAPPIST-1e  58.0   True         43.0   \n",
       "3        Europa     False     A/0/S    TRAPPIST-1e  33.0  False          0.0   \n",
       "4         Earth     False     F/1/S    TRAPPIST-1e  16.0  False        303.0   \n",
       "...         ...       ...       ...            ...   ...    ...          ...   \n",
       "8688     Europa     False    A/98/P    55 Cancri e  41.0   True          0.0   \n",
       "8689      Earth      True  G/1499/S  PSO J318.5-22  18.0  False          0.0   \n",
       "8690      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False          0.0   \n",
       "8691     Europa     False   E/608/S    55 Cancri e  32.0  False          0.0   \n",
       "8692     Europa     False   E/608/S    TRAPPIST-1e  44.0  False        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported  \n",
       "0           0.0           0.0     0.0     0.0        False  \n",
       "1           9.0          25.0   549.0    44.0         True  \n",
       "2        3576.0           0.0  6715.0    49.0        False  \n",
       "3        1283.0         371.0  3329.0   193.0        False  \n",
       "4          70.0         151.0   565.0     2.0         True  \n",
       "...         ...           ...     ...     ...          ...  \n",
       "8688     6819.0           0.0  1643.0    74.0        False  \n",
       "8689        0.0           0.0     0.0     0.0        False  \n",
       "8690        0.0        1872.0     1.0     0.0         True  \n",
       "8691     1049.0           0.0   353.0  3235.0        False  \n",
       "8692     4688.0           0.0     0.0    12.0         True  \n",
       "\n",
       "[8693 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9266b0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              1          0      1            2  39.0    0          0.0   \n",
       "1              0          0      5            2  24.0    0        109.0   \n",
       "2              1          0      0            2  58.0    1         43.0   \n",
       "3              1          0      0            2  33.0    0          0.0   \n",
       "4              0          0      5            2  16.0    0        303.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "8688           1          0      0            0  41.0    1          0.0   \n",
       "8689           0          1      6            1  18.0    0          0.0   \n",
       "8690           0          0      6            2  26.0    0          0.0   \n",
       "8691           1          0      4            0  32.0    0          0.0   \n",
       "8692           1          0      4            2  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported  Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0            0        0  \n",
       "1           9.0          25.0   549.0    44.0            1        1  \n",
       "2        3576.0           0.0  6715.0    49.0            0        1  \n",
       "3        1283.0         371.0  3329.0   193.0            0        1  \n",
       "4          70.0         151.0   565.0     2.0            1        1  \n",
       "...         ...           ...     ...     ...          ...      ...  \n",
       "8688     6819.0           0.0  1643.0    74.0            0        0  \n",
       "8689        0.0           0.0     0.0     0.0            0        1  \n",
       "8690        0.0        1872.0     1.0     0.0            1        1  \n",
       "8691     1049.0           0.0   353.0  3235.0            0        1  \n",
       "8692     4688.0           0.0     0.0    12.0            1        1  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f570f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2=data_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac1175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5656\n",
       "1    3037\n",
       "Name: CryoSleep, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.CryoSleep.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee195ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2=pd.get_dummies(data_2,columns=['HomePlanet','Cabin','Destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1699834d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_1</th>\n",
       "      <th>Cabin_2</th>\n",
       "      <th>Cabin_3</th>\n",
       "      <th>Cabin_4</th>\n",
       "      <th>Cabin_5</th>\n",
       "      <th>Cabin_6</th>\n",
       "      <th>Cabin_7</th>\n",
       "      <th>Destination_0</th>\n",
       "      <th>Destination_1</th>\n",
       "      <th>Destination_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall     Spa  \\\n",
       "0             0  39.0    0          0.0        0.0           0.0     0.0   \n",
       "1             0  24.0    0        109.0        9.0          25.0   549.0   \n",
       "2             0  58.0    1         43.0     3576.0           0.0  6715.0   \n",
       "3             0  33.0    0          0.0     1283.0         371.0  3329.0   \n",
       "4             0  16.0    0        303.0       70.0         151.0   565.0   \n",
       "...         ...   ...  ...          ...        ...           ...     ...   \n",
       "8688          0  41.0    1          0.0     6819.0           0.0  1643.0   \n",
       "8689          1  18.0    0          0.0        0.0           0.0     0.0   \n",
       "8690          0  26.0    0          0.0        0.0        1872.0     1.0   \n",
       "8691          0  32.0    0          0.0     1049.0           0.0   353.0   \n",
       "8692          0  44.0    0        126.0     4688.0           0.0     0.0   \n",
       "\n",
       "      VRDeck  Transported  Cabin_s  ...  Cabin_1  Cabin_2  Cabin_3  Cabin_4  \\\n",
       "0        0.0            0        0  ...        1        0        0        0   \n",
       "1       44.0            1        1  ...        0        0        0        0   \n",
       "2       49.0            0        1  ...        0        0        0        0   \n",
       "3      193.0            0        1  ...        0        0        0        0   \n",
       "4        2.0            1        1  ...        0        0        0        0   \n",
       "...      ...          ...      ...  ...      ...      ...      ...      ...   \n",
       "8688    74.0            0        0  ...        0        0        0        0   \n",
       "8689     0.0            0        1  ...        0        0        0        0   \n",
       "8690     0.0            1        1  ...        0        0        0        0   \n",
       "8691  3235.0            0        1  ...        0        0        0        1   \n",
       "8692    12.0            1        1  ...        0        0        0        1   \n",
       "\n",
       "      Cabin_5  Cabin_6  Cabin_7  Destination_0  Destination_1  Destination_2  \n",
       "0           0        0        0              0              0              1  \n",
       "1           1        0        0              0              0              1  \n",
       "2           0        0        0              0              0              1  \n",
       "3           0        0        0              0              0              1  \n",
       "4           1        0        0              0              0              1  \n",
       "...       ...      ...      ...            ...            ...            ...  \n",
       "8688        0        0        0              1              0              0  \n",
       "8689        0        1        0              0              1              0  \n",
       "8690        0        1        0              0              0              1  \n",
       "8691        0        0        0              1              0              0  \n",
       "8692        0        0        0              0              0              1  \n",
       "\n",
       "[8693 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41dc46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "\n",
    "x_1=data_2.drop(['Transported'],axis=1)\n",
    "ss=preprocessing.StandardScaler()\n",
    "x_1=ss.fit_transform(x_1)\n",
    "y_1=data_2.loc[:,'Transported']\n",
    "x_1train,x_1test,y_1train,y_1test=train_test_split(x_1,y_1, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6351f751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.73277002,  0.70943692, -0.15306307, ..., -0.51101319,\n",
       "        -0.31748665,  0.65252063],\n",
       "       [-0.73277002, -0.33671733, -0.15306307, ..., -0.51101319,\n",
       "        -0.31748665,  0.65252063],\n",
       "       [-0.73277002,  2.03456565,  6.53325471, ..., -0.51101319,\n",
       "        -0.31748665,  0.65252063],\n",
       "       ...,\n",
       "       [-0.73277002, -0.1972301 , -0.15306307, ..., -0.51101319,\n",
       "        -0.31748665,  0.65252063],\n",
       "       [-0.73277002,  0.2212316 , -0.15306307, ...,  1.95689664,\n",
       "        -0.31748665, -1.5325186 ],\n",
       "       [-0.73277002,  1.05815501, -0.15306307, ..., -0.51101319,\n",
       "        -0.31748665,  0.65252063]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ff02e",
   "metadata": {},
   "source": [
    "### Building model with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a32f3c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7866589994249569\n",
      "0.8184931506849316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78       863\n",
      "           1       0.77      0.82      0.79       876\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.79      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[651 212]\n",
      " [159 717]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(x_1train,y_1train)\n",
    "print(metrics.accuracy_score(y_1test,model_lr.predict(x_1test)))\n",
    "print(metrics.recall_score(y_1test,model_lr.predict(x_1test)))\n",
    "print(metrics.classification_report(y_1test,model_lr.predict(x_1test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_1test,model_lr.predict(x_1test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc995f",
   "metadata": {},
   "source": [
    "### Building a SVM model using the new training data(which uses one hot encoding which is more accurate then label encoded for SVM and logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d1a7063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}, 0.7995451914330605)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "kfold=KFold(n_splits=10)\n",
    "svm = SVC()\n",
    "param_grid = [{'kernel':['rbf'],'gamma':[100,50,0.5,0.1,0.01,0.001,0.0001],\n",
    "               'C':[15,14,13,12,11,10,0.1,0.001,0.0001]}]\n",
    "gsv = GridSearchCV(svm,param_grid,n_jobs=-1,cv=kfold)\n",
    "gsv.fit(x_1train,y_1train)\n",
    "gsv.best_params_ , gsv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa22532c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79700977573318\n",
      "0.8207762557077626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79       863\n",
      "           1       0.79      0.82      0.80       876\n",
      "\n",
      "    accuracy                           0.80      1739\n",
      "   macro avg       0.80      0.80      0.80      1739\n",
      "weighted avg       0.80      0.80      0.80      1739\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[667 196]\n",
      " [157 719]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_svm = SVC(kernel='rbf',gamma=0.01,C=10)\n",
    "model_svm.fit(x_1train,y_1train)\n",
    "print(metrics.accuracy_score(y_1test,model_svm.predict(x_1test)))\n",
    "print(metrics.recall_score(y_1test,model_svm.predict(x_1test)))\n",
    "print(metrics.classification_report(y_1test,model_svm.predict(x_1test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_1test,model_svm.predict(x_1test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095e8a5",
   "metadata": {},
   "source": [
    "### Fitting for the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d4e5141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.01)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm=SVC(kernel='rbf',gamma=0.01,C=10)\n",
    "svm.fit(x_1,y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b05aa",
   "metadata": {},
   "source": [
    "### Building a model with neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d72c1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33c0c583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6954, 23)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e083998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23*23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ef51683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "174/174 [==============================] - 2s 6ms/step - loss: 0.4582 - binary_accuracy: 0.7683 - val_loss: 0.4220 - val_binary_accuracy: 0.7951\n",
      "Epoch 2/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.4182 - binary_accuracy: 0.8012 - val_loss: 0.4169 - val_binary_accuracy: 0.7980\n",
      "Epoch 3/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.4057 - binary_accuracy: 0.8053 - val_loss: 0.4060 - val_binary_accuracy: 0.8081\n",
      "Epoch 4/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.4021 - binary_accuracy: 0.8062 - val_loss: 0.4067 - val_binary_accuracy: 0.7994\n",
      "Epoch 5/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3960 - binary_accuracy: 0.8080 - val_loss: 0.4074 - val_binary_accuracy: 0.8016\n",
      "Epoch 6/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3920 - binary_accuracy: 0.8114 - val_loss: 0.4020 - val_binary_accuracy: 0.8059\n",
      "Epoch 7/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3896 - binary_accuracy: 0.8154 - val_loss: 0.4155 - val_binary_accuracy: 0.8052\n",
      "Epoch 8/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3843 - binary_accuracy: 0.8172 - val_loss: 0.4210 - val_binary_accuracy: 0.7987\n",
      "Epoch 9/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3825 - binary_accuracy: 0.8143 - val_loss: 0.4178 - val_binary_accuracy: 0.7930\n",
      "Epoch 10/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3798 - binary_accuracy: 0.8163 - val_loss: 0.4177 - val_binary_accuracy: 0.7980\n",
      "Epoch 11/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3743 - binary_accuracy: 0.8165 - val_loss: 0.4274 - val_binary_accuracy: 0.8030\n",
      "Epoch 12/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3771 - binary_accuracy: 0.8152 - val_loss: 0.4126 - val_binary_accuracy: 0.8016\n",
      "Epoch 13/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3712 - binary_accuracy: 0.8181 - val_loss: 0.4244 - val_binary_accuracy: 0.7994\n",
      "Epoch 14/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3696 - binary_accuracy: 0.8201 - val_loss: 0.4339 - val_binary_accuracy: 0.7980\n",
      "Epoch 15/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3615 - binary_accuracy: 0.8184 - val_loss: 0.4445 - val_binary_accuracy: 0.8009\n",
      "Epoch 16/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3613 - binary_accuracy: 0.8242 - val_loss: 0.4534 - val_binary_accuracy: 0.7994\n",
      "Epoch 17/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3584 - binary_accuracy: 0.8206 - val_loss: 0.4580 - val_binary_accuracy: 0.7965\n",
      "Epoch 18/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3587 - binary_accuracy: 0.8253 - val_loss: 0.4528 - val_binary_accuracy: 0.8088\n",
      "Epoch 19/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3555 - binary_accuracy: 0.8301 - val_loss: 0.4546 - val_binary_accuracy: 0.8030\n",
      "Epoch 20/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3492 - binary_accuracy: 0.8283 - val_loss: 0.4654 - val_binary_accuracy: 0.8009\n",
      "Epoch 21/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3468 - binary_accuracy: 0.8294 - val_loss: 0.4650 - val_binary_accuracy: 0.7994\n",
      "Epoch 22/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3475 - binary_accuracy: 0.8278 - val_loss: 0.4612 - val_binary_accuracy: 0.7987\n",
      "Epoch 23/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3408 - binary_accuracy: 0.8294 - val_loss: 0.4931 - val_binary_accuracy: 0.8009\n",
      "Epoch 24/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3397 - binary_accuracy: 0.8314 - val_loss: 0.4978 - val_binary_accuracy: 0.8001\n",
      "Epoch 25/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3406 - binary_accuracy: 0.8341 - val_loss: 0.4802 - val_binary_accuracy: 0.7994\n",
      "Epoch 26/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3390 - binary_accuracy: 0.8353 - val_loss: 0.4907 - val_binary_accuracy: 0.7930\n",
      "Epoch 27/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3307 - binary_accuracy: 0.8370 - val_loss: 0.4960 - val_binary_accuracy: 0.7958\n",
      "Epoch 28/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3326 - binary_accuracy: 0.8334 - val_loss: 0.5008 - val_binary_accuracy: 0.7973\n",
      "Epoch 29/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3308 - binary_accuracy: 0.8361 - val_loss: 0.5393 - val_binary_accuracy: 0.7915\n",
      "Epoch 30/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3288 - binary_accuracy: 0.8350 - val_loss: 0.5204 - val_binary_accuracy: 0.7836\n",
      "Epoch 31/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3231 - binary_accuracy: 0.8400 - val_loss: 0.5201 - val_binary_accuracy: 0.7965\n",
      "Epoch 32/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3229 - binary_accuracy: 0.8348 - val_loss: 0.5217 - val_binary_accuracy: 0.7858\n",
      "Epoch 33/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3185 - binary_accuracy: 0.8406 - val_loss: 0.5673 - val_binary_accuracy: 0.7901\n",
      "Epoch 34/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3148 - binary_accuracy: 0.8413 - val_loss: 0.5688 - val_binary_accuracy: 0.7965\n",
      "Epoch 35/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3149 - binary_accuracy: 0.8434 - val_loss: 0.5605 - val_binary_accuracy: 0.7973\n",
      "Epoch 36/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3093 - binary_accuracy: 0.8433 - val_loss: 0.5773 - val_binary_accuracy: 0.7786\n",
      "Epoch 37/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3078 - binary_accuracy: 0.8431 - val_loss: 0.5778 - val_binary_accuracy: 0.7843\n",
      "Epoch 38/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3065 - binary_accuracy: 0.8427 - val_loss: 0.6578 - val_binary_accuracy: 0.7771\n",
      "Epoch 39/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3141 - binary_accuracy: 0.8458 - val_loss: 0.6013 - val_binary_accuracy: 0.7894\n",
      "Epoch 40/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3003 - binary_accuracy: 0.8497 - val_loss: 0.6192 - val_binary_accuracy: 0.7865\n",
      "Epoch 41/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2990 - binary_accuracy: 0.8486 - val_loss: 0.6461 - val_binary_accuracy: 0.7850\n",
      "Epoch 42/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2988 - binary_accuracy: 0.8522 - val_loss: 0.6499 - val_binary_accuracy: 0.7786\n",
      "Epoch 43/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2986 - binary_accuracy: 0.8503 - val_loss: 0.6675 - val_binary_accuracy: 0.7872\n",
      "Epoch 44/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2940 - binary_accuracy: 0.8528 - val_loss: 0.6828 - val_binary_accuracy: 0.7879\n",
      "Epoch 45/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2893 - binary_accuracy: 0.8551 - val_loss: 0.7675 - val_binary_accuracy: 0.7836\n",
      "Epoch 46/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2846 - binary_accuracy: 0.8578 - val_loss: 0.7592 - val_binary_accuracy: 0.7843\n",
      "Epoch 47/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2876 - binary_accuracy: 0.8522 - val_loss: 0.7403 - val_binary_accuracy: 0.7807\n",
      "Epoch 48/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3093 - binary_accuracy: 0.8499 - val_loss: 0.5994 - val_binary_accuracy: 0.7915\n",
      "Epoch 49/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2896 - binary_accuracy: 0.8553 - val_loss: 0.7077 - val_binary_accuracy: 0.7786\n",
      "Epoch 50/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2889 - binary_accuracy: 0.8546 - val_loss: 0.7152 - val_binary_accuracy: 0.7908\n",
      "Epoch 51/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2867 - binary_accuracy: 0.8605 - val_loss: 0.6698 - val_binary_accuracy: 0.7822\n",
      "Epoch 52/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2772 - binary_accuracy: 0.8610 - val_loss: 0.7692 - val_binary_accuracy: 0.7901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2735 - binary_accuracy: 0.8596 - val_loss: 0.7460 - val_binary_accuracy: 0.7815\n",
      "Epoch 54/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2711 - binary_accuracy: 0.8654 - val_loss: 0.8090 - val_binary_accuracy: 0.7807\n",
      "Epoch 55/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2692 - binary_accuracy: 0.8655 - val_loss: 0.8306 - val_binary_accuracy: 0.7793\n",
      "Epoch 56/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2748 - binary_accuracy: 0.8601 - val_loss: 0.8181 - val_binary_accuracy: 0.7779\n",
      "Epoch 57/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2673 - binary_accuracy: 0.8652 - val_loss: 0.8403 - val_binary_accuracy: 0.7786\n",
      "Epoch 58/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2680 - binary_accuracy: 0.8628 - val_loss: 0.8460 - val_binary_accuracy: 0.7886\n",
      "Epoch 59/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2825 - binary_accuracy: 0.8609 - val_loss: 0.7673 - val_binary_accuracy: 0.7807\n",
      "Epoch 60/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2739 - binary_accuracy: 0.8655 - val_loss: 0.8717 - val_binary_accuracy: 0.7836\n",
      "Epoch 61/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2725 - binary_accuracy: 0.8637 - val_loss: 0.7934 - val_binary_accuracy: 0.7692\n",
      "Epoch 62/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2646 - binary_accuracy: 0.8668 - val_loss: 0.8487 - val_binary_accuracy: 0.7685\n",
      "Epoch 63/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2640 - binary_accuracy: 0.8709 - val_loss: 0.9109 - val_binary_accuracy: 0.7829\n",
      "Epoch 64/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2587 - binary_accuracy: 0.8717 - val_loss: 0.8748 - val_binary_accuracy: 0.7779\n",
      "Epoch 65/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2577 - binary_accuracy: 0.8726 - val_loss: 0.9510 - val_binary_accuracy: 0.7771\n",
      "Epoch 66/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2590 - binary_accuracy: 0.8700 - val_loss: 0.9178 - val_binary_accuracy: 0.7685\n",
      "Epoch 67/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2513 - binary_accuracy: 0.8758 - val_loss: 0.9369 - val_binary_accuracy: 0.7757\n",
      "Epoch 68/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2568 - binary_accuracy: 0.8715 - val_loss: 0.9156 - val_binary_accuracy: 0.7886\n",
      "Epoch 69/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2488 - binary_accuracy: 0.8765 - val_loss: 1.0731 - val_binary_accuracy: 0.7764\n",
      "Epoch 70/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2539 - binary_accuracy: 0.8733 - val_loss: 0.9535 - val_binary_accuracy: 0.7786\n",
      "Epoch 71/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2495 - binary_accuracy: 0.8743 - val_loss: 1.0537 - val_binary_accuracy: 0.7793\n",
      "Epoch 72/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2465 - binary_accuracy: 0.8749 - val_loss: 1.0409 - val_binary_accuracy: 0.7771\n",
      "Epoch 73/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2543 - binary_accuracy: 0.8734 - val_loss: 1.0166 - val_binary_accuracy: 0.7815\n",
      "Epoch 74/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2457 - binary_accuracy: 0.8790 - val_loss: 1.0621 - val_binary_accuracy: 0.7779\n",
      "Epoch 75/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2453 - binary_accuracy: 0.8769 - val_loss: 1.0576 - val_binary_accuracy: 0.7599\n",
      "Epoch 76/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2583 - binary_accuracy: 0.8720 - val_loss: 1.0433 - val_binary_accuracy: 0.7678\n",
      "Epoch 77/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2695 - binary_accuracy: 0.8718 - val_loss: 0.8917 - val_binary_accuracy: 0.7793\n",
      "Epoch 78/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2453 - binary_accuracy: 0.8742 - val_loss: 0.9465 - val_binary_accuracy: 0.7743\n",
      "Epoch 79/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2415 - binary_accuracy: 0.8776 - val_loss: 1.0263 - val_binary_accuracy: 0.7699\n",
      "Epoch 80/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2375 - binary_accuracy: 0.8814 - val_loss: 1.0359 - val_binary_accuracy: 0.7771\n",
      "Epoch 81/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2332 - binary_accuracy: 0.8823 - val_loss: 1.1078 - val_binary_accuracy: 0.7649\n",
      "Epoch 82/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2364 - binary_accuracy: 0.8810 - val_loss: 1.0065 - val_binary_accuracy: 0.7721\n",
      "Epoch 83/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2363 - binary_accuracy: 0.8803 - val_loss: 1.1125 - val_binary_accuracy: 0.7699\n",
      "Epoch 84/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2327 - binary_accuracy: 0.8832 - val_loss: 1.1137 - val_binary_accuracy: 0.7699\n",
      "Epoch 85/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2314 - binary_accuracy: 0.8835 - val_loss: 1.0803 - val_binary_accuracy: 0.7721\n",
      "Epoch 86/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2313 - binary_accuracy: 0.8835 - val_loss: 1.1635 - val_binary_accuracy: 0.7685\n",
      "Epoch 87/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2420 - binary_accuracy: 0.8796 - val_loss: 1.1678 - val_binary_accuracy: 0.7764\n",
      "Epoch 88/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2293 - binary_accuracy: 0.8837 - val_loss: 1.1543 - val_binary_accuracy: 0.7656\n",
      "Epoch 89/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2330 - binary_accuracy: 0.8828 - val_loss: 1.1290 - val_binary_accuracy: 0.7664\n",
      "Epoch 90/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2275 - binary_accuracy: 0.8839 - val_loss: 1.1468 - val_binary_accuracy: 0.7714\n",
      "Epoch 91/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2472 - binary_accuracy: 0.8806 - val_loss: 1.1684 - val_binary_accuracy: 0.7735\n",
      "Epoch 92/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2385 - binary_accuracy: 0.8826 - val_loss: 1.0883 - val_binary_accuracy: 0.7721\n",
      "Epoch 93/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2370 - binary_accuracy: 0.8824 - val_loss: 1.0933 - val_binary_accuracy: 0.7764\n",
      "Epoch 94/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2310 - binary_accuracy: 0.8855 - val_loss: 1.1815 - val_binary_accuracy: 0.7714\n",
      "Epoch 95/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2406 - binary_accuracy: 0.8884 - val_loss: 1.1967 - val_binary_accuracy: 0.7829\n",
      "Epoch 96/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2230 - binary_accuracy: 0.8871 - val_loss: 1.1834 - val_binary_accuracy: 0.7628\n",
      "Epoch 97/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2184 - binary_accuracy: 0.8868 - val_loss: 1.1381 - val_binary_accuracy: 0.7692\n",
      "Epoch 98/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2200 - binary_accuracy: 0.8894 - val_loss: 1.2765 - val_binary_accuracy: 0.7771\n",
      "Epoch 99/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2459 - binary_accuracy: 0.8812 - val_loss: 1.0984 - val_binary_accuracy: 0.7649\n",
      "Epoch 100/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2198 - binary_accuracy: 0.8862 - val_loss: 1.2686 - val_binary_accuracy: 0.7642\n",
      "Epoch 101/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2178 - binary_accuracy: 0.8877 - val_loss: 1.1952 - val_binary_accuracy: 0.7584\n",
      "Epoch 102/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2262 - binary_accuracy: 0.8846 - val_loss: 1.2125 - val_binary_accuracy: 0.7570\n",
      "Epoch 103/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2291 - binary_accuracy: 0.8855 - val_loss: 1.2136 - val_binary_accuracy: 0.7714\n",
      "Epoch 104/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2218 - binary_accuracy: 0.8894 - val_loss: 1.2530 - val_binary_accuracy: 0.7649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2110 - binary_accuracy: 0.8950 - val_loss: 1.3547 - val_binary_accuracy: 0.7613\n",
      "Epoch 106/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2079 - binary_accuracy: 0.8912 - val_loss: 1.3023 - val_binary_accuracy: 0.7678\n",
      "Epoch 107/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2087 - binary_accuracy: 0.8934 - val_loss: 1.3859 - val_binary_accuracy: 0.7786\n",
      "Epoch 108/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2175 - binary_accuracy: 0.8875 - val_loss: 1.3076 - val_binary_accuracy: 0.7707\n",
      "Epoch 109/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2174 - binary_accuracy: 0.8918 - val_loss: 1.3923 - val_binary_accuracy: 0.7728\n",
      "Epoch 110/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2243 - binary_accuracy: 0.8884 - val_loss: 1.2528 - val_binary_accuracy: 0.7592\n",
      "Epoch 111/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2151 - binary_accuracy: 0.8903 - val_loss: 1.3689 - val_binary_accuracy: 0.7606\n",
      "Epoch 112/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2143 - binary_accuracy: 0.8932 - val_loss: 1.3513 - val_binary_accuracy: 0.7613\n",
      "Epoch 113/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2084 - binary_accuracy: 0.8943 - val_loss: 1.4123 - val_binary_accuracy: 0.7620\n",
      "Epoch 114/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2120 - binary_accuracy: 0.8920 - val_loss: 1.4512 - val_binary_accuracy: 0.7671\n",
      "Epoch 115/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2046 - binary_accuracy: 0.8930 - val_loss: 1.4859 - val_binary_accuracy: 0.7577\n",
      "Epoch 116/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2095 - binary_accuracy: 0.8961 - val_loss: 1.4663 - val_binary_accuracy: 0.7671\n",
      "Epoch 117/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2086 - binary_accuracy: 0.8930 - val_loss: 1.5979 - val_binary_accuracy: 0.7685\n",
      "Epoch 118/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2296 - binary_accuracy: 0.8932 - val_loss: 1.2499 - val_binary_accuracy: 0.7735\n",
      "Epoch 119/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2131 - binary_accuracy: 0.8923 - val_loss: 1.4068 - val_binary_accuracy: 0.7678\n",
      "Epoch 120/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2092 - binary_accuracy: 0.8893 - val_loss: 1.6145 - val_binary_accuracy: 0.7735\n",
      "Epoch 121/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2199 - binary_accuracy: 0.8956 - val_loss: 1.4505 - val_binary_accuracy: 0.7620\n",
      "Epoch 122/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2014 - binary_accuracy: 0.8966 - val_loss: 1.4711 - val_binary_accuracy: 0.7685\n",
      "Epoch 123/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1997 - binary_accuracy: 0.8981 - val_loss: 1.6263 - val_binary_accuracy: 0.7721\n",
      "Epoch 124/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2068 - binary_accuracy: 0.8970 - val_loss: 1.5213 - val_binary_accuracy: 0.7584\n",
      "Epoch 125/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2111 - binary_accuracy: 0.8957 - val_loss: 1.6177 - val_binary_accuracy: 0.7563\n",
      "Epoch 126/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2252 - binary_accuracy: 0.8902 - val_loss: 1.4911 - val_binary_accuracy: 0.7728\n",
      "Epoch 127/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2260 - binary_accuracy: 0.8921 - val_loss: 1.5045 - val_binary_accuracy: 0.7692\n",
      "Epoch 128/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2137 - binary_accuracy: 0.8923 - val_loss: 1.4226 - val_binary_accuracy: 0.7678\n",
      "Epoch 129/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1926 - binary_accuracy: 0.9028 - val_loss: 1.6354 - val_binary_accuracy: 0.7750\n",
      "Epoch 130/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1954 - binary_accuracy: 0.8988 - val_loss: 1.6082 - val_binary_accuracy: 0.7642\n",
      "Epoch 131/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1968 - binary_accuracy: 0.9020 - val_loss: 1.5964 - val_binary_accuracy: 0.7664\n",
      "Epoch 132/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1964 - binary_accuracy: 0.9001 - val_loss: 1.6268 - val_binary_accuracy: 0.7649\n",
      "Epoch 133/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1935 - binary_accuracy: 0.9020 - val_loss: 1.7390 - val_binary_accuracy: 0.7599\n",
      "Epoch 134/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1961 - binary_accuracy: 0.9002 - val_loss: 1.6573 - val_binary_accuracy: 0.7771\n",
      "Epoch 135/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2069 - binary_accuracy: 0.8970 - val_loss: 1.6257 - val_binary_accuracy: 0.7556\n",
      "Epoch 136/500\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.2017 - binary_accuracy: 0.8979 - val_loss: 1.5413 - val_binary_accuracy: 0.7656\n",
      "Epoch 137/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2187 - binary_accuracy: 0.8977 - val_loss: 1.6326 - val_binary_accuracy: 0.7642\n",
      "Epoch 138/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2201 - binary_accuracy: 0.8894 - val_loss: 1.4133 - val_binary_accuracy: 0.7649\n",
      "Epoch 139/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2092 - binary_accuracy: 0.8963 - val_loss: 1.4777 - val_binary_accuracy: 0.7671\n",
      "Epoch 140/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1963 - binary_accuracy: 0.9038 - val_loss: 1.5470 - val_binary_accuracy: 0.7656\n",
      "Epoch 141/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1919 - binary_accuracy: 0.9038 - val_loss: 1.5390 - val_binary_accuracy: 0.7685\n",
      "Epoch 142/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1927 - binary_accuracy: 0.9008 - val_loss: 1.6638 - val_binary_accuracy: 0.7699\n",
      "Epoch 143/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1913 - binary_accuracy: 0.9071 - val_loss: 1.5908 - val_binary_accuracy: 0.7678\n",
      "Epoch 144/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1880 - binary_accuracy: 0.9029 - val_loss: 1.6295 - val_binary_accuracy: 0.7692\n",
      "Epoch 145/500\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.1919 - binary_accuracy: 0.8999 - val_loss: 1.6428 - val_binary_accuracy: 0.7728\n",
      "Epoch 146/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1912 - binary_accuracy: 0.9033 - val_loss: 1.7054 - val_binary_accuracy: 0.7735\n",
      "Epoch 147/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1907 - binary_accuracy: 0.8988 - val_loss: 1.7885 - val_binary_accuracy: 0.7649\n",
      "Epoch 148/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1962 - binary_accuracy: 0.9010 - val_loss: 1.6153 - val_binary_accuracy: 0.7664\n",
      "Epoch 149/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1987 - binary_accuracy: 0.9006 - val_loss: 1.7309 - val_binary_accuracy: 0.7599\n",
      "Epoch 150/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2023 - binary_accuracy: 0.8995 - val_loss: 1.8799 - val_binary_accuracy: 0.7685\n",
      "Epoch 151/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2004 - binary_accuracy: 0.8990 - val_loss: 1.6158 - val_binary_accuracy: 0.7671\n",
      "Epoch 152/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1884 - binary_accuracy: 0.9053 - val_loss: 1.8075 - val_binary_accuracy: 0.7707\n",
      "Epoch 153/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1904 - binary_accuracy: 0.9063 - val_loss: 1.7973 - val_binary_accuracy: 0.7656\n",
      "Epoch 154/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1912 - binary_accuracy: 0.9047 - val_loss: 1.8849 - val_binary_accuracy: 0.7563\n",
      "Epoch 155/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1881 - binary_accuracy: 0.9028 - val_loss: 1.8568 - val_binary_accuracy: 0.7671\n",
      "Epoch 156/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1927 - binary_accuracy: 0.9060 - val_loss: 1.7451 - val_binary_accuracy: 0.7671\n",
      "Epoch 157/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1923 - binary_accuracy: 0.9058 - val_loss: 1.6590 - val_binary_accuracy: 0.7678\n",
      "Epoch 158/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1851 - binary_accuracy: 0.9065 - val_loss: 2.0548 - val_binary_accuracy: 0.7628\n",
      "Epoch 159/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1840 - binary_accuracy: 0.9058 - val_loss: 1.8943 - val_binary_accuracy: 0.7699\n",
      "Epoch 160/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1925 - binary_accuracy: 0.9067 - val_loss: 1.8928 - val_binary_accuracy: 0.7764\n",
      "Epoch 161/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1878 - binary_accuracy: 0.9067 - val_loss: 1.8298 - val_binary_accuracy: 0.7656\n",
      "Epoch 162/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1953 - binary_accuracy: 0.9069 - val_loss: 2.0288 - val_binary_accuracy: 0.7807\n",
      "Epoch 163/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2313 - binary_accuracy: 0.8950 - val_loss: 1.6851 - val_binary_accuracy: 0.7685\n",
      "Epoch 164/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1919 - binary_accuracy: 0.9036 - val_loss: 1.7912 - val_binary_accuracy: 0.7728\n",
      "Epoch 165/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1826 - binary_accuracy: 0.9056 - val_loss: 1.8619 - val_binary_accuracy: 0.7635\n",
      "Epoch 166/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1784 - binary_accuracy: 0.9101 - val_loss: 2.0413 - val_binary_accuracy: 0.7692\n",
      "Epoch 167/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1865 - binary_accuracy: 0.9069 - val_loss: 1.8763 - val_binary_accuracy: 0.7592\n",
      "Epoch 168/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1858 - binary_accuracy: 0.9040 - val_loss: 1.7978 - val_binary_accuracy: 0.7628\n",
      "Epoch 169/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1823 - binary_accuracy: 0.9065 - val_loss: 2.0233 - val_binary_accuracy: 0.7685\n",
      "Epoch 170/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1776 - binary_accuracy: 0.9096 - val_loss: 1.9869 - val_binary_accuracy: 0.7635\n",
      "Epoch 171/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1810 - binary_accuracy: 0.9099 - val_loss: 2.0352 - val_binary_accuracy: 0.7599\n",
      "Epoch 172/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1787 - binary_accuracy: 0.9080 - val_loss: 2.0887 - val_binary_accuracy: 0.7678\n",
      "Epoch 173/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1809 - binary_accuracy: 0.9081 - val_loss: 1.9711 - val_binary_accuracy: 0.7628\n",
      "Epoch 174/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1790 - binary_accuracy: 0.9119 - val_loss: 1.9491 - val_binary_accuracy: 0.7584\n",
      "Epoch 175/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1800 - binary_accuracy: 0.9083 - val_loss: 2.1263 - val_binary_accuracy: 0.7584\n",
      "Epoch 176/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1933 - binary_accuracy: 0.9063 - val_loss: 2.0589 - val_binary_accuracy: 0.7577\n",
      "Epoch 177/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1977 - binary_accuracy: 0.8999 - val_loss: 2.0200 - val_binary_accuracy: 0.7678\n",
      "Epoch 178/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2182 - binary_accuracy: 0.8981 - val_loss: 1.8555 - val_binary_accuracy: 0.7707\n",
      "Epoch 179/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1993 - binary_accuracy: 0.9033 - val_loss: 1.7136 - val_binary_accuracy: 0.7678\n",
      "Epoch 180/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1981 - binary_accuracy: 0.9085 - val_loss: 1.7668 - val_binary_accuracy: 0.7628\n",
      "Epoch 181/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1777 - binary_accuracy: 0.9144 - val_loss: 1.8660 - val_binary_accuracy: 0.7584\n",
      "Epoch 182/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1962 - binary_accuracy: 0.9060 - val_loss: 1.7251 - val_binary_accuracy: 0.7656\n",
      "Epoch 183/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1879 - binary_accuracy: 0.9107 - val_loss: 1.6497 - val_binary_accuracy: 0.7656\n",
      "Epoch 184/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1740 - binary_accuracy: 0.9128 - val_loss: 1.9269 - val_binary_accuracy: 0.7584\n",
      "Epoch 185/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1731 - binary_accuracy: 0.9116 - val_loss: 1.9065 - val_binary_accuracy: 0.7685\n",
      "Epoch 186/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1800 - binary_accuracy: 0.9098 - val_loss: 1.9534 - val_binary_accuracy: 0.7599\n",
      "Epoch 187/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1730 - binary_accuracy: 0.9112 - val_loss: 1.9492 - val_binary_accuracy: 0.7664\n",
      "Epoch 188/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1687 - binary_accuracy: 0.9130 - val_loss: 2.1136 - val_binary_accuracy: 0.7649\n",
      "Epoch 189/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1780 - binary_accuracy: 0.9107 - val_loss: 2.0214 - val_binary_accuracy: 0.7678\n",
      "Epoch 190/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1788 - binary_accuracy: 0.9087 - val_loss: 2.0613 - val_binary_accuracy: 0.7649\n",
      "Epoch 191/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1808 - binary_accuracy: 0.9119 - val_loss: 1.9389 - val_binary_accuracy: 0.7707\n",
      "Epoch 192/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1773 - binary_accuracy: 0.9092 - val_loss: 2.0317 - val_binary_accuracy: 0.7750\n",
      "Epoch 193/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1983 - binary_accuracy: 0.9065 - val_loss: 1.8035 - val_binary_accuracy: 0.7771\n",
      "Epoch 194/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1840 - binary_accuracy: 0.9074 - val_loss: 1.9004 - val_binary_accuracy: 0.7656\n",
      "Epoch 195/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1867 - binary_accuracy: 0.9040 - val_loss: 1.8237 - val_binary_accuracy: 0.7642\n",
      "Epoch 196/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1779 - binary_accuracy: 0.9083 - val_loss: 1.8260 - val_binary_accuracy: 0.7642\n",
      "Epoch 197/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1778 - binary_accuracy: 0.9099 - val_loss: 1.9068 - val_binary_accuracy: 0.7592\n",
      "Epoch 198/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1829 - binary_accuracy: 0.9094 - val_loss: 1.9311 - val_binary_accuracy: 0.7692\n",
      "Epoch 199/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1730 - binary_accuracy: 0.9110 - val_loss: 2.1016 - val_binary_accuracy: 0.7656\n",
      "Epoch 200/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1874 - binary_accuracy: 0.9065 - val_loss: 1.9738 - val_binary_accuracy: 0.7563\n",
      "Epoch 201/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1925 - binary_accuracy: 0.9067 - val_loss: 1.9699 - val_binary_accuracy: 0.7714\n",
      "Epoch 202/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1841 - binary_accuracy: 0.9076 - val_loss: 1.7505 - val_binary_accuracy: 0.7642\n",
      "Epoch 203/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1726 - binary_accuracy: 0.9090 - val_loss: 1.8230 - val_binary_accuracy: 0.7678\n",
      "Epoch 204/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1751 - binary_accuracy: 0.9125 - val_loss: 1.8214 - val_binary_accuracy: 0.7635\n",
      "Epoch 205/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1759 - binary_accuracy: 0.9105 - val_loss: 1.8372 - val_binary_accuracy: 0.7534\n",
      "Epoch 206/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1723 - binary_accuracy: 0.9126 - val_loss: 2.0802 - val_binary_accuracy: 0.7635\n",
      "Epoch 207/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1684 - binary_accuracy: 0.9137 - val_loss: 2.1112 - val_binary_accuracy: 0.7685\n",
      "Epoch 208/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1669 - binary_accuracy: 0.9139 - val_loss: 1.9941 - val_binary_accuracy: 0.7671\n",
      "Epoch 209/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1670 - binary_accuracy: 0.9148 - val_loss: 2.2414 - val_binary_accuracy: 0.7692\n",
      "Epoch 210/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1802 - binary_accuracy: 0.9121 - val_loss: 1.9954 - val_binary_accuracy: 0.7685\n",
      "Epoch 211/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1724 - binary_accuracy: 0.9135 - val_loss: 2.1043 - val_binary_accuracy: 0.7664\n",
      "Epoch 212/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1777 - binary_accuracy: 0.9072 - val_loss: 2.0485 - val_binary_accuracy: 0.7635\n",
      "Epoch 213/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1693 - binary_accuracy: 0.9134 - val_loss: 2.0473 - val_binary_accuracy: 0.7699\n",
      "Epoch 214/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1719 - binary_accuracy: 0.9135 - val_loss: 2.0796 - val_binary_accuracy: 0.7707\n",
      "Epoch 215/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2133 - binary_accuracy: 0.9051 - val_loss: 1.8710 - val_binary_accuracy: 0.7750\n",
      "Epoch 216/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2057 - binary_accuracy: 0.9038 - val_loss: 1.8158 - val_binary_accuracy: 0.7692\n",
      "Epoch 217/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1792 - binary_accuracy: 0.9094 - val_loss: 1.8759 - val_binary_accuracy: 0.7707\n",
      "Epoch 218/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1717 - binary_accuracy: 0.9139 - val_loss: 1.9448 - val_binary_accuracy: 0.7671\n",
      "Epoch 219/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1803 - binary_accuracy: 0.9110 - val_loss: 1.9973 - val_binary_accuracy: 0.7570\n",
      "Epoch 220/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1735 - binary_accuracy: 0.9135 - val_loss: 2.0421 - val_binary_accuracy: 0.7735\n",
      "Epoch 221/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1738 - binary_accuracy: 0.9159 - val_loss: 1.8694 - val_binary_accuracy: 0.7649\n",
      "Epoch 222/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1774 - binary_accuracy: 0.9130 - val_loss: 1.9632 - val_binary_accuracy: 0.7699\n",
      "Epoch 223/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1652 - binary_accuracy: 0.9159 - val_loss: 2.1140 - val_binary_accuracy: 0.7671\n",
      "Epoch 224/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1644 - binary_accuracy: 0.9175 - val_loss: 2.0969 - val_binary_accuracy: 0.7599\n",
      "Epoch 225/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1648 - binary_accuracy: 0.9139 - val_loss: 2.1878 - val_binary_accuracy: 0.7764\n",
      "Epoch 226/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1646 - binary_accuracy: 0.9134 - val_loss: 2.1267 - val_binary_accuracy: 0.7664\n",
      "Epoch 227/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1577 - binary_accuracy: 0.9177 - val_loss: 2.2703 - val_binary_accuracy: 0.7728\n",
      "Epoch 228/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1642 - binary_accuracy: 0.9143 - val_loss: 2.2726 - val_binary_accuracy: 0.7606\n",
      "Epoch 229/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1796 - binary_accuracy: 0.9116 - val_loss: 2.1688 - val_binary_accuracy: 0.7678\n",
      "Epoch 230/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1684 - binary_accuracy: 0.9135 - val_loss: 2.3471 - val_binary_accuracy: 0.7628\n",
      "Epoch 231/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1849 - binary_accuracy: 0.9110 - val_loss: 2.1374 - val_binary_accuracy: 0.7743\n",
      "Epoch 232/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1955 - binary_accuracy: 0.9076 - val_loss: 1.9556 - val_binary_accuracy: 0.7656\n",
      "Epoch 233/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1722 - binary_accuracy: 0.9139 - val_loss: 2.3129 - val_binary_accuracy: 0.7649\n",
      "Epoch 234/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1794 - binary_accuracy: 0.9105 - val_loss: 2.1144 - val_binary_accuracy: 0.7692\n",
      "Epoch 235/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1866 - binary_accuracy: 0.9101 - val_loss: 1.8814 - val_binary_accuracy: 0.7699\n",
      "Epoch 236/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1893 - binary_accuracy: 0.9081 - val_loss: 1.7968 - val_binary_accuracy: 0.7714\n",
      "Epoch 237/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1720 - binary_accuracy: 0.9130 - val_loss: 1.9512 - val_binary_accuracy: 0.7699\n",
      "Epoch 238/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1697 - binary_accuracy: 0.9196 - val_loss: 2.2506 - val_binary_accuracy: 0.7656\n",
      "Epoch 239/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1689 - binary_accuracy: 0.9182 - val_loss: 1.9120 - val_binary_accuracy: 0.7714\n",
      "Epoch 240/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1631 - binary_accuracy: 0.9157 - val_loss: 2.1762 - val_binary_accuracy: 0.7664\n",
      "Epoch 241/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1618 - binary_accuracy: 0.9150 - val_loss: 2.2126 - val_binary_accuracy: 0.7671\n",
      "Epoch 242/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1639 - binary_accuracy: 0.9148 - val_loss: 2.1572 - val_binary_accuracy: 0.7743\n",
      "Epoch 243/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1695 - binary_accuracy: 0.9146 - val_loss: 2.0937 - val_binary_accuracy: 0.7707\n",
      "Epoch 244/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1778 - binary_accuracy: 0.9128 - val_loss: 2.0630 - val_binary_accuracy: 0.7570\n",
      "Epoch 245/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1803 - binary_accuracy: 0.9121 - val_loss: 1.9185 - val_binary_accuracy: 0.7678\n",
      "Epoch 246/500\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.1673 - binary_accuracy: 0.9148 - val_loss: 2.2159 - val_binary_accuracy: 0.7707\n",
      "Epoch 247/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1623 - binary_accuracy: 0.9179 - val_loss: 2.2570 - val_binary_accuracy: 0.7692\n",
      "Epoch 248/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1654 - binary_accuracy: 0.9144 - val_loss: 2.1826 - val_binary_accuracy: 0.7606\n",
      "Epoch 249/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1574 - binary_accuracy: 0.9155 - val_loss: 2.4213 - val_binary_accuracy: 0.7671\n",
      "Epoch 250/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1593 - binary_accuracy: 0.9164 - val_loss: 2.3411 - val_binary_accuracy: 0.7563\n",
      "Epoch 251/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1736 - binary_accuracy: 0.9099 - val_loss: 2.2394 - val_binary_accuracy: 0.7620\n",
      "Epoch 252/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2005 - binary_accuracy: 0.9044 - val_loss: 2.0071 - val_binary_accuracy: 0.7664\n",
      "Epoch 253/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1820 - binary_accuracy: 0.9090 - val_loss: 1.9994 - val_binary_accuracy: 0.7649\n",
      "Epoch 254/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1742 - binary_accuracy: 0.9114 - val_loss: 2.1951 - val_binary_accuracy: 0.7642\n",
      "Epoch 255/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1666 - binary_accuracy: 0.9144 - val_loss: 2.1970 - val_binary_accuracy: 0.7649\n",
      "Epoch 256/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1590 - binary_accuracy: 0.9161 - val_loss: 2.3347 - val_binary_accuracy: 0.7635\n",
      "Epoch 257/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1574 - binary_accuracy: 0.9173 - val_loss: 2.4166 - val_binary_accuracy: 0.7692\n",
      "Epoch 258/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1619 - binary_accuracy: 0.9162 - val_loss: 2.3158 - val_binary_accuracy: 0.7620\n",
      "Epoch 259/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1633 - binary_accuracy: 0.9189 - val_loss: 2.4427 - val_binary_accuracy: 0.7714\n",
      "Epoch 260/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1693 - binary_accuracy: 0.9130 - val_loss: 2.2814 - val_binary_accuracy: 0.7664\n",
      "Epoch 261/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1571 - binary_accuracy: 0.9180 - val_loss: 2.3104 - val_binary_accuracy: 0.7606\n",
      "Epoch 262/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1634 - binary_accuracy: 0.9175 - val_loss: 2.2292 - val_binary_accuracy: 0.7707\n",
      "Epoch 263/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1670 - binary_accuracy: 0.9159 - val_loss: 2.2955 - val_binary_accuracy: 0.7628\n",
      "Epoch 264/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1623 - binary_accuracy: 0.9159 - val_loss: 2.2739 - val_binary_accuracy: 0.7635\n",
      "Epoch 265/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1799 - binary_accuracy: 0.9107 - val_loss: 2.2070 - val_binary_accuracy: 0.7599\n",
      "Epoch 266/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1633 - binary_accuracy: 0.9180 - val_loss: 2.2452 - val_binary_accuracy: 0.7692\n",
      "Epoch 267/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1667 - binary_accuracy: 0.9161 - val_loss: 2.2490 - val_binary_accuracy: 0.7692\n",
      "Epoch 268/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1726 - binary_accuracy: 0.9125 - val_loss: 2.2943 - val_binary_accuracy: 0.7699\n",
      "Epoch 269/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1677 - binary_accuracy: 0.9148 - val_loss: 2.2638 - val_binary_accuracy: 0.7699\n",
      "Epoch 270/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1638 - binary_accuracy: 0.9168 - val_loss: 2.1066 - val_binary_accuracy: 0.7685\n",
      "Epoch 271/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1711 - binary_accuracy: 0.9130 - val_loss: 2.1624 - val_binary_accuracy: 0.7771\n",
      "Epoch 272/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1644 - binary_accuracy: 0.9164 - val_loss: 2.3802 - val_binary_accuracy: 0.7728\n",
      "Epoch 273/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1697 - binary_accuracy: 0.9157 - val_loss: 2.4745 - val_binary_accuracy: 0.7656\n",
      "Epoch 274/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1659 - binary_accuracy: 0.9179 - val_loss: 2.5194 - val_binary_accuracy: 0.7606\n",
      "Epoch 275/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1647 - binary_accuracy: 0.9148 - val_loss: 2.1934 - val_binary_accuracy: 0.7771\n",
      "Epoch 276/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1618 - binary_accuracy: 0.9168 - val_loss: 2.2338 - val_binary_accuracy: 0.7620\n",
      "Epoch 277/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1600 - binary_accuracy: 0.9159 - val_loss: 2.2881 - val_binary_accuracy: 0.7750\n",
      "Epoch 278/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1544 - binary_accuracy: 0.9204 - val_loss: 2.3092 - val_binary_accuracy: 0.7728\n",
      "Epoch 279/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1621 - binary_accuracy: 0.9159 - val_loss: 2.3684 - val_binary_accuracy: 0.7735\n",
      "Epoch 280/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1631 - binary_accuracy: 0.9179 - val_loss: 2.2474 - val_binary_accuracy: 0.7707\n",
      "Epoch 281/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1604 - binary_accuracy: 0.9182 - val_loss: 2.2669 - val_binary_accuracy: 0.7685\n",
      "Epoch 282/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1676 - binary_accuracy: 0.9135 - val_loss: 2.3085 - val_binary_accuracy: 0.7664\n",
      "Epoch 283/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1702 - binary_accuracy: 0.9155 - val_loss: 2.2186 - val_binary_accuracy: 0.7628\n",
      "Epoch 284/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1591 - binary_accuracy: 0.9204 - val_loss: 2.3025 - val_binary_accuracy: 0.7534\n",
      "Epoch 285/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1839 - binary_accuracy: 0.9107 - val_loss: 2.1258 - val_binary_accuracy: 0.7649\n",
      "Epoch 286/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1811 - binary_accuracy: 0.9105 - val_loss: 2.1145 - val_binary_accuracy: 0.7649\n",
      "Epoch 287/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1779 - binary_accuracy: 0.9112 - val_loss: 2.1476 - val_binary_accuracy: 0.7728\n",
      "Epoch 288/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1593 - binary_accuracy: 0.9189 - val_loss: 2.1968 - val_binary_accuracy: 0.7685\n",
      "Epoch 289/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1550 - binary_accuracy: 0.9204 - val_loss: 2.2576 - val_binary_accuracy: 0.7671\n",
      "Epoch 290/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1565 - binary_accuracy: 0.9202 - val_loss: 2.3579 - val_binary_accuracy: 0.7613\n",
      "Epoch 291/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1505 - binary_accuracy: 0.9196 - val_loss: 2.4848 - val_binary_accuracy: 0.7635\n",
      "Epoch 292/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1490 - binary_accuracy: 0.9209 - val_loss: 2.4358 - val_binary_accuracy: 0.7656\n",
      "Epoch 293/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1514 - binary_accuracy: 0.9213 - val_loss: 2.7162 - val_binary_accuracy: 0.7692\n",
      "Epoch 294/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1571 - binary_accuracy: 0.9205 - val_loss: 2.6292 - val_binary_accuracy: 0.7707\n",
      "Epoch 295/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1763 - binary_accuracy: 0.9166 - val_loss: 2.3512 - val_binary_accuracy: 0.7628\n",
      "Epoch 296/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1639 - binary_accuracy: 0.9153 - val_loss: 2.4659 - val_binary_accuracy: 0.7728\n",
      "Epoch 297/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1740 - binary_accuracy: 0.9162 - val_loss: 2.1819 - val_binary_accuracy: 0.7584\n",
      "Epoch 298/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1965 - binary_accuracy: 0.9099 - val_loss: 1.9292 - val_binary_accuracy: 0.7642\n",
      "Epoch 299/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1827 - binary_accuracy: 0.9152 - val_loss: 2.0556 - val_binary_accuracy: 0.7664\n",
      "Epoch 300/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1555 - binary_accuracy: 0.9205 - val_loss: 2.2358 - val_binary_accuracy: 0.7671\n",
      "Epoch 301/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1579 - binary_accuracy: 0.9214 - val_loss: 2.2091 - val_binary_accuracy: 0.7678\n",
      "Epoch 302/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1552 - binary_accuracy: 0.9216 - val_loss: 2.3186 - val_binary_accuracy: 0.7635\n",
      "Epoch 303/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1567 - binary_accuracy: 0.9211 - val_loss: 2.3594 - val_binary_accuracy: 0.7692\n",
      "Epoch 304/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1697 - binary_accuracy: 0.9112 - val_loss: 2.0106 - val_binary_accuracy: 0.7656\n",
      "Epoch 305/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1693 - binary_accuracy: 0.9144 - val_loss: 2.1642 - val_binary_accuracy: 0.7757\n",
      "Epoch 306/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1595 - binary_accuracy: 0.9170 - val_loss: 2.3034 - val_binary_accuracy: 0.7613\n",
      "Epoch 307/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1640 - binary_accuracy: 0.9171 - val_loss: 2.2407 - val_binary_accuracy: 0.7656\n",
      "Epoch 308/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1645 - binary_accuracy: 0.9164 - val_loss: 2.3416 - val_binary_accuracy: 0.7685\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1646 - binary_accuracy: 0.9200 - val_loss: 2.3277 - val_binary_accuracy: 0.7613\n",
      "Epoch 310/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1619 - binary_accuracy: 0.9179 - val_loss: 2.3967 - val_binary_accuracy: 0.7656\n",
      "Epoch 311/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1553 - binary_accuracy: 0.9218 - val_loss: 2.4403 - val_binary_accuracy: 0.7599\n",
      "Epoch 312/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1550 - binary_accuracy: 0.9200 - val_loss: 2.5305 - val_binary_accuracy: 0.7728\n",
      "Epoch 313/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1581 - binary_accuracy: 0.9189 - val_loss: 2.4663 - val_binary_accuracy: 0.7664\n",
      "Epoch 314/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1545 - binary_accuracy: 0.9218 - val_loss: 2.5468 - val_binary_accuracy: 0.7699\n",
      "Epoch 315/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1556 - binary_accuracy: 0.9207 - val_loss: 2.5200 - val_binary_accuracy: 0.7678\n",
      "Epoch 316/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1585 - binary_accuracy: 0.9204 - val_loss: 2.4947 - val_binary_accuracy: 0.7649\n",
      "Epoch 317/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1701 - binary_accuracy: 0.9162 - val_loss: 2.5217 - val_binary_accuracy: 0.7592\n",
      "Epoch 318/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1713 - binary_accuracy: 0.9162 - val_loss: 2.4537 - val_binary_accuracy: 0.7692\n",
      "Epoch 319/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1633 - binary_accuracy: 0.9157 - val_loss: 2.4979 - val_binary_accuracy: 0.7664\n",
      "Epoch 320/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1583 - binary_accuracy: 0.9171 - val_loss: 2.3607 - val_binary_accuracy: 0.7613\n",
      "Epoch 321/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1499 - binary_accuracy: 0.9222 - val_loss: 2.5918 - val_binary_accuracy: 0.7707\n",
      "Epoch 322/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1538 - binary_accuracy: 0.9213 - val_loss: 2.6220 - val_binary_accuracy: 0.7707\n",
      "Epoch 323/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1504 - binary_accuracy: 0.9227 - val_loss: 2.7302 - val_binary_accuracy: 0.7678\n",
      "Epoch 324/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1562 - binary_accuracy: 0.9198 - val_loss: 2.6575 - val_binary_accuracy: 0.7699\n",
      "Epoch 325/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1544 - binary_accuracy: 0.9216 - val_loss: 2.7486 - val_binary_accuracy: 0.7664\n",
      "Epoch 326/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1534 - binary_accuracy: 0.9200 - val_loss: 2.8031 - val_binary_accuracy: 0.7664\n",
      "Epoch 327/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1697 - binary_accuracy: 0.9180 - val_loss: 2.5743 - val_binary_accuracy: 0.7635\n",
      "Epoch 328/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1745 - binary_accuracy: 0.9139 - val_loss: 2.4132 - val_binary_accuracy: 0.7721\n",
      "Epoch 329/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1872 - binary_accuracy: 0.9146 - val_loss: 2.0218 - val_binary_accuracy: 0.7671\n",
      "Epoch 330/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1695 - binary_accuracy: 0.9153 - val_loss: 2.1539 - val_binary_accuracy: 0.7613\n",
      "Epoch 331/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1581 - binary_accuracy: 0.9179 - val_loss: 2.2889 - val_binary_accuracy: 0.7664\n",
      "Epoch 332/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1564 - binary_accuracy: 0.9175 - val_loss: 2.3760 - val_binary_accuracy: 0.7664\n",
      "Epoch 333/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1560 - binary_accuracy: 0.9209 - val_loss: 2.4600 - val_binary_accuracy: 0.7671\n",
      "Epoch 334/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1551 - binary_accuracy: 0.9205 - val_loss: 2.6090 - val_binary_accuracy: 0.7735\n",
      "Epoch 335/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1608 - binary_accuracy: 0.9182 - val_loss: 2.3523 - val_binary_accuracy: 0.7642\n",
      "Epoch 336/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1575 - binary_accuracy: 0.9216 - val_loss: 2.4420 - val_binary_accuracy: 0.7728\n",
      "Epoch 337/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1832 - binary_accuracy: 0.9240 - val_loss: 2.5568 - val_binary_accuracy: 0.7664\n",
      "Epoch 338/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1761 - binary_accuracy: 0.9159 - val_loss: 2.2689 - val_binary_accuracy: 0.7534\n",
      "Epoch 339/500\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.1571 - binary_accuracy: 0.9216 - val_loss: 2.4280 - val_binary_accuracy: 0.7606\n",
      "Epoch 340/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1475 - binary_accuracy: 0.9223 - val_loss: 2.5931 - val_binary_accuracy: 0.7541\n",
      "Epoch 341/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1422 - binary_accuracy: 0.9258 - val_loss: 2.5408 - val_binary_accuracy: 0.7642\n",
      "Epoch 342/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1456 - binary_accuracy: 0.9243 - val_loss: 2.6892 - val_binary_accuracy: 0.7606\n",
      "Epoch 343/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1458 - binary_accuracy: 0.9223 - val_loss: 2.7335 - val_binary_accuracy: 0.7656\n",
      "Epoch 344/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1477 - binary_accuracy: 0.9220 - val_loss: 2.7445 - val_binary_accuracy: 0.7599\n",
      "Epoch 345/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1490 - binary_accuracy: 0.9225 - val_loss: 2.5923 - val_binary_accuracy: 0.7606\n",
      "Epoch 346/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1534 - binary_accuracy: 0.9175 - val_loss: 2.8923 - val_binary_accuracy: 0.7520\n",
      "Epoch 347/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1814 - binary_accuracy: 0.9119 - val_loss: 2.5218 - val_binary_accuracy: 0.7584\n",
      "Epoch 348/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1724 - binary_accuracy: 0.9139 - val_loss: 2.9184 - val_binary_accuracy: 0.7699\n",
      "Epoch 349/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1785 - binary_accuracy: 0.9152 - val_loss: 2.4785 - val_binary_accuracy: 0.7628\n",
      "Epoch 350/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1597 - binary_accuracy: 0.9193 - val_loss: 2.6123 - val_binary_accuracy: 0.7685\n",
      "Epoch 351/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1602 - binary_accuracy: 0.9214 - val_loss: 2.6417 - val_binary_accuracy: 0.7613\n",
      "Epoch 352/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1701 - binary_accuracy: 0.9196 - val_loss: 2.7436 - val_binary_accuracy: 0.7678\n",
      "Epoch 353/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1736 - binary_accuracy: 0.9164 - val_loss: 2.7882 - val_binary_accuracy: 0.7685\n",
      "Epoch 354/500\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.1510 - binary_accuracy: 0.9222 - val_loss: 2.8077 - val_binary_accuracy: 0.7592\n",
      "Epoch 355/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1737 - binary_accuracy: 0.9191 - val_loss: 2.2625 - val_binary_accuracy: 0.7642\n",
      "Epoch 356/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1873 - binary_accuracy: 0.9182 - val_loss: 2.3532 - val_binary_accuracy: 0.7606\n",
      "Epoch 357/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1509 - binary_accuracy: 0.9232 - val_loss: 2.4462 - val_binary_accuracy: 0.7649\n",
      "Epoch 358/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1507 - binary_accuracy: 0.9231 - val_loss: 2.3212 - val_binary_accuracy: 0.7628\n",
      "Epoch 359/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1465 - binary_accuracy: 0.9240 - val_loss: 2.6364 - val_binary_accuracy: 0.7664\n",
      "Epoch 360/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1489 - binary_accuracy: 0.9238 - val_loss: 2.6271 - val_binary_accuracy: 0.7678\n",
      "Epoch 361/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1499 - binary_accuracy: 0.9229 - val_loss: 2.4411 - val_binary_accuracy: 0.7606\n",
      "Epoch 362/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1486 - binary_accuracy: 0.9231 - val_loss: 2.7108 - val_binary_accuracy: 0.7584\n",
      "Epoch 363/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1489 - binary_accuracy: 0.9227 - val_loss: 2.6819 - val_binary_accuracy: 0.7642\n",
      "Epoch 364/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1491 - binary_accuracy: 0.9245 - val_loss: 2.5298 - val_binary_accuracy: 0.7692\n",
      "Epoch 365/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1518 - binary_accuracy: 0.9225 - val_loss: 2.5731 - val_binary_accuracy: 0.7613\n",
      "Epoch 366/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1570 - binary_accuracy: 0.9182 - val_loss: 2.6902 - val_binary_accuracy: 0.7678\n",
      "Epoch 367/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1504 - binary_accuracy: 0.9223 - val_loss: 2.7726 - val_binary_accuracy: 0.7692\n",
      "Epoch 368/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1558 - binary_accuracy: 0.9218 - val_loss: 2.8803 - val_binary_accuracy: 0.7628\n",
      "Epoch 369/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1546 - binary_accuracy: 0.9191 - val_loss: 2.7062 - val_binary_accuracy: 0.7649\n",
      "Epoch 370/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1592 - binary_accuracy: 0.9223 - val_loss: 2.8499 - val_binary_accuracy: 0.7613\n",
      "Epoch 371/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1628 - binary_accuracy: 0.9187 - val_loss: 2.7104 - val_binary_accuracy: 0.7635\n",
      "Epoch 372/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1486 - binary_accuracy: 0.9214 - val_loss: 2.6631 - val_binary_accuracy: 0.7649\n",
      "Epoch 373/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1559 - binary_accuracy: 0.9250 - val_loss: 2.5136 - val_binary_accuracy: 0.7613\n",
      "Epoch 374/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1479 - binary_accuracy: 0.9238 - val_loss: 2.8476 - val_binary_accuracy: 0.7656\n",
      "Epoch 375/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1501 - binary_accuracy: 0.9222 - val_loss: 2.8063 - val_binary_accuracy: 0.7692\n",
      "Epoch 376/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1518 - binary_accuracy: 0.9216 - val_loss: 2.7047 - val_binary_accuracy: 0.7620\n",
      "Epoch 377/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1499 - binary_accuracy: 0.9211 - val_loss: 2.8870 - val_binary_accuracy: 0.7671\n",
      "Epoch 378/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1842 - binary_accuracy: 0.9182 - val_loss: 2.8912 - val_binary_accuracy: 0.7513\n",
      "Epoch 379/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1994 - binary_accuracy: 0.9130 - val_loss: 2.5064 - val_binary_accuracy: 0.7606\n",
      "Epoch 380/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2303 - binary_accuracy: 0.9130 - val_loss: 2.2917 - val_binary_accuracy: 0.7592\n",
      "Epoch 381/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.3232 - binary_accuracy: 0.9218 - val_loss: 2.8923 - val_binary_accuracy: 0.7599\n",
      "Epoch 382/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.2371 - binary_accuracy: 0.9216 - val_loss: 2.2299 - val_binary_accuracy: 0.7656\n",
      "Epoch 383/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1464 - binary_accuracy: 0.9258 - val_loss: 2.3943 - val_binary_accuracy: 0.7599\n",
      "Epoch 384/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1424 - binary_accuracy: 0.9265 - val_loss: 2.5553 - val_binary_accuracy: 0.7620\n",
      "Epoch 385/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1442 - binary_accuracy: 0.9256 - val_loss: 2.3590 - val_binary_accuracy: 0.7599\n",
      "Epoch 386/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1416 - binary_accuracy: 0.9263 - val_loss: 2.5278 - val_binary_accuracy: 0.7649\n",
      "Epoch 387/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1431 - binary_accuracy: 0.9258 - val_loss: 2.4917 - val_binary_accuracy: 0.7671\n",
      "Epoch 388/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1419 - binary_accuracy: 0.9267 - val_loss: 2.6850 - val_binary_accuracy: 0.7656\n",
      "Epoch 389/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1407 - binary_accuracy: 0.9283 - val_loss: 2.5569 - val_binary_accuracy: 0.7620\n",
      "Epoch 390/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1425 - binary_accuracy: 0.9241 - val_loss: 2.5934 - val_binary_accuracy: 0.7577\n",
      "Epoch 391/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1534 - binary_accuracy: 0.9232 - val_loss: 2.5971 - val_binary_accuracy: 0.7620\n",
      "Epoch 392/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1469 - binary_accuracy: 0.9229 - val_loss: 2.6901 - val_binary_accuracy: 0.7556\n",
      "Epoch 393/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1628 - binary_accuracy: 0.9222 - val_loss: 2.5890 - val_binary_accuracy: 0.7549\n",
      "Epoch 394/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1542 - binary_accuracy: 0.9205 - val_loss: 2.5377 - val_binary_accuracy: 0.7577\n",
      "Epoch 395/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1508 - binary_accuracy: 0.9216 - val_loss: 2.6920 - val_binary_accuracy: 0.7620\n",
      "Epoch 396/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1444 - binary_accuracy: 0.9250 - val_loss: 2.6965 - val_binary_accuracy: 0.7656\n",
      "Epoch 397/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1420 - binary_accuracy: 0.9241 - val_loss: 2.7378 - val_binary_accuracy: 0.7577\n",
      "Epoch 398/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1436 - binary_accuracy: 0.9243 - val_loss: 2.5755 - val_binary_accuracy: 0.7685\n",
      "Epoch 399/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1580 - binary_accuracy: 0.9209 - val_loss: 2.6309 - val_binary_accuracy: 0.7628\n",
      "Epoch 400/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1605 - binary_accuracy: 0.9214 - val_loss: 2.7281 - val_binary_accuracy: 0.7707\n",
      "Epoch 401/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1580 - binary_accuracy: 0.9216 - val_loss: 2.5940 - val_binary_accuracy: 0.7642\n",
      "Epoch 402/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1578 - binary_accuracy: 0.9202 - val_loss: 2.5449 - val_binary_accuracy: 0.7563\n",
      "Epoch 403/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1586 - binary_accuracy: 0.9191 - val_loss: 2.4823 - val_binary_accuracy: 0.7628\n",
      "Epoch 404/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1483 - binary_accuracy: 0.9232 - val_loss: 2.7071 - val_binary_accuracy: 0.7613\n",
      "Epoch 405/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1468 - binary_accuracy: 0.9238 - val_loss: 2.7025 - val_binary_accuracy: 0.7606\n",
      "Epoch 406/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1471 - binary_accuracy: 0.9240 - val_loss: 2.8631 - val_binary_accuracy: 0.7671\n",
      "Epoch 407/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1432 - binary_accuracy: 0.9245 - val_loss: 2.8521 - val_binary_accuracy: 0.7563\n",
      "Epoch 408/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1522 - binary_accuracy: 0.9202 - val_loss: 2.7194 - val_binary_accuracy: 0.7563\n",
      "Epoch 409/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1694 - binary_accuracy: 0.9155 - val_loss: 2.7846 - val_binary_accuracy: 0.7505\n",
      "Epoch 410/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1655 - binary_accuracy: 0.9205 - val_loss: 2.5764 - val_binary_accuracy: 0.7592\n",
      "Epoch 411/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1649 - binary_accuracy: 0.9213 - val_loss: 2.4036 - val_binary_accuracy: 0.7664\n",
      "Epoch 412/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1477 - binary_accuracy: 0.9240 - val_loss: 2.7831 - val_binary_accuracy: 0.7656\n",
      "Epoch 413/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1415 - binary_accuracy: 0.9283 - val_loss: 2.7765 - val_binary_accuracy: 0.7678\n",
      "Epoch 414/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1470 - binary_accuracy: 0.9252 - val_loss: 2.7888 - val_binary_accuracy: 0.7664\n",
      "Epoch 415/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1508 - binary_accuracy: 0.9238 - val_loss: 3.0726 - val_binary_accuracy: 0.7642\n",
      "Epoch 416/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1708 - binary_accuracy: 0.9214 - val_loss: 2.7753 - val_binary_accuracy: 0.7592\n",
      "Epoch 417/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1673 - binary_accuracy: 0.9216 - val_loss: 2.6091 - val_binary_accuracy: 0.7678\n",
      "Epoch 418/500\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 0.1427 - binary_accuracy: 0.9279 - val_loss: 2.7143 - val_binary_accuracy: 0.7664\n",
      "Epoch 419/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1454 - binary_accuracy: 0.9252 - val_loss: 2.8131 - val_binary_accuracy: 0.7642\n",
      "Epoch 420/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1529 - binary_accuracy: 0.9225 - val_loss: 2.6355 - val_binary_accuracy: 0.7584\n",
      "Epoch 421/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1445 - binary_accuracy: 0.9245 - val_loss: 2.6980 - val_binary_accuracy: 0.7649\n",
      "Epoch 422/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1459 - binary_accuracy: 0.9250 - val_loss: 2.7910 - val_binary_accuracy: 0.7664\n",
      "Epoch 423/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1412 - binary_accuracy: 0.9259 - val_loss: 2.8630 - val_binary_accuracy: 0.7628\n",
      "Epoch 424/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1393 - binary_accuracy: 0.9265 - val_loss: 2.8002 - val_binary_accuracy: 0.7642\n",
      "Epoch 425/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1436 - binary_accuracy: 0.9243 - val_loss: 2.8915 - val_binary_accuracy: 0.7620\n",
      "Epoch 426/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1421 - binary_accuracy: 0.9263 - val_loss: 2.9201 - val_binary_accuracy: 0.7628\n",
      "Epoch 427/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1515 - binary_accuracy: 0.9222 - val_loss: 2.9815 - val_binary_accuracy: 0.7599\n",
      "Epoch 428/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1443 - binary_accuracy: 0.9241 - val_loss: 2.8026 - val_binary_accuracy: 0.7649\n",
      "Epoch 429/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1553 - binary_accuracy: 0.9204 - val_loss: 3.1166 - val_binary_accuracy: 0.7671\n",
      "Epoch 430/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1622 - binary_accuracy: 0.9180 - val_loss: 2.8869 - val_binary_accuracy: 0.7707\n",
      "Epoch 431/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1626 - binary_accuracy: 0.9196 - val_loss: 2.5201 - val_binary_accuracy: 0.7520\n",
      "Epoch 432/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1560 - binary_accuracy: 0.9236 - val_loss: 2.8768 - val_binary_accuracy: 0.7664\n",
      "Epoch 433/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1439 - binary_accuracy: 0.9259 - val_loss: 3.3284 - val_binary_accuracy: 0.7649\n",
      "Epoch 434/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1662 - binary_accuracy: 0.9186 - val_loss: 2.7607 - val_binary_accuracy: 0.7599\n",
      "Epoch 435/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1472 - binary_accuracy: 0.9245 - val_loss: 3.1334 - val_binary_accuracy: 0.7606\n",
      "Epoch 436/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1443 - binary_accuracy: 0.9252 - val_loss: 2.9060 - val_binary_accuracy: 0.7628\n",
      "Epoch 437/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1478 - binary_accuracy: 0.9227 - val_loss: 3.0471 - val_binary_accuracy: 0.7606\n",
      "Epoch 438/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1487 - binary_accuracy: 0.9265 - val_loss: 3.3501 - val_binary_accuracy: 0.7584\n",
      "Epoch 439/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1875 - binary_accuracy: 0.9193 - val_loss: 2.9762 - val_binary_accuracy: 0.7656\n",
      "Epoch 440/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1668 - binary_accuracy: 0.9182 - val_loss: 2.8223 - val_binary_accuracy: 0.7563\n",
      "Epoch 441/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1698 - binary_accuracy: 0.9195 - val_loss: 2.5550 - val_binary_accuracy: 0.7592\n",
      "Epoch 442/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1476 - binary_accuracy: 0.9220 - val_loss: 2.8793 - val_binary_accuracy: 0.7635\n",
      "Epoch 443/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1449 - binary_accuracy: 0.9252 - val_loss: 2.9597 - val_binary_accuracy: 0.7563\n",
      "Epoch 444/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1442 - binary_accuracy: 0.9265 - val_loss: 3.1069 - val_binary_accuracy: 0.7642\n",
      "Epoch 445/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1400 - binary_accuracy: 0.9258 - val_loss: 3.0404 - val_binary_accuracy: 0.7606\n",
      "Epoch 446/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1375 - binary_accuracy: 0.9267 - val_loss: 3.2320 - val_binary_accuracy: 0.7613\n",
      "Epoch 447/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1352 - binary_accuracy: 0.9279 - val_loss: 3.3491 - val_binary_accuracy: 0.7606\n",
      "Epoch 448/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1357 - binary_accuracy: 0.9310 - val_loss: 3.2437 - val_binary_accuracy: 0.7606\n",
      "Epoch 449/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1456 - binary_accuracy: 0.9236 - val_loss: 3.0628 - val_binary_accuracy: 0.7505\n",
      "Epoch 450/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1588 - binary_accuracy: 0.9220 - val_loss: 2.7437 - val_binary_accuracy: 0.7685\n",
      "Epoch 451/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1779 - binary_accuracy: 0.9139 - val_loss: 2.7423 - val_binary_accuracy: 0.7534\n",
      "Epoch 452/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1609 - binary_accuracy: 0.9214 - val_loss: 2.7277 - val_binary_accuracy: 0.7599\n",
      "Epoch 453/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1499 - binary_accuracy: 0.9225 - val_loss: 3.0271 - val_binary_accuracy: 0.7628\n",
      "Epoch 454/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1444 - binary_accuracy: 0.9245 - val_loss: 3.1132 - val_binary_accuracy: 0.7714\n",
      "Epoch 455/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1424 - binary_accuracy: 0.9267 - val_loss: 3.1343 - val_binary_accuracy: 0.7664\n",
      "Epoch 456/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1441 - binary_accuracy: 0.9231 - val_loss: 3.3699 - val_binary_accuracy: 0.7635\n",
      "Epoch 457/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1434 - binary_accuracy: 0.9229 - val_loss: 3.4198 - val_binary_accuracy: 0.7649\n",
      "Epoch 458/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1465 - binary_accuracy: 0.9261 - val_loss: 3.2558 - val_binary_accuracy: 0.7556\n",
      "Epoch 459/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1455 - binary_accuracy: 0.9256 - val_loss: 3.1841 - val_binary_accuracy: 0.7577\n",
      "Epoch 460/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1475 - binary_accuracy: 0.9279 - val_loss: 3.2668 - val_binary_accuracy: 0.7628\n",
      "Epoch 461/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1579 - binary_accuracy: 0.9202 - val_loss: 3.9100 - val_binary_accuracy: 0.7707\n",
      "Epoch 462/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1982 - binary_accuracy: 0.9148 - val_loss: 2.4159 - val_binary_accuracy: 0.7513\n",
      "Epoch 463/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1619 - binary_accuracy: 0.9227 - val_loss: 3.2735 - val_binary_accuracy: 0.7620\n",
      "Epoch 464/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1605 - binary_accuracy: 0.9247 - val_loss: 2.7608 - val_binary_accuracy: 0.7577\n",
      "Epoch 465/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1433 - binary_accuracy: 0.9268 - val_loss: 2.9803 - val_binary_accuracy: 0.7563\n",
      "Epoch 466/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1459 - binary_accuracy: 0.9249 - val_loss: 3.0701 - val_binary_accuracy: 0.7563\n",
      "Epoch 467/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1412 - binary_accuracy: 0.9240 - val_loss: 3.1341 - val_binary_accuracy: 0.7664\n",
      "Epoch 468/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1413 - binary_accuracy: 0.9267 - val_loss: 2.9641 - val_binary_accuracy: 0.7613\n",
      "Epoch 469/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1400 - binary_accuracy: 0.9274 - val_loss: 3.1515 - val_binary_accuracy: 0.7692\n",
      "Epoch 470/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1444 - binary_accuracy: 0.9240 - val_loss: 3.1623 - val_binary_accuracy: 0.7656\n",
      "Epoch 471/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1405 - binary_accuracy: 0.9267 - val_loss: 3.3504 - val_binary_accuracy: 0.7664\n",
      "Epoch 472/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1398 - binary_accuracy: 0.9263 - val_loss: 3.2356 - val_binary_accuracy: 0.7635\n",
      "Epoch 473/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1379 - binary_accuracy: 0.9274 - val_loss: 3.1668 - val_binary_accuracy: 0.7613\n",
      "Epoch 474/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1409 - binary_accuracy: 0.9259 - val_loss: 3.3553 - val_binary_accuracy: 0.7656\n",
      "Epoch 475/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1420 - binary_accuracy: 0.9279 - val_loss: 3.3297 - val_binary_accuracy: 0.7642\n",
      "Epoch 476/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1396 - binary_accuracy: 0.9268 - val_loss: 3.3509 - val_binary_accuracy: 0.7628\n",
      "Epoch 477/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1531 - binary_accuracy: 0.9220 - val_loss: 2.9757 - val_binary_accuracy: 0.7685\n",
      "Epoch 478/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1672 - binary_accuracy: 0.9182 - val_loss: 3.3095 - val_binary_accuracy: 0.7599\n",
      "Epoch 479/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1444 - binary_accuracy: 0.9254 - val_loss: 3.4092 - val_binary_accuracy: 0.7642\n",
      "Epoch 480/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1432 - binary_accuracy: 0.9238 - val_loss: 3.3463 - val_binary_accuracy: 0.7628\n",
      "Epoch 481/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1465 - binary_accuracy: 0.9254 - val_loss: 3.3270 - val_binary_accuracy: 0.7642\n",
      "Epoch 482/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1541 - binary_accuracy: 0.9213 - val_loss: 3.3198 - val_binary_accuracy: 0.7656\n",
      "Epoch 483/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1458 - binary_accuracy: 0.9256 - val_loss: 3.1690 - val_binary_accuracy: 0.7678\n",
      "Epoch 484/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1419 - binary_accuracy: 0.9267 - val_loss: 3.3281 - val_binary_accuracy: 0.7685\n",
      "Epoch 485/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1519 - binary_accuracy: 0.9229 - val_loss: 3.1944 - val_binary_accuracy: 0.7628\n",
      "Epoch 486/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1493 - binary_accuracy: 0.9236 - val_loss: 3.4071 - val_binary_accuracy: 0.7599\n",
      "Epoch 487/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1721 - binary_accuracy: 0.9220 - val_loss: 3.1611 - val_binary_accuracy: 0.7649\n",
      "Epoch 488/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1474 - binary_accuracy: 0.9240 - val_loss: 3.2424 - val_binary_accuracy: 0.7642\n",
      "Epoch 489/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1419 - binary_accuracy: 0.9272 - val_loss: 3.1235 - val_binary_accuracy: 0.7563\n",
      "Epoch 490/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1417 - binary_accuracy: 0.9265 - val_loss: 3.3149 - val_binary_accuracy: 0.7613\n",
      "Epoch 491/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1383 - binary_accuracy: 0.9270 - val_loss: 3.4199 - val_binary_accuracy: 0.7620\n",
      "Epoch 492/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1481 - binary_accuracy: 0.9229 - val_loss: 3.2740 - val_binary_accuracy: 0.7527\n",
      "Epoch 493/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1412 - binary_accuracy: 0.9267 - val_loss: 3.4105 - val_binary_accuracy: 0.7599\n",
      "Epoch 494/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1392 - binary_accuracy: 0.9276 - val_loss: 3.3838 - val_binary_accuracy: 0.7649\n",
      "Epoch 495/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1396 - binary_accuracy: 0.9288 - val_loss: 3.5198 - val_binary_accuracy: 0.7613\n",
      "Epoch 496/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1476 - binary_accuracy: 0.9261 - val_loss: 3.4952 - val_binary_accuracy: 0.7635\n",
      "Epoch 497/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1662 - binary_accuracy: 0.9196 - val_loss: 3.1696 - val_binary_accuracy: 0.7678\n",
      "Epoch 498/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1621 - binary_accuracy: 0.9179 - val_loss: 3.3284 - val_binary_accuracy: 0.7584\n",
      "Epoch 499/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1498 - binary_accuracy: 0.9240 - val_loss: 3.3211 - val_binary_accuracy: 0.7592\n",
      "Epoch 500/500\n",
      "174/174 [==============================] - 1s 5ms/step - loss: 0.1383 - binary_accuracy: 0.9295 - val_loss: 3.3512 - val_binary_accuracy: 0.7527\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.Sequential([\n",
    "    # the hidden ReLU layers\n",
    "    layers.Dense(units=529, activation='relu', input_shape=[23]),\n",
    "    layers.Dense(units=529, activation='relu'),\n",
    "    layers.Dense(units=529, activation='relu'),\n",
    "    # the linear output layer \n",
    "    layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model_2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "history=model_2.fit(x_1train,y_1train,epochs=500,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce63abe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458214</td>\n",
       "      <td>0.768291</td>\n",
       "      <td>0.421989</td>\n",
       "      <td>0.795111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.418166</td>\n",
       "      <td>0.801186</td>\n",
       "      <td>0.416909</td>\n",
       "      <td>0.797987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.405664</td>\n",
       "      <td>0.805321</td>\n",
       "      <td>0.405969</td>\n",
       "      <td>0.808052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402104</td>\n",
       "      <td>0.806220</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.799425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.396039</td>\n",
       "      <td>0.808017</td>\n",
       "      <td>0.407356</td>\n",
       "      <td>0.801582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.147626</td>\n",
       "      <td>0.926119</td>\n",
       "      <td>3.495169</td>\n",
       "      <td>0.763480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.166214</td>\n",
       "      <td>0.919648</td>\n",
       "      <td>3.169578</td>\n",
       "      <td>0.767793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.162055</td>\n",
       "      <td>0.917850</td>\n",
       "      <td>3.328415</td>\n",
       "      <td>0.758447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.149832</td>\n",
       "      <td>0.923962</td>\n",
       "      <td>3.321121</td>\n",
       "      <td>0.759166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.138334</td>\n",
       "      <td>0.929534</td>\n",
       "      <td>3.351153</td>\n",
       "      <td>0.752696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0    0.458214         0.768291  0.421989             0.795111\n",
       "1    0.418166         0.801186  0.416909             0.797987\n",
       "2    0.405664         0.805321  0.405969             0.808052\n",
       "3    0.402104         0.806220  0.406737             0.799425\n",
       "4    0.396039         0.808017  0.407356             0.801582\n",
       "..        ...              ...       ...                  ...\n",
       "495  0.147626         0.926119  3.495169             0.763480\n",
       "496  0.166214         0.919648  3.169578             0.767793\n",
       "497  0.162055         0.917850  3.328415             0.758447\n",
       "498  0.149832         0.923962  3.321121             0.759166\n",
       "499  0.138334         0.929534  3.351153             0.752696\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb39662e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df['binary_accuracy'].plot()\n",
    "history_df['val_binary_accuracy'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "71552516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.5796 - binary_accuracy: 0.7108 - val_loss: 0.4954 - val_binary_accuracy: 0.7656\n",
      "Epoch 2/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4709 - binary_accuracy: 0.7730 - val_loss: 0.4463 - val_binary_accuracy: 0.7951\n",
      "Epoch 3/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4383 - binary_accuracy: 0.7949 - val_loss: 0.4288 - val_binary_accuracy: 0.7994\n",
      "Epoch 4/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4223 - binary_accuracy: 0.8035 - val_loss: 0.4225 - val_binary_accuracy: 0.8037\n",
      "Epoch 5/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4140 - binary_accuracy: 0.8059 - val_loss: 0.4161 - val_binary_accuracy: 0.8037\n",
      "Epoch 6/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4101 - binary_accuracy: 0.8050 - val_loss: 0.4120 - val_binary_accuracy: 0.8073\n",
      "Epoch 7/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4066 - binary_accuracy: 0.8084 - val_loss: 0.4138 - val_binary_accuracy: 0.8066\n",
      "Epoch 8/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4046 - binary_accuracy: 0.8057 - val_loss: 0.4112 - val_binary_accuracy: 0.8059\n",
      "Epoch 9/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4018 - binary_accuracy: 0.8084 - val_loss: 0.4099 - val_binary_accuracy: 0.8095\n",
      "Epoch 10/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3999 - binary_accuracy: 0.8075 - val_loss: 0.4081 - val_binary_accuracy: 0.8073\n",
      "Epoch 11/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3980 - binary_accuracy: 0.8109 - val_loss: 0.4078 - val_binary_accuracy: 0.7987\n",
      "Epoch 12/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3974 - binary_accuracy: 0.8078 - val_loss: 0.4068 - val_binary_accuracy: 0.8066\n",
      "Epoch 13/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3956 - binary_accuracy: 0.8082 - val_loss: 0.4065 - val_binary_accuracy: 0.8059\n",
      "Epoch 14/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3951 - binary_accuracy: 0.8093 - val_loss: 0.4055 - val_binary_accuracy: 0.8102\n",
      "Epoch 15/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3934 - binary_accuracy: 0.8093 - val_loss: 0.4085 - val_binary_accuracy: 0.8066\n",
      "Epoch 16/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3917 - binary_accuracy: 0.8102 - val_loss: 0.4089 - val_binary_accuracy: 0.8052\n",
      "Epoch 17/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3904 - binary_accuracy: 0.8102 - val_loss: 0.4081 - val_binary_accuracy: 0.8073\n",
      "Epoch 18/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3900 - binary_accuracy: 0.8109 - val_loss: 0.4063 - val_binary_accuracy: 0.8081\n",
      "Epoch 19/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3883 - binary_accuracy: 0.8120 - val_loss: 0.4071 - val_binary_accuracy: 0.8095\n",
      "Epoch 20/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3881 - binary_accuracy: 0.8114 - val_loss: 0.4073 - val_binary_accuracy: 0.8030\n",
      "Epoch 21/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3875 - binary_accuracy: 0.8131 - val_loss: 0.4039 - val_binary_accuracy: 0.8059\n",
      "Epoch 22/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3859 - binary_accuracy: 0.8152 - val_loss: 0.4085 - val_binary_accuracy: 0.8052\n",
      "Epoch 23/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3854 - binary_accuracy: 0.8141 - val_loss: 0.4030 - val_binary_accuracy: 0.8109\n",
      "Epoch 24/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3850 - binary_accuracy: 0.8131 - val_loss: 0.4063 - val_binary_accuracy: 0.8109\n",
      "Epoch 25/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3843 - binary_accuracy: 0.8150 - val_loss: 0.4052 - val_binary_accuracy: 0.8045\n",
      "Epoch 26/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3833 - binary_accuracy: 0.8157 - val_loss: 0.4075 - val_binary_accuracy: 0.8066\n",
      "Epoch 27/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3829 - binary_accuracy: 0.8188 - val_loss: 0.4077 - val_binary_accuracy: 0.8059\n",
      "Epoch 28/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3819 - binary_accuracy: 0.8170 - val_loss: 0.4073 - val_binary_accuracy: 0.8037\n",
      "Epoch 29/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3804 - binary_accuracy: 0.8166 - val_loss: 0.4043 - val_binary_accuracy: 0.8109\n",
      "Epoch 30/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3806 - binary_accuracy: 0.8148 - val_loss: 0.4060 - val_binary_accuracy: 0.8059\n",
      "Epoch 31/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3797 - binary_accuracy: 0.8174 - val_loss: 0.4057 - val_binary_accuracy: 0.8009\n",
      "Epoch 32/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3795 - binary_accuracy: 0.8148 - val_loss: 0.4075 - val_binary_accuracy: 0.8073\n",
      "Epoch 33/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3808 - binary_accuracy: 0.8177 - val_loss: 0.4045 - val_binary_accuracy: 0.8059\n",
      "Epoch 34/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3786 - binary_accuracy: 0.8159 - val_loss: 0.4084 - val_binary_accuracy: 0.8081\n",
      "Epoch 35/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3782 - binary_accuracy: 0.8183 - val_loss: 0.4057 - val_binary_accuracy: 0.8088\n",
      "Epoch 36/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3768 - binary_accuracy: 0.8181 - val_loss: 0.4078 - val_binary_accuracy: 0.8045\n",
      "Epoch 37/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3768 - binary_accuracy: 0.8192 - val_loss: 0.4062 - val_binary_accuracy: 0.8059\n",
      "Epoch 38/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3775 - binary_accuracy: 0.8197 - val_loss: 0.4059 - val_binary_accuracy: 0.8081\n",
      "Epoch 39/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3761 - binary_accuracy: 0.8201 - val_loss: 0.4083 - val_binary_accuracy: 0.8052\n",
      "Epoch 40/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3757 - binary_accuracy: 0.8186 - val_loss: 0.4093 - val_binary_accuracy: 0.8066\n",
      "Epoch 41/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3746 - binary_accuracy: 0.8228 - val_loss: 0.4098 - val_binary_accuracy: 0.8001\n",
      "Epoch 42/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3751 - binary_accuracy: 0.8217 - val_loss: 0.4101 - val_binary_accuracy: 0.8059\n",
      "Epoch 43/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3739 - binary_accuracy: 0.8201 - val_loss: 0.4086 - val_binary_accuracy: 0.8073\n",
      "Epoch 44/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3734 - binary_accuracy: 0.8208 - val_loss: 0.4087 - val_binary_accuracy: 0.8109\n",
      "Epoch 45/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3737 - binary_accuracy: 0.8193 - val_loss: 0.4116 - val_binary_accuracy: 0.8059\n",
      "Epoch 46/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3726 - binary_accuracy: 0.8237 - val_loss: 0.4098 - val_binary_accuracy: 0.8066\n",
      "Epoch 47/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3709 - binary_accuracy: 0.8255 - val_loss: 0.4121 - val_binary_accuracy: 0.8023\n",
      "Epoch 48/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3708 - binary_accuracy: 0.8233 - val_loss: 0.4126 - val_binary_accuracy: 0.8016\n",
      "Epoch 49/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3716 - binary_accuracy: 0.8215 - val_loss: 0.4132 - val_binary_accuracy: 0.8045\n",
      "Epoch 50/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3720 - binary_accuracy: 0.8184 - val_loss: 0.4097 - val_binary_accuracy: 0.8037\n",
      "Epoch 51/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3702 - binary_accuracy: 0.8210 - val_loss: 0.4117 - val_binary_accuracy: 0.8073\n",
      "Epoch 52/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3694 - binary_accuracy: 0.8233 - val_loss: 0.4104 - val_binary_accuracy: 0.8073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3693 - binary_accuracy: 0.8208 - val_loss: 0.4109 - val_binary_accuracy: 0.8030\n",
      "Epoch 54/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3692 - binary_accuracy: 0.8226 - val_loss: 0.4131 - val_binary_accuracy: 0.8045\n",
      "Epoch 55/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3686 - binary_accuracy: 0.8222 - val_loss: 0.4150 - val_binary_accuracy: 0.8081\n",
      "Epoch 56/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3690 - binary_accuracy: 0.8222 - val_loss: 0.4121 - val_binary_accuracy: 0.8016\n",
      "Epoch 57/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3681 - binary_accuracy: 0.8195 - val_loss: 0.4173 - val_binary_accuracy: 0.8045\n",
      "Epoch 58/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3688 - binary_accuracy: 0.8208 - val_loss: 0.4155 - val_binary_accuracy: 0.8073\n",
      "Epoch 59/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3672 - binary_accuracy: 0.8260 - val_loss: 0.4150 - val_binary_accuracy: 0.8052\n",
      "Epoch 60/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3663 - binary_accuracy: 0.8238 - val_loss: 0.4118 - val_binary_accuracy: 0.8030\n",
      "Epoch 61/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3655 - binary_accuracy: 0.8228 - val_loss: 0.4138 - val_binary_accuracy: 0.8059\n",
      "Epoch 62/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3661 - binary_accuracy: 0.8235 - val_loss: 0.4117 - val_binary_accuracy: 0.8109\n",
      "Epoch 63/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3651 - binary_accuracy: 0.8238 - val_loss: 0.4126 - val_binary_accuracy: 0.8030\n",
      "Epoch 64/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3658 - binary_accuracy: 0.8278 - val_loss: 0.4177 - val_binary_accuracy: 0.8023\n",
      "Epoch 65/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3646 - binary_accuracy: 0.8260 - val_loss: 0.4127 - val_binary_accuracy: 0.8073\n",
      "Epoch 66/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3644 - binary_accuracy: 0.8244 - val_loss: 0.4159 - val_binary_accuracy: 0.8045\n",
      "Epoch 67/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3633 - binary_accuracy: 0.8274 - val_loss: 0.4181 - val_binary_accuracy: 0.8109\n",
      "Epoch 68/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3636 - binary_accuracy: 0.8195 - val_loss: 0.4214 - val_binary_accuracy: 0.8037\n",
      "Epoch 69/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3636 - binary_accuracy: 0.8237 - val_loss: 0.4154 - val_binary_accuracy: 0.8030\n",
      "Epoch 70/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3632 - binary_accuracy: 0.8251 - val_loss: 0.4156 - val_binary_accuracy: 0.8045\n",
      "Epoch 71/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3639 - binary_accuracy: 0.8240 - val_loss: 0.4190 - val_binary_accuracy: 0.7994\n",
      "Epoch 72/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3632 - binary_accuracy: 0.8264 - val_loss: 0.4137 - val_binary_accuracy: 0.8088\n",
      "Epoch 73/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3614 - binary_accuracy: 0.8233 - val_loss: 0.4212 - val_binary_accuracy: 0.8037\n",
      "Epoch 74/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3624 - binary_accuracy: 0.8238 - val_loss: 0.4188 - val_binary_accuracy: 0.8030\n",
      "Epoch 75/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3613 - binary_accuracy: 0.8271 - val_loss: 0.4180 - val_binary_accuracy: 0.8081\n",
      "Epoch 76/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3617 - binary_accuracy: 0.8287 - val_loss: 0.4214 - val_binary_accuracy: 0.8030\n",
      "Epoch 77/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3609 - binary_accuracy: 0.8251 - val_loss: 0.4174 - val_binary_accuracy: 0.8016\n",
      "Epoch 78/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3602 - binary_accuracy: 0.8283 - val_loss: 0.4175 - val_binary_accuracy: 0.8023\n",
      "Epoch 79/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3592 - binary_accuracy: 0.8260 - val_loss: 0.4194 - val_binary_accuracy: 0.8009\n",
      "Epoch 80/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3598 - binary_accuracy: 0.8265 - val_loss: 0.4191 - val_binary_accuracy: 0.8045\n",
      "Epoch 81/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3599 - binary_accuracy: 0.8274 - val_loss: 0.4199 - val_binary_accuracy: 0.8001\n",
      "Epoch 82/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3601 - binary_accuracy: 0.8276 - val_loss: 0.4200 - val_binary_accuracy: 0.8016\n",
      "Epoch 83/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3589 - binary_accuracy: 0.8233 - val_loss: 0.4226 - val_binary_accuracy: 0.8059\n",
      "Epoch 84/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8282 - val_loss: 0.4218 - val_binary_accuracy: 0.8073\n",
      "Epoch 85/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8274 - val_loss: 0.4184 - val_binary_accuracy: 0.7994\n",
      "Epoch 86/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3580 - binary_accuracy: 0.8287 - val_loss: 0.4200 - val_binary_accuracy: 0.8088\n",
      "Epoch 87/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3576 - binary_accuracy: 0.8256 - val_loss: 0.4217 - val_binary_accuracy: 0.8073\n",
      "Epoch 88/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8280 - val_loss: 0.4195 - val_binary_accuracy: 0.8023\n",
      "Epoch 89/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3574 - binary_accuracy: 0.8249 - val_loss: 0.4236 - val_binary_accuracy: 0.7994\n",
      "Epoch 90/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3569 - binary_accuracy: 0.8278 - val_loss: 0.4233 - val_binary_accuracy: 0.8030\n",
      "Epoch 91/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3568 - binary_accuracy: 0.8280 - val_loss: 0.4256 - val_binary_accuracy: 0.8037\n",
      "Epoch 92/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3565 - binary_accuracy: 0.8303 - val_loss: 0.4262 - val_binary_accuracy: 0.8030\n",
      "Epoch 93/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3568 - binary_accuracy: 0.8237 - val_loss: 0.4223 - val_binary_accuracy: 0.8037\n",
      "Epoch 94/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3563 - binary_accuracy: 0.8255 - val_loss: 0.4254 - val_binary_accuracy: 0.8023\n",
      "Epoch 95/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3553 - binary_accuracy: 0.8296 - val_loss: 0.4288 - val_binary_accuracy: 0.8045\n",
      "Epoch 96/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3572 - binary_accuracy: 0.8258 - val_loss: 0.4213 - val_binary_accuracy: 0.8052\n",
      "Epoch 97/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3551 - binary_accuracy: 0.8280 - val_loss: 0.4234 - val_binary_accuracy: 0.8045\n",
      "Epoch 98/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3542 - binary_accuracy: 0.8274 - val_loss: 0.4248 - val_binary_accuracy: 0.8059\n",
      "Epoch 99/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3543 - binary_accuracy: 0.8260 - val_loss: 0.4235 - val_binary_accuracy: 0.8081\n",
      "Epoch 100/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3542 - binary_accuracy: 0.8330 - val_loss: 0.4271 - val_binary_accuracy: 0.8037\n",
      "Epoch 101/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3541 - binary_accuracy: 0.8282 - val_loss: 0.4301 - val_binary_accuracy: 0.8059\n",
      "Epoch 102/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3540 - binary_accuracy: 0.8287 - val_loss: 0.4321 - val_binary_accuracy: 0.8037\n",
      "Epoch 103/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3542 - binary_accuracy: 0.8260 - val_loss: 0.4247 - val_binary_accuracy: 0.8045\n",
      "Epoch 104/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3526 - binary_accuracy: 0.8328 - val_loss: 0.4319 - val_binary_accuracy: 0.8030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3525 - binary_accuracy: 0.8299 - val_loss: 0.4229 - val_binary_accuracy: 0.8045\n",
      "Epoch 106/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3527 - binary_accuracy: 0.8301 - val_loss: 0.4317 - val_binary_accuracy: 0.8066\n",
      "Epoch 107/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3539 - binary_accuracy: 0.8260 - val_loss: 0.4311 - val_binary_accuracy: 0.8052\n",
      "Epoch 108/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3531 - binary_accuracy: 0.8278 - val_loss: 0.4277 - val_binary_accuracy: 0.8009\n",
      "Epoch 109/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3522 - binary_accuracy: 0.8325 - val_loss: 0.4328 - val_binary_accuracy: 0.8052\n",
      "Epoch 110/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3527 - binary_accuracy: 0.8296 - val_loss: 0.4283 - val_binary_accuracy: 0.8052\n",
      "Epoch 111/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3530 - binary_accuracy: 0.8271 - val_loss: 0.4283 - val_binary_accuracy: 0.8023\n",
      "Epoch 112/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3515 - binary_accuracy: 0.8292 - val_loss: 0.4262 - val_binary_accuracy: 0.8016\n",
      "Epoch 113/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3506 - binary_accuracy: 0.8301 - val_loss: 0.4289 - val_binary_accuracy: 0.8045\n",
      "Epoch 114/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3512 - binary_accuracy: 0.8292 - val_loss: 0.4278 - val_binary_accuracy: 0.8023\n",
      "Epoch 115/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3518 - binary_accuracy: 0.8310 - val_loss: 0.4306 - val_binary_accuracy: 0.8037\n",
      "Epoch 116/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3510 - binary_accuracy: 0.8278 - val_loss: 0.4260 - val_binary_accuracy: 0.8023\n",
      "Epoch 117/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3510 - binary_accuracy: 0.8273 - val_loss: 0.4298 - val_binary_accuracy: 0.8045\n",
      "Epoch 118/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3500 - binary_accuracy: 0.8337 - val_loss: 0.4372 - val_binary_accuracy: 0.8030\n",
      "Epoch 119/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3507 - binary_accuracy: 0.8310 - val_loss: 0.4316 - val_binary_accuracy: 0.8066\n",
      "Epoch 120/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3507 - binary_accuracy: 0.8308 - val_loss: 0.4342 - val_binary_accuracy: 0.8016\n",
      "Epoch 121/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3499 - binary_accuracy: 0.8317 - val_loss: 0.4312 - val_binary_accuracy: 0.8088\n",
      "Epoch 122/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3504 - binary_accuracy: 0.8287 - val_loss: 0.4338 - val_binary_accuracy: 0.8016\n",
      "Epoch 123/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3508 - binary_accuracy: 0.8292 - val_loss: 0.4279 - val_binary_accuracy: 0.8059\n",
      "Epoch 124/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3489 - binary_accuracy: 0.8290 - val_loss: 0.4292 - val_binary_accuracy: 0.8045\n",
      "Epoch 125/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3499 - binary_accuracy: 0.8290 - val_loss: 0.4352 - val_binary_accuracy: 0.8059\n",
      "Epoch 126/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3484 - binary_accuracy: 0.8321 - val_loss: 0.4333 - val_binary_accuracy: 0.8045\n",
      "Epoch 127/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3493 - binary_accuracy: 0.8298 - val_loss: 0.4375 - val_binary_accuracy: 0.7937\n",
      "Epoch 128/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3470 - binary_accuracy: 0.8326 - val_loss: 0.4434 - val_binary_accuracy: 0.8030\n",
      "Epoch 129/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3486 - binary_accuracy: 0.8282 - val_loss: 0.4337 - val_binary_accuracy: 0.8030\n",
      "Epoch 130/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3480 - binary_accuracy: 0.8314 - val_loss: 0.4376 - val_binary_accuracy: 0.8052\n",
      "Epoch 131/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3469 - binary_accuracy: 0.8326 - val_loss: 0.4354 - val_binary_accuracy: 0.8037\n",
      "Epoch 132/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3473 - binary_accuracy: 0.8335 - val_loss: 0.4369 - val_binary_accuracy: 0.8016\n",
      "Epoch 133/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3479 - binary_accuracy: 0.8303 - val_loss: 0.4387 - val_binary_accuracy: 0.7980\n",
      "Epoch 134/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3458 - binary_accuracy: 0.8326 - val_loss: 0.4390 - val_binary_accuracy: 0.8016\n",
      "Epoch 135/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3473 - binary_accuracy: 0.8323 - val_loss: 0.4452 - val_binary_accuracy: 0.8030\n",
      "Epoch 136/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3486 - binary_accuracy: 0.8299 - val_loss: 0.4364 - val_binary_accuracy: 0.8030\n",
      "Epoch 137/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3450 - binary_accuracy: 0.8339 - val_loss: 0.4422 - val_binary_accuracy: 0.7987\n",
      "Epoch 138/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3445 - binary_accuracy: 0.8355 - val_loss: 0.4350 - val_binary_accuracy: 0.8016\n",
      "Epoch 139/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3452 - binary_accuracy: 0.8296 - val_loss: 0.4401 - val_binary_accuracy: 0.8045\n",
      "Epoch 140/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3460 - binary_accuracy: 0.8317 - val_loss: 0.4424 - val_binary_accuracy: 0.8009\n",
      "Epoch 141/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3455 - binary_accuracy: 0.8343 - val_loss: 0.4390 - val_binary_accuracy: 0.8030\n",
      "Epoch 142/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3443 - binary_accuracy: 0.8353 - val_loss: 0.4391 - val_binary_accuracy: 0.8052\n",
      "Epoch 143/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3459 - binary_accuracy: 0.8307 - val_loss: 0.4393 - val_binary_accuracy: 0.8030\n",
      "Epoch 144/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3442 - binary_accuracy: 0.8352 - val_loss: 0.4451 - val_binary_accuracy: 0.8037\n",
      "Epoch 145/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3451 - binary_accuracy: 0.8303 - val_loss: 0.4390 - val_binary_accuracy: 0.7987\n",
      "Epoch 146/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3444 - binary_accuracy: 0.8323 - val_loss: 0.4424 - val_binary_accuracy: 0.7980\n",
      "Epoch 147/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3436 - binary_accuracy: 0.8337 - val_loss: 0.4421 - val_binary_accuracy: 0.7965\n",
      "Epoch 148/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3444 - binary_accuracy: 0.8312 - val_loss: 0.4437 - val_binary_accuracy: 0.8009\n",
      "Epoch 149/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3431 - binary_accuracy: 0.8339 - val_loss: 0.4469 - val_binary_accuracy: 0.7980\n",
      "Epoch 150/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3429 - binary_accuracy: 0.8325 - val_loss: 0.4447 - val_binary_accuracy: 0.7987\n",
      "Epoch 151/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3431 - binary_accuracy: 0.8326 - val_loss: 0.4451 - val_binary_accuracy: 0.8009\n",
      "Epoch 152/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3421 - binary_accuracy: 0.8379 - val_loss: 0.4452 - val_binary_accuracy: 0.7980\n",
      "Epoch 153/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3427 - binary_accuracy: 0.8341 - val_loss: 0.4465 - val_binary_accuracy: 0.7980\n",
      "Epoch 154/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3423 - binary_accuracy: 0.8344 - val_loss: 0.4485 - val_binary_accuracy: 0.8009\n",
      "Epoch 155/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3435 - binary_accuracy: 0.8310 - val_loss: 0.4460 - val_binary_accuracy: 0.8009\n",
      "Epoch 156/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3409 - binary_accuracy: 0.8355 - val_loss: 0.4496 - val_binary_accuracy: 0.8009\n",
      "Epoch 157/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3415 - binary_accuracy: 0.8352 - val_loss: 0.4457 - val_binary_accuracy: 0.7994\n",
      "Epoch 158/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3430 - binary_accuracy: 0.8321 - val_loss: 0.4458 - val_binary_accuracy: 0.8009\n",
      "Epoch 159/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3405 - binary_accuracy: 0.8355 - val_loss: 0.4519 - val_binary_accuracy: 0.7994\n",
      "Epoch 160/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3408 - binary_accuracy: 0.8353 - val_loss: 0.4440 - val_binary_accuracy: 0.8023\n",
      "Epoch 161/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3410 - binary_accuracy: 0.8337 - val_loss: 0.4516 - val_binary_accuracy: 0.7951\n",
      "Epoch 162/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3411 - binary_accuracy: 0.8353 - val_loss: 0.4509 - val_binary_accuracy: 0.7994\n",
      "Epoch 163/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3402 - binary_accuracy: 0.8364 - val_loss: 0.4483 - val_binary_accuracy: 0.8037\n",
      "Epoch 164/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3409 - binary_accuracy: 0.8344 - val_loss: 0.4473 - val_binary_accuracy: 0.7951\n",
      "Epoch 165/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3396 - binary_accuracy: 0.8357 - val_loss: 0.4492 - val_binary_accuracy: 0.8001\n",
      "Epoch 166/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3388 - binary_accuracy: 0.8359 - val_loss: 0.4482 - val_binary_accuracy: 0.7958\n",
      "Epoch 167/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3402 - binary_accuracy: 0.8353 - val_loss: 0.4539 - val_binary_accuracy: 0.7951\n",
      "Epoch 168/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3405 - binary_accuracy: 0.8343 - val_loss: 0.4527 - val_binary_accuracy: 0.7987\n",
      "Epoch 169/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3406 - binary_accuracy: 0.8344 - val_loss: 0.4508 - val_binary_accuracy: 0.7980\n",
      "Epoch 170/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3387 - binary_accuracy: 0.8364 - val_loss: 0.4504 - val_binary_accuracy: 0.8001\n",
      "Epoch 171/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3397 - binary_accuracy: 0.8343 - val_loss: 0.4467 - val_binary_accuracy: 0.7937\n",
      "Epoch 172/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3384 - binary_accuracy: 0.8343 - val_loss: 0.4566 - val_binary_accuracy: 0.7944\n",
      "Epoch 173/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3376 - binary_accuracy: 0.8379 - val_loss: 0.4529 - val_binary_accuracy: 0.7951\n",
      "Epoch 174/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3399 - binary_accuracy: 0.8355 - val_loss: 0.4522 - val_binary_accuracy: 0.7980\n",
      "Epoch 175/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3384 - binary_accuracy: 0.8355 - val_loss: 0.4492 - val_binary_accuracy: 0.7994\n",
      "Epoch 176/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3381 - binary_accuracy: 0.8400 - val_loss: 0.4573 - val_binary_accuracy: 0.7973\n",
      "Epoch 177/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3376 - binary_accuracy: 0.8389 - val_loss: 0.4522 - val_binary_accuracy: 0.8016\n",
      "Epoch 178/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3380 - binary_accuracy: 0.8362 - val_loss: 0.4597 - val_binary_accuracy: 0.8023\n",
      "Epoch 179/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3380 - binary_accuracy: 0.8346 - val_loss: 0.4546 - val_binary_accuracy: 0.7958\n",
      "Epoch 180/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3376 - binary_accuracy: 0.8379 - val_loss: 0.4529 - val_binary_accuracy: 0.7987\n",
      "Epoch 181/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3378 - binary_accuracy: 0.8355 - val_loss: 0.4603 - val_binary_accuracy: 0.8016\n",
      "Epoch 182/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3383 - binary_accuracy: 0.8371 - val_loss: 0.4588 - val_binary_accuracy: 0.8009\n",
      "Epoch 183/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3368 - binary_accuracy: 0.8366 - val_loss: 0.4599 - val_binary_accuracy: 0.7973\n",
      "Epoch 184/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3371 - binary_accuracy: 0.8395 - val_loss: 0.4577 - val_binary_accuracy: 0.7980\n",
      "Epoch 185/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3357 - binary_accuracy: 0.8373 - val_loss: 0.4673 - val_binary_accuracy: 0.7872\n",
      "Epoch 186/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3350 - binary_accuracy: 0.8388 - val_loss: 0.4577 - val_binary_accuracy: 0.7987\n",
      "Epoch 187/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3364 - binary_accuracy: 0.8391 - val_loss: 0.4609 - val_binary_accuracy: 0.7908\n",
      "Epoch 188/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3362 - binary_accuracy: 0.8380 - val_loss: 0.4588 - val_binary_accuracy: 0.7944\n",
      "Epoch 189/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3350 - binary_accuracy: 0.8391 - val_loss: 0.4588 - val_binary_accuracy: 0.7987\n",
      "Epoch 190/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3360 - binary_accuracy: 0.8361 - val_loss: 0.4641 - val_binary_accuracy: 0.7944\n",
      "Epoch 191/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3349 - binary_accuracy: 0.8377 - val_loss: 0.4647 - val_binary_accuracy: 0.7951\n",
      "Epoch 192/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3354 - binary_accuracy: 0.8386 - val_loss: 0.4657 - val_binary_accuracy: 0.7958\n",
      "Epoch 193/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3339 - binary_accuracy: 0.8371 - val_loss: 0.4643 - val_binary_accuracy: 0.8016\n",
      "Epoch 194/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3362 - binary_accuracy: 0.8350 - val_loss: 0.4599 - val_binary_accuracy: 0.7987\n",
      "Epoch 195/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3334 - binary_accuracy: 0.8411 - val_loss: 0.4641 - val_binary_accuracy: 0.7944\n",
      "Epoch 196/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3350 - binary_accuracy: 0.8388 - val_loss: 0.4685 - val_binary_accuracy: 0.7937\n",
      "Epoch 197/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3342 - binary_accuracy: 0.8388 - val_loss: 0.4696 - val_binary_accuracy: 0.7958\n",
      "Epoch 198/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3351 - binary_accuracy: 0.8388 - val_loss: 0.4696 - val_binary_accuracy: 0.8001\n",
      "Epoch 199/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3333 - binary_accuracy: 0.8362 - val_loss: 0.4695 - val_binary_accuracy: 0.7973\n",
      "Epoch 200/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3351 - binary_accuracy: 0.8379 - val_loss: 0.4698 - val_binary_accuracy: 0.7951\n",
      "Epoch 201/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3338 - binary_accuracy: 0.8386 - val_loss: 0.4692 - val_binary_accuracy: 0.7958\n",
      "Epoch 202/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3340 - binary_accuracy: 0.8370 - val_loss: 0.4700 - val_binary_accuracy: 0.7915\n",
      "Epoch 203/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3329 - binary_accuracy: 0.8409 - val_loss: 0.4692 - val_binary_accuracy: 0.8023\n",
      "Epoch 204/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3342 - binary_accuracy: 0.8422 - val_loss: 0.4698 - val_binary_accuracy: 0.7958\n",
      "Epoch 205/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3327 - binary_accuracy: 0.8366 - val_loss: 0.4720 - val_binary_accuracy: 0.7973\n",
      "Epoch 206/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3330 - binary_accuracy: 0.8389 - val_loss: 0.4697 - val_binary_accuracy: 0.7951\n",
      "Epoch 207/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3333 - binary_accuracy: 0.8377 - val_loss: 0.4698 - val_binary_accuracy: 0.7994\n",
      "Epoch 208/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3332 - binary_accuracy: 0.8371 - val_loss: 0.4730 - val_binary_accuracy: 0.7980\n",
      "Epoch 209/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3329 - binary_accuracy: 0.8393 - val_loss: 0.4721 - val_binary_accuracy: 0.7944\n",
      "Epoch 210/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3337 - binary_accuracy: 0.8386 - val_loss: 0.4750 - val_binary_accuracy: 0.7937\n",
      "Epoch 211/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3329 - binary_accuracy: 0.8402 - val_loss: 0.4723 - val_binary_accuracy: 0.7930\n",
      "Epoch 212/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3326 - binary_accuracy: 0.8371 - val_loss: 0.4748 - val_binary_accuracy: 0.7922\n",
      "Epoch 213/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3318 - binary_accuracy: 0.8422 - val_loss: 0.4780 - val_binary_accuracy: 0.7922\n",
      "Epoch 214/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3312 - binary_accuracy: 0.8413 - val_loss: 0.4744 - val_binary_accuracy: 0.7937\n",
      "Epoch 215/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3329 - binary_accuracy: 0.8364 - val_loss: 0.4755 - val_binary_accuracy: 0.7980\n",
      "Epoch 216/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3313 - binary_accuracy: 0.8384 - val_loss: 0.4800 - val_binary_accuracy: 0.7958\n",
      "Epoch 217/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3327 - binary_accuracy: 0.8359 - val_loss: 0.4800 - val_binary_accuracy: 0.7965\n",
      "Epoch 218/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3310 - binary_accuracy: 0.8397 - val_loss: 0.4769 - val_binary_accuracy: 0.7980\n",
      "Epoch 219/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3321 - binary_accuracy: 0.8361 - val_loss: 0.4774 - val_binary_accuracy: 0.7980\n",
      "Epoch 220/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3296 - binary_accuracy: 0.8429 - val_loss: 0.4772 - val_binary_accuracy: 0.7987\n",
      "Epoch 221/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3298 - binary_accuracy: 0.8433 - val_loss: 0.4796 - val_binary_accuracy: 0.8023\n",
      "Epoch 222/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3318 - binary_accuracy: 0.8406 - val_loss: 0.4793 - val_binary_accuracy: 0.8001\n",
      "Epoch 223/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3316 - binary_accuracy: 0.8397 - val_loss: 0.4746 - val_binary_accuracy: 0.7958\n",
      "Epoch 224/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3300 - binary_accuracy: 0.8393 - val_loss: 0.4788 - val_binary_accuracy: 0.7915\n",
      "Epoch 225/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3312 - binary_accuracy: 0.8398 - val_loss: 0.4768 - val_binary_accuracy: 0.7915\n",
      "Epoch 226/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3299 - binary_accuracy: 0.8429 - val_loss: 0.4794 - val_binary_accuracy: 0.7987\n",
      "Epoch 227/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3308 - binary_accuracy: 0.8402 - val_loss: 0.4762 - val_binary_accuracy: 0.7944\n",
      "Epoch 228/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3294 - binary_accuracy: 0.8427 - val_loss: 0.4872 - val_binary_accuracy: 0.7951\n",
      "Epoch 229/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3309 - binary_accuracy: 0.8425 - val_loss: 0.4867 - val_binary_accuracy: 0.7930\n",
      "Epoch 230/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3306 - binary_accuracy: 0.8407 - val_loss: 0.4769 - val_binary_accuracy: 0.7965\n",
      "Epoch 231/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3298 - binary_accuracy: 0.8418 - val_loss: 0.4802 - val_binary_accuracy: 0.7951\n",
      "Epoch 232/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3298 - binary_accuracy: 0.8402 - val_loss: 0.4776 - val_binary_accuracy: 0.8009\n",
      "Epoch 233/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3287 - binary_accuracy: 0.8411 - val_loss: 0.4849 - val_binary_accuracy: 0.7944\n",
      "Epoch 234/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3296 - binary_accuracy: 0.8397 - val_loss: 0.4893 - val_binary_accuracy: 0.7915\n",
      "Epoch 235/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3275 - binary_accuracy: 0.8429 - val_loss: 0.4820 - val_binary_accuracy: 0.8009\n",
      "Epoch 236/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3284 - binary_accuracy: 0.8406 - val_loss: 0.4827 - val_binary_accuracy: 0.7922\n",
      "Epoch 237/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3303 - binary_accuracy: 0.8424 - val_loss: 0.4787 - val_binary_accuracy: 0.7937\n",
      "Epoch 238/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3287 - binary_accuracy: 0.8407 - val_loss: 0.4810 - val_binary_accuracy: 0.7944\n",
      "Epoch 239/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3277 - binary_accuracy: 0.8407 - val_loss: 0.4837 - val_binary_accuracy: 0.7958\n",
      "Epoch 240/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3274 - binary_accuracy: 0.8447 - val_loss: 0.4954 - val_binary_accuracy: 0.7908\n",
      "Epoch 241/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3288 - binary_accuracy: 0.8400 - val_loss: 0.4815 - val_binary_accuracy: 0.7951\n",
      "Epoch 242/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3261 - binary_accuracy: 0.8427 - val_loss: 0.4834 - val_binary_accuracy: 0.7980\n",
      "Epoch 243/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3279 - binary_accuracy: 0.8404 - val_loss: 0.4886 - val_binary_accuracy: 0.7958\n",
      "Epoch 244/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3281 - binary_accuracy: 0.8409 - val_loss: 0.4857 - val_binary_accuracy: 0.7915\n",
      "Epoch 245/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3264 - binary_accuracy: 0.8441 - val_loss: 0.4858 - val_binary_accuracy: 0.7922\n",
      "Epoch 246/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3276 - binary_accuracy: 0.8422 - val_loss: 0.4897 - val_binary_accuracy: 0.7973\n",
      "Epoch 247/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3283 - binary_accuracy: 0.8395 - val_loss: 0.4857 - val_binary_accuracy: 0.7965\n",
      "Epoch 248/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3268 - binary_accuracy: 0.8449 - val_loss: 0.4966 - val_binary_accuracy: 0.7944\n",
      "Epoch 249/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3261 - binary_accuracy: 0.8415 - val_loss: 0.4853 - val_binary_accuracy: 0.8016\n",
      "Epoch 250/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3264 - binary_accuracy: 0.8411 - val_loss: 0.4884 - val_binary_accuracy: 0.7944\n",
      "Epoch 251/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3267 - binary_accuracy: 0.8413 - val_loss: 0.4962 - val_binary_accuracy: 0.8023\n",
      "Epoch 252/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3256 - binary_accuracy: 0.8431 - val_loss: 0.4913 - val_binary_accuracy: 0.7944\n",
      "Epoch 253/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3266 - binary_accuracy: 0.8418 - val_loss: 0.4922 - val_binary_accuracy: 0.8001\n",
      "Epoch 254/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3275 - binary_accuracy: 0.8391 - val_loss: 0.4945 - val_binary_accuracy: 0.7980\n",
      "Epoch 255/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3269 - binary_accuracy: 0.8411 - val_loss: 0.4923 - val_binary_accuracy: 0.7886\n",
      "Epoch 256/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3264 - binary_accuracy: 0.8373 - val_loss: 0.4935 - val_binary_accuracy: 0.7915\n",
      "Epoch 257/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3251 - binary_accuracy: 0.8452 - val_loss: 0.5005 - val_binary_accuracy: 0.7908\n",
      "Epoch 258/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3251 - binary_accuracy: 0.8436 - val_loss: 0.4909 - val_binary_accuracy: 0.7958\n",
      "Epoch 259/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3252 - binary_accuracy: 0.8424 - val_loss: 0.5021 - val_binary_accuracy: 0.8009\n",
      "Epoch 260/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3253 - binary_accuracy: 0.8441 - val_loss: 0.4954 - val_binary_accuracy: 0.7958\n",
      "Epoch 261/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3256 - binary_accuracy: 0.8433 - val_loss: 0.4953 - val_binary_accuracy: 0.7944\n",
      "Epoch 262/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3250 - binary_accuracy: 0.8431 - val_loss: 0.4948 - val_binary_accuracy: 0.7973\n",
      "Epoch 263/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3251 - binary_accuracy: 0.8434 - val_loss: 0.4984 - val_binary_accuracy: 0.7915\n",
      "Epoch 264/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3253 - binary_accuracy: 0.8416 - val_loss: 0.4987 - val_binary_accuracy: 0.7908\n",
      "Epoch 265/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3241 - binary_accuracy: 0.8420 - val_loss: 0.4945 - val_binary_accuracy: 0.7908\n",
      "Epoch 266/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3249 - binary_accuracy: 0.8420 - val_loss: 0.5014 - val_binary_accuracy: 0.7944\n",
      "Epoch 267/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3239 - binary_accuracy: 0.8407 - val_loss: 0.4980 - val_binary_accuracy: 0.7987\n",
      "Epoch 268/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3232 - binary_accuracy: 0.8467 - val_loss: 0.4997 - val_binary_accuracy: 0.7872\n",
      "Epoch 269/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3238 - binary_accuracy: 0.8407 - val_loss: 0.4982 - val_binary_accuracy: 0.7937\n",
      "Epoch 270/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3247 - binary_accuracy: 0.8450 - val_loss: 0.5059 - val_binary_accuracy: 0.7922\n",
      "Epoch 271/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3233 - binary_accuracy: 0.8440 - val_loss: 0.5020 - val_binary_accuracy: 0.7915\n",
      "Epoch 272/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3240 - binary_accuracy: 0.8454 - val_loss: 0.5044 - val_binary_accuracy: 0.7965\n",
      "Epoch 273/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3229 - binary_accuracy: 0.8434 - val_loss: 0.5096 - val_binary_accuracy: 0.7937\n",
      "Epoch 274/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3255 - binary_accuracy: 0.8427 - val_loss: 0.5063 - val_binary_accuracy: 0.7965\n",
      "Epoch 275/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3228 - binary_accuracy: 0.8438 - val_loss: 0.5056 - val_binary_accuracy: 0.7958\n",
      "Epoch 276/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3219 - binary_accuracy: 0.8436 - val_loss: 0.5145 - val_binary_accuracy: 0.7965\n",
      "Epoch 277/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3238 - binary_accuracy: 0.8468 - val_loss: 0.5014 - val_binary_accuracy: 0.7901\n",
      "Epoch 278/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3218 - binary_accuracy: 0.8431 - val_loss: 0.5173 - val_binary_accuracy: 0.7865\n",
      "Epoch 279/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3240 - binary_accuracy: 0.8434 - val_loss: 0.5062 - val_binary_accuracy: 0.7958\n",
      "Epoch 280/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3214 - binary_accuracy: 0.8459 - val_loss: 0.5090 - val_binary_accuracy: 0.7886\n",
      "Epoch 281/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3223 - binary_accuracy: 0.8434 - val_loss: 0.5130 - val_binary_accuracy: 0.7937\n",
      "Epoch 282/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3228 - binary_accuracy: 0.8445 - val_loss: 0.5134 - val_binary_accuracy: 0.7915\n",
      "Epoch 283/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3239 - binary_accuracy: 0.8431 - val_loss: 0.5159 - val_binary_accuracy: 0.7901\n",
      "Epoch 284/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3219 - binary_accuracy: 0.8468 - val_loss: 0.5066 - val_binary_accuracy: 0.7872\n",
      "Epoch 285/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3221 - binary_accuracy: 0.8467 - val_loss: 0.5082 - val_binary_accuracy: 0.7987\n",
      "Epoch 286/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3218 - binary_accuracy: 0.8470 - val_loss: 0.5104 - val_binary_accuracy: 0.7944\n",
      "Epoch 287/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3208 - binary_accuracy: 0.8440 - val_loss: 0.5167 - val_binary_accuracy: 0.7894\n",
      "Epoch 288/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3224 - binary_accuracy: 0.8463 - val_loss: 0.5100 - val_binary_accuracy: 0.7937\n",
      "Epoch 289/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3235 - binary_accuracy: 0.8443 - val_loss: 0.5129 - val_binary_accuracy: 0.7901\n",
      "Epoch 290/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3223 - binary_accuracy: 0.8441 - val_loss: 0.5083 - val_binary_accuracy: 0.7901\n",
      "Epoch 291/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3220 - binary_accuracy: 0.8443 - val_loss: 0.5146 - val_binary_accuracy: 0.7915\n",
      "Epoch 292/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3209 - binary_accuracy: 0.8481 - val_loss: 0.5121 - val_binary_accuracy: 0.7879\n",
      "Epoch 293/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3212 - binary_accuracy: 0.8472 - val_loss: 0.5184 - val_binary_accuracy: 0.7908\n",
      "Epoch 294/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3214 - binary_accuracy: 0.8474 - val_loss: 0.5205 - val_binary_accuracy: 0.7901\n",
      "Epoch 295/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3209 - binary_accuracy: 0.8449 - val_loss: 0.5156 - val_binary_accuracy: 0.7937\n",
      "Epoch 296/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3201 - binary_accuracy: 0.8479 - val_loss: 0.5141 - val_binary_accuracy: 0.7922\n",
      "Epoch 297/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3209 - binary_accuracy: 0.8449 - val_loss: 0.5179 - val_binary_accuracy: 0.7872\n",
      "Epoch 298/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3183 - binary_accuracy: 0.8433 - val_loss: 0.5257 - val_binary_accuracy: 0.7901\n",
      "Epoch 299/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3203 - binary_accuracy: 0.8472 - val_loss: 0.5158 - val_binary_accuracy: 0.7951\n",
      "Epoch 300/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3203 - binary_accuracy: 0.8481 - val_loss: 0.5209 - val_binary_accuracy: 0.7922\n",
      "Epoch 301/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3200 - binary_accuracy: 0.8476 - val_loss: 0.5214 - val_binary_accuracy: 0.7908\n",
      "Epoch 302/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3203 - binary_accuracy: 0.8440 - val_loss: 0.5231 - val_binary_accuracy: 0.7843\n",
      "Epoch 303/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3213 - binary_accuracy: 0.8433 - val_loss: 0.5220 - val_binary_accuracy: 0.7908\n",
      "Epoch 304/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3180 - binary_accuracy: 0.8490 - val_loss: 0.5175 - val_binary_accuracy: 0.7937\n",
      "Epoch 305/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3190 - binary_accuracy: 0.8470 - val_loss: 0.5236 - val_binary_accuracy: 0.7958\n",
      "Epoch 306/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3203 - binary_accuracy: 0.8454 - val_loss: 0.5225 - val_binary_accuracy: 0.7843\n",
      "Epoch 307/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3195 - binary_accuracy: 0.8463 - val_loss: 0.5225 - val_binary_accuracy: 0.7922\n",
      "Epoch 308/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3184 - binary_accuracy: 0.8461 - val_loss: 0.5205 - val_binary_accuracy: 0.7865\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3198 - binary_accuracy: 0.8499 - val_loss: 0.5290 - val_binary_accuracy: 0.7922\n",
      "Epoch 310/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3193 - binary_accuracy: 0.8504 - val_loss: 0.5240 - val_binary_accuracy: 0.7930\n",
      "Epoch 311/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3174 - binary_accuracy: 0.8494 - val_loss: 0.5228 - val_binary_accuracy: 0.7908\n",
      "Epoch 312/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3196 - binary_accuracy: 0.8485 - val_loss: 0.5254 - val_binary_accuracy: 0.7930\n",
      "Epoch 313/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3177 - binary_accuracy: 0.8481 - val_loss: 0.5294 - val_binary_accuracy: 0.7922\n",
      "Epoch 314/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3178 - binary_accuracy: 0.8485 - val_loss: 0.5289 - val_binary_accuracy: 0.7865\n",
      "Epoch 315/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3184 - binary_accuracy: 0.8510 - val_loss: 0.5261 - val_binary_accuracy: 0.7944\n",
      "Epoch 316/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3175 - binary_accuracy: 0.8433 - val_loss: 0.5268 - val_binary_accuracy: 0.7879\n",
      "Epoch 317/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3183 - binary_accuracy: 0.8497 - val_loss: 0.5271 - val_binary_accuracy: 0.7865\n",
      "Epoch 318/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3182 - binary_accuracy: 0.8450 - val_loss: 0.5297 - val_binary_accuracy: 0.7858\n",
      "Epoch 319/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3182 - binary_accuracy: 0.8476 - val_loss: 0.5248 - val_binary_accuracy: 0.7901\n",
      "Epoch 320/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3176 - binary_accuracy: 0.8465 - val_loss: 0.5330 - val_binary_accuracy: 0.7930\n",
      "Epoch 321/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3167 - binary_accuracy: 0.8461 - val_loss: 0.5352 - val_binary_accuracy: 0.7951\n",
      "Epoch 322/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3182 - binary_accuracy: 0.8474 - val_loss: 0.5224 - val_binary_accuracy: 0.7879\n",
      "Epoch 323/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3176 - binary_accuracy: 0.8468 - val_loss: 0.5361 - val_binary_accuracy: 0.7951\n",
      "Epoch 324/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3174 - binary_accuracy: 0.8494 - val_loss: 0.5376 - val_binary_accuracy: 0.7973\n",
      "Epoch 325/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3177 - binary_accuracy: 0.8472 - val_loss: 0.5381 - val_binary_accuracy: 0.7850\n",
      "Epoch 326/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3161 - binary_accuracy: 0.8479 - val_loss: 0.5284 - val_binary_accuracy: 0.7973\n",
      "Epoch 327/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3168 - binary_accuracy: 0.8467 - val_loss: 0.5284 - val_binary_accuracy: 0.7894\n",
      "Epoch 328/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3161 - binary_accuracy: 0.8486 - val_loss: 0.5341 - val_binary_accuracy: 0.7865\n",
      "Epoch 329/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3172 - binary_accuracy: 0.8452 - val_loss: 0.5286 - val_binary_accuracy: 0.7879\n",
      "Epoch 330/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3166 - binary_accuracy: 0.8470 - val_loss: 0.5345 - val_binary_accuracy: 0.7894\n",
      "Epoch 331/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3159 - binary_accuracy: 0.8506 - val_loss: 0.5342 - val_binary_accuracy: 0.7894\n",
      "Epoch 332/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3158 - binary_accuracy: 0.8501 - val_loss: 0.5325 - val_binary_accuracy: 0.7901\n",
      "Epoch 333/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3174 - binary_accuracy: 0.8488 - val_loss: 0.5384 - val_binary_accuracy: 0.7908\n",
      "Epoch 334/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3161 - binary_accuracy: 0.8481 - val_loss: 0.5415 - val_binary_accuracy: 0.7944\n",
      "Epoch 335/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3152 - binary_accuracy: 0.8488 - val_loss: 0.5385 - val_binary_accuracy: 0.7894\n",
      "Epoch 336/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3151 - binary_accuracy: 0.8495 - val_loss: 0.5390 - val_binary_accuracy: 0.7858\n",
      "Epoch 337/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3151 - binary_accuracy: 0.8503 - val_loss: 0.5421 - val_binary_accuracy: 0.7894\n",
      "Epoch 338/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3160 - binary_accuracy: 0.8492 - val_loss: 0.5354 - val_binary_accuracy: 0.7944\n",
      "Epoch 339/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3142 - binary_accuracy: 0.8494 - val_loss: 0.5401 - val_binary_accuracy: 0.7872\n",
      "Epoch 340/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3160 - binary_accuracy: 0.8461 - val_loss: 0.5384 - val_binary_accuracy: 0.7908\n",
      "Epoch 341/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3160 - binary_accuracy: 0.8476 - val_loss: 0.5473 - val_binary_accuracy: 0.7886\n",
      "Epoch 342/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3150 - binary_accuracy: 0.8441 - val_loss: 0.5420 - val_binary_accuracy: 0.7865\n",
      "Epoch 343/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3150 - binary_accuracy: 0.8468 - val_loss: 0.5391 - val_binary_accuracy: 0.7850\n",
      "Epoch 344/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3146 - binary_accuracy: 0.8476 - val_loss: 0.5373 - val_binary_accuracy: 0.7894\n",
      "Epoch 345/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3147 - binary_accuracy: 0.8461 - val_loss: 0.5446 - val_binary_accuracy: 0.7836\n",
      "Epoch 346/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3140 - binary_accuracy: 0.8490 - val_loss: 0.5400 - val_binary_accuracy: 0.7843\n",
      "Epoch 347/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3155 - binary_accuracy: 0.8490 - val_loss: 0.5430 - val_binary_accuracy: 0.7886\n",
      "Epoch 348/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3155 - binary_accuracy: 0.8470 - val_loss: 0.5462 - val_binary_accuracy: 0.7922\n",
      "Epoch 349/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3137 - binary_accuracy: 0.8447 - val_loss: 0.5421 - val_binary_accuracy: 0.7951\n",
      "Epoch 350/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3127 - binary_accuracy: 0.8508 - val_loss: 0.5454 - val_binary_accuracy: 0.7894\n",
      "Epoch 351/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3156 - binary_accuracy: 0.8503 - val_loss: 0.5442 - val_binary_accuracy: 0.7800\n",
      "Epoch 352/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3144 - binary_accuracy: 0.8483 - val_loss: 0.5457 - val_binary_accuracy: 0.7850\n",
      "Epoch 353/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3153 - binary_accuracy: 0.8506 - val_loss: 0.5464 - val_binary_accuracy: 0.7757\n",
      "Epoch 354/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3156 - binary_accuracy: 0.8503 - val_loss: 0.5413 - val_binary_accuracy: 0.7908\n",
      "Epoch 355/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3149 - binary_accuracy: 0.8477 - val_loss: 0.5661 - val_binary_accuracy: 0.7800\n",
      "Epoch 356/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3164 - binary_accuracy: 0.8467 - val_loss: 0.5270 - val_binary_accuracy: 0.7858\n",
      "Epoch 357/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3152 - binary_accuracy: 0.8483 - val_loss: 0.5576 - val_binary_accuracy: 0.7872\n",
      "Epoch 358/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3131 - binary_accuracy: 0.8485 - val_loss: 0.5510 - val_binary_accuracy: 0.7865\n",
      "Epoch 359/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3146 - binary_accuracy: 0.8470 - val_loss: 0.5555 - val_binary_accuracy: 0.7872\n",
      "Epoch 360/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3115 - binary_accuracy: 0.8481 - val_loss: 0.5492 - val_binary_accuracy: 0.7879\n",
      "Epoch 361/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3133 - binary_accuracy: 0.8485 - val_loss: 0.5497 - val_binary_accuracy: 0.7879\n",
      "Epoch 362/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3142 - binary_accuracy: 0.8497 - val_loss: 0.5505 - val_binary_accuracy: 0.7836\n",
      "Epoch 363/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3124 - binary_accuracy: 0.8503 - val_loss: 0.5570 - val_binary_accuracy: 0.7879\n",
      "Epoch 364/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3126 - binary_accuracy: 0.8510 - val_loss: 0.5530 - val_binary_accuracy: 0.7894\n",
      "Epoch 365/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3122 - binary_accuracy: 0.8499 - val_loss: 0.5566 - val_binary_accuracy: 0.7872\n",
      "Epoch 366/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3141 - binary_accuracy: 0.8479 - val_loss: 0.5627 - val_binary_accuracy: 0.7872\n",
      "Epoch 367/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3136 - binary_accuracy: 0.8474 - val_loss: 0.5611 - val_binary_accuracy: 0.7958\n",
      "Epoch 368/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3122 - binary_accuracy: 0.8485 - val_loss: 0.5621 - val_binary_accuracy: 0.7886\n",
      "Epoch 369/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3130 - binary_accuracy: 0.8488 - val_loss: 0.5542 - val_binary_accuracy: 0.7930\n",
      "Epoch 370/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3130 - binary_accuracy: 0.8465 - val_loss: 0.5590 - val_binary_accuracy: 0.7915\n",
      "Epoch 371/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3114 - binary_accuracy: 0.8508 - val_loss: 0.5545 - val_binary_accuracy: 0.7915\n",
      "Epoch 372/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3127 - binary_accuracy: 0.8510 - val_loss: 0.5551 - val_binary_accuracy: 0.7922\n",
      "Epoch 373/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3127 - binary_accuracy: 0.8490 - val_loss: 0.5537 - val_binary_accuracy: 0.7858\n",
      "Epoch 374/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3123 - binary_accuracy: 0.8495 - val_loss: 0.5552 - val_binary_accuracy: 0.7901\n",
      "Epoch 375/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3121 - binary_accuracy: 0.8513 - val_loss: 0.5634 - val_binary_accuracy: 0.7922\n",
      "Epoch 376/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3116 - binary_accuracy: 0.8495 - val_loss: 0.5600 - val_binary_accuracy: 0.7872\n",
      "Epoch 377/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3120 - binary_accuracy: 0.8503 - val_loss: 0.5714 - val_binary_accuracy: 0.7836\n",
      "Epoch 378/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3114 - binary_accuracy: 0.8467 - val_loss: 0.5597 - val_binary_accuracy: 0.7922\n",
      "Epoch 379/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3149 - binary_accuracy: 0.8508 - val_loss: 0.5580 - val_binary_accuracy: 0.7872\n",
      "Epoch 380/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3115 - binary_accuracy: 0.8488 - val_loss: 0.5572 - val_binary_accuracy: 0.7822\n",
      "Epoch 381/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3113 - binary_accuracy: 0.8499 - val_loss: 0.5629 - val_binary_accuracy: 0.7865\n",
      "Epoch 382/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3104 - binary_accuracy: 0.8503 - val_loss: 0.5567 - val_binary_accuracy: 0.7930\n",
      "Epoch 383/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3129 - binary_accuracy: 0.8535 - val_loss: 0.5546 - val_binary_accuracy: 0.7865\n",
      "Epoch 384/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3114 - binary_accuracy: 0.8519 - val_loss: 0.5648 - val_binary_accuracy: 0.7879\n",
      "Epoch 385/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3128 - binary_accuracy: 0.8510 - val_loss: 0.5654 - val_binary_accuracy: 0.7836\n",
      "Epoch 386/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3108 - binary_accuracy: 0.8515 - val_loss: 0.5613 - val_binary_accuracy: 0.7865\n",
      "Epoch 387/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3116 - binary_accuracy: 0.8492 - val_loss: 0.5651 - val_binary_accuracy: 0.7894\n",
      "Epoch 388/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3107 - binary_accuracy: 0.8530 - val_loss: 0.5612 - val_binary_accuracy: 0.7872\n",
      "Epoch 389/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3100 - binary_accuracy: 0.8530 - val_loss: 0.5656 - val_binary_accuracy: 0.7901\n",
      "Epoch 390/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3108 - binary_accuracy: 0.8512 - val_loss: 0.5666 - val_binary_accuracy: 0.7908\n",
      "Epoch 391/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3108 - binary_accuracy: 0.8517 - val_loss: 0.5626 - val_binary_accuracy: 0.7930\n",
      "Epoch 392/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3099 - binary_accuracy: 0.8497 - val_loss: 0.5753 - val_binary_accuracy: 0.7872\n",
      "Epoch 393/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3111 - binary_accuracy: 0.8512 - val_loss: 0.5694 - val_binary_accuracy: 0.7786\n",
      "Epoch 394/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3127 - binary_accuracy: 0.8503 - val_loss: 0.5642 - val_binary_accuracy: 0.7865\n",
      "Epoch 395/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3095 - binary_accuracy: 0.8535 - val_loss: 0.5640 - val_binary_accuracy: 0.7850\n",
      "Epoch 396/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3090 - binary_accuracy: 0.8521 - val_loss: 0.5761 - val_binary_accuracy: 0.7836\n",
      "Epoch 397/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3103 - binary_accuracy: 0.8522 - val_loss: 0.5653 - val_binary_accuracy: 0.7951\n",
      "Epoch 398/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3090 - binary_accuracy: 0.8517 - val_loss: 0.5670 - val_binary_accuracy: 0.7872\n",
      "Epoch 399/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3101 - binary_accuracy: 0.8508 - val_loss: 0.5678 - val_binary_accuracy: 0.7886\n",
      "Epoch 400/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3099 - binary_accuracy: 0.8495 - val_loss: 0.5727 - val_binary_accuracy: 0.7829\n",
      "Epoch 401/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3108 - binary_accuracy: 0.8499 - val_loss: 0.5713 - val_binary_accuracy: 0.7815\n",
      "Epoch 402/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3101 - binary_accuracy: 0.8519 - val_loss: 0.5756 - val_binary_accuracy: 0.7915\n",
      "Epoch 403/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3086 - binary_accuracy: 0.8517 - val_loss: 0.5721 - val_binary_accuracy: 0.7822\n",
      "Epoch 404/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3101 - binary_accuracy: 0.8510 - val_loss: 0.5760 - val_binary_accuracy: 0.7850\n",
      "Epoch 405/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3100 - binary_accuracy: 0.8530 - val_loss: 0.5764 - val_binary_accuracy: 0.7807\n",
      "Epoch 406/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3086 - binary_accuracy: 0.8530 - val_loss: 0.5755 - val_binary_accuracy: 0.7836\n",
      "Epoch 407/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3081 - binary_accuracy: 0.8531 - val_loss: 0.5758 - val_binary_accuracy: 0.7879\n",
      "Epoch 408/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3083 - binary_accuracy: 0.8548 - val_loss: 0.5792 - val_binary_accuracy: 0.7908\n",
      "Epoch 409/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3099 - binary_accuracy: 0.8499 - val_loss: 0.5837 - val_binary_accuracy: 0.7836\n",
      "Epoch 410/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3093 - binary_accuracy: 0.8504 - val_loss: 0.5781 - val_binary_accuracy: 0.7872\n",
      "Epoch 411/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3091 - binary_accuracy: 0.8537 - val_loss: 0.5814 - val_binary_accuracy: 0.7829\n",
      "Epoch 412/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3079 - binary_accuracy: 0.8553 - val_loss: 0.5821 - val_binary_accuracy: 0.7872\n",
      "Epoch 413/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3100 - binary_accuracy: 0.8512 - val_loss: 0.5763 - val_binary_accuracy: 0.7815\n",
      "Epoch 414/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3085 - binary_accuracy: 0.8517 - val_loss: 0.5802 - val_binary_accuracy: 0.7843\n",
      "Epoch 415/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3087 - binary_accuracy: 0.8497 - val_loss: 0.5795 - val_binary_accuracy: 0.7879\n",
      "Epoch 416/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3106 - binary_accuracy: 0.8530 - val_loss: 0.5751 - val_binary_accuracy: 0.7800\n",
      "Epoch 417/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3091 - binary_accuracy: 0.8510 - val_loss: 0.5783 - val_binary_accuracy: 0.7815\n",
      "Epoch 418/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3084 - binary_accuracy: 0.8533 - val_loss: 0.5778 - val_binary_accuracy: 0.7843\n",
      "Epoch 419/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3083 - binary_accuracy: 0.8528 - val_loss: 0.5805 - val_binary_accuracy: 0.7793\n",
      "Epoch 420/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3081 - binary_accuracy: 0.8517 - val_loss: 0.5820 - val_binary_accuracy: 0.7850\n",
      "Epoch 421/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3083 - binary_accuracy: 0.8524 - val_loss: 0.5884 - val_binary_accuracy: 0.7865\n",
      "Epoch 422/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3088 - binary_accuracy: 0.8510 - val_loss: 0.5794 - val_binary_accuracy: 0.7836\n",
      "Epoch 423/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3072 - binary_accuracy: 0.8558 - val_loss: 0.5825 - val_binary_accuracy: 0.7865\n",
      "Epoch 424/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3062 - binary_accuracy: 0.8535 - val_loss: 0.5920 - val_binary_accuracy: 0.7886\n",
      "Epoch 425/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3093 - binary_accuracy: 0.8542 - val_loss: 0.5743 - val_binary_accuracy: 0.7872\n",
      "Epoch 426/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3060 - binary_accuracy: 0.8539 - val_loss: 0.5779 - val_binary_accuracy: 0.7836\n",
      "Epoch 427/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3071 - binary_accuracy: 0.8531 - val_loss: 0.5828 - val_binary_accuracy: 0.7850\n",
      "Epoch 428/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3093 - binary_accuracy: 0.8539 - val_loss: 0.5899 - val_binary_accuracy: 0.7858\n",
      "Epoch 429/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3067 - binary_accuracy: 0.8560 - val_loss: 0.5835 - val_binary_accuracy: 0.7901\n",
      "Epoch 430/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3100 - binary_accuracy: 0.8494 - val_loss: 0.5914 - val_binary_accuracy: 0.7872\n",
      "Epoch 431/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3088 - binary_accuracy: 0.8504 - val_loss: 0.5867 - val_binary_accuracy: 0.7858\n",
      "Epoch 432/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3082 - binary_accuracy: 0.8503 - val_loss: 0.5922 - val_binary_accuracy: 0.7858\n",
      "Epoch 433/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3068 - binary_accuracy: 0.8524 - val_loss: 0.5896 - val_binary_accuracy: 0.7886\n",
      "Epoch 434/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3054 - binary_accuracy: 0.8512 - val_loss: 0.6011 - val_binary_accuracy: 0.7901\n",
      "Epoch 435/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3066 - binary_accuracy: 0.8546 - val_loss: 0.5942 - val_binary_accuracy: 0.7822\n",
      "Epoch 436/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3062 - binary_accuracy: 0.8564 - val_loss: 0.5910 - val_binary_accuracy: 0.7872\n",
      "Epoch 437/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3059 - binary_accuracy: 0.8522 - val_loss: 0.5878 - val_binary_accuracy: 0.7879\n",
      "Epoch 438/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3061 - binary_accuracy: 0.8566 - val_loss: 0.5950 - val_binary_accuracy: 0.7815\n",
      "Epoch 439/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3065 - binary_accuracy: 0.8510 - val_loss: 0.5842 - val_binary_accuracy: 0.7843\n",
      "Epoch 440/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3072 - binary_accuracy: 0.8537 - val_loss: 0.5977 - val_binary_accuracy: 0.7793\n",
      "Epoch 441/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3058 - binary_accuracy: 0.8517 - val_loss: 0.5865 - val_binary_accuracy: 0.7836\n",
      "Epoch 442/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3064 - binary_accuracy: 0.8524 - val_loss: 0.5892 - val_binary_accuracy: 0.7829\n",
      "Epoch 443/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3071 - binary_accuracy: 0.8515 - val_loss: 0.5935 - val_binary_accuracy: 0.7858\n",
      "Epoch 444/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3053 - binary_accuracy: 0.8540 - val_loss: 0.5989 - val_binary_accuracy: 0.7815\n",
      "Epoch 445/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3069 - binary_accuracy: 0.8537 - val_loss: 0.6023 - val_binary_accuracy: 0.7908\n",
      "Epoch 446/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3069 - binary_accuracy: 0.8510 - val_loss: 0.5997 - val_binary_accuracy: 0.7886\n",
      "Epoch 447/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3068 - binary_accuracy: 0.8517 - val_loss: 0.5937 - val_binary_accuracy: 0.7865\n",
      "Epoch 448/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3074 - binary_accuracy: 0.8503 - val_loss: 0.6027 - val_binary_accuracy: 0.7829\n",
      "Epoch 449/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3060 - binary_accuracy: 0.8544 - val_loss: 0.6017 - val_binary_accuracy: 0.7858\n",
      "Epoch 450/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3059 - binary_accuracy: 0.8546 - val_loss: 0.5986 - val_binary_accuracy: 0.7786\n",
      "Epoch 451/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3054 - binary_accuracy: 0.8522 - val_loss: 0.6005 - val_binary_accuracy: 0.7829\n",
      "Epoch 452/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3047 - binary_accuracy: 0.8517 - val_loss: 0.6044 - val_binary_accuracy: 0.7865\n",
      "Epoch 453/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3067 - binary_accuracy: 0.8540 - val_loss: 0.5903 - val_binary_accuracy: 0.7850\n",
      "Epoch 454/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3065 - binary_accuracy: 0.8521 - val_loss: 0.5779 - val_binary_accuracy: 0.7822\n",
      "Epoch 455/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3038 - binary_accuracy: 0.8546 - val_loss: 0.5906 - val_binary_accuracy: 0.7894\n",
      "Epoch 456/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3053 - binary_accuracy: 0.8526 - val_loss: 0.5802 - val_binary_accuracy: 0.7908\n",
      "Epoch 457/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3044 - binary_accuracy: 0.8535 - val_loss: 0.5866 - val_binary_accuracy: 0.7886\n",
      "Epoch 458/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3068 - binary_accuracy: 0.8537 - val_loss: 0.5909 - val_binary_accuracy: 0.7764\n",
      "Epoch 459/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3037 - binary_accuracy: 0.8578 - val_loss: 0.5849 - val_binary_accuracy: 0.7872\n",
      "Epoch 460/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3040 - binary_accuracy: 0.8562 - val_loss: 0.5974 - val_binary_accuracy: 0.7872\n",
      "Epoch 461/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3053 - binary_accuracy: 0.8535 - val_loss: 0.5843 - val_binary_accuracy: 0.7843\n",
      "Epoch 462/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3029 - binary_accuracy: 0.8531 - val_loss: 0.5927 - val_binary_accuracy: 0.7829\n",
      "Epoch 463/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3048 - binary_accuracy: 0.8548 - val_loss: 0.5949 - val_binary_accuracy: 0.7901\n",
      "Epoch 464/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3061 - binary_accuracy: 0.8542 - val_loss: 0.5930 - val_binary_accuracy: 0.7894\n",
      "Epoch 465/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3033 - binary_accuracy: 0.8537 - val_loss: 0.5974 - val_binary_accuracy: 0.7815\n",
      "Epoch 466/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3049 - binary_accuracy: 0.8540 - val_loss: 0.5829 - val_binary_accuracy: 0.7865\n",
      "Epoch 467/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3049 - binary_accuracy: 0.8540 - val_loss: 0.5884 - val_binary_accuracy: 0.7886\n",
      "Epoch 468/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3040 - binary_accuracy: 0.8578 - val_loss: 0.5975 - val_binary_accuracy: 0.7850\n",
      "Epoch 469/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3056 - binary_accuracy: 0.8530 - val_loss: 0.5888 - val_binary_accuracy: 0.7829\n",
      "Epoch 470/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3057 - binary_accuracy: 0.8544 - val_loss: 0.6064 - val_binary_accuracy: 0.7836\n",
      "Epoch 471/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3039 - binary_accuracy: 0.8540 - val_loss: 0.6051 - val_binary_accuracy: 0.7807\n",
      "Epoch 472/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3034 - binary_accuracy: 0.8548 - val_loss: 0.5900 - val_binary_accuracy: 0.7793\n",
      "Epoch 473/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3048 - binary_accuracy: 0.8557 - val_loss: 0.5987 - val_binary_accuracy: 0.7836\n",
      "Epoch 474/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3036 - binary_accuracy: 0.8560 - val_loss: 0.5993 - val_binary_accuracy: 0.7865\n",
      "Epoch 475/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3032 - binary_accuracy: 0.8560 - val_loss: 0.6018 - val_binary_accuracy: 0.7850\n",
      "Epoch 476/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3059 - binary_accuracy: 0.8549 - val_loss: 0.6003 - val_binary_accuracy: 0.7872\n",
      "Epoch 477/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3049 - binary_accuracy: 0.8589 - val_loss: 0.6015 - val_binary_accuracy: 0.7829\n",
      "Epoch 478/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3050 - binary_accuracy: 0.8578 - val_loss: 0.5946 - val_binary_accuracy: 0.7822\n",
      "Epoch 479/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3033 - binary_accuracy: 0.8537 - val_loss: 0.5933 - val_binary_accuracy: 0.7901\n",
      "Epoch 480/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3040 - binary_accuracy: 0.8521 - val_loss: 0.6046 - val_binary_accuracy: 0.7858\n",
      "Epoch 481/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3035 - binary_accuracy: 0.8540 - val_loss: 0.5961 - val_binary_accuracy: 0.7901\n",
      "Epoch 482/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3031 - binary_accuracy: 0.8546 - val_loss: 0.5974 - val_binary_accuracy: 0.7865\n",
      "Epoch 483/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3030 - binary_accuracy: 0.8576 - val_loss: 0.6103 - val_binary_accuracy: 0.7858\n",
      "Epoch 484/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3018 - binary_accuracy: 0.8578 - val_loss: 0.6101 - val_binary_accuracy: 0.7822\n",
      "Epoch 485/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3048 - binary_accuracy: 0.8558 - val_loss: 0.6006 - val_binary_accuracy: 0.7829\n",
      "Epoch 486/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3025 - binary_accuracy: 0.8540 - val_loss: 0.6096 - val_binary_accuracy: 0.7800\n",
      "Epoch 487/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3029 - binary_accuracy: 0.8540 - val_loss: 0.6047 - val_binary_accuracy: 0.7843\n",
      "Epoch 488/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3041 - binary_accuracy: 0.8555 - val_loss: 0.6089 - val_binary_accuracy: 0.7886\n",
      "Epoch 489/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3015 - binary_accuracy: 0.8558 - val_loss: 0.6098 - val_binary_accuracy: 0.7879\n",
      "Epoch 490/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3034 - binary_accuracy: 0.8557 - val_loss: 0.6084 - val_binary_accuracy: 0.7779\n",
      "Epoch 491/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3039 - binary_accuracy: 0.8530 - val_loss: 0.6144 - val_binary_accuracy: 0.7858\n",
      "Epoch 492/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3028 - binary_accuracy: 0.8585 - val_loss: 0.6101 - val_binary_accuracy: 0.7886\n",
      "Epoch 493/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3022 - binary_accuracy: 0.8546 - val_loss: 0.6062 - val_binary_accuracy: 0.7822\n",
      "Epoch 494/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3029 - binary_accuracy: 0.8526 - val_loss: 0.6021 - val_binary_accuracy: 0.7829\n",
      "Epoch 495/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3008 - binary_accuracy: 0.8580 - val_loss: 0.6162 - val_binary_accuracy: 0.7886\n",
      "Epoch 496/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3016 - binary_accuracy: 0.8573 - val_loss: 0.6128 - val_binary_accuracy: 0.7800\n",
      "Epoch 497/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3018 - binary_accuracy: 0.8582 - val_loss: 0.6068 - val_binary_accuracy: 0.7829\n",
      "Epoch 498/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3036 - binary_accuracy: 0.8540 - val_loss: 0.6102 - val_binary_accuracy: 0.7858\n",
      "Epoch 499/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3016 - binary_accuracy: 0.8592 - val_loss: 0.6059 - val_binary_accuracy: 0.7843\n",
      "Epoch 500/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3015 - binary_accuracy: 0.8571 - val_loss: 0.6109 - val_binary_accuracy: 0.7822\n"
     ]
    }
   ],
   "source": [
    "model_3 = keras.Sequential([\n",
    "    # the hidden ReLU layers\n",
    "    layers.Dense(units=23, activation='relu', input_shape=[23]),\n",
    "    layers.Dense(units=23, activation='relu'),\n",
    "    # the linear output layer \n",
    "    layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model_3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "history=model_3.fit(x_1train,y_1train,epochs=500,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49456938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.579603</td>\n",
       "      <td>0.710768</td>\n",
       "      <td>0.495425</td>\n",
       "      <td>0.765636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.772964</td>\n",
       "      <td>0.446285</td>\n",
       "      <td>0.795111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.438294</td>\n",
       "      <td>0.794895</td>\n",
       "      <td>0.428801</td>\n",
       "      <td>0.799425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.422316</td>\n",
       "      <td>0.803523</td>\n",
       "      <td>0.422482</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414027</td>\n",
       "      <td>0.805860</td>\n",
       "      <td>0.416137</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.301637</td>\n",
       "      <td>0.857271</td>\n",
       "      <td>0.612771</td>\n",
       "      <td>0.780014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.301832</td>\n",
       "      <td>0.858170</td>\n",
       "      <td>0.606758</td>\n",
       "      <td>0.782890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.303559</td>\n",
       "      <td>0.854036</td>\n",
       "      <td>0.610206</td>\n",
       "      <td>0.785766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.301630</td>\n",
       "      <td>0.859249</td>\n",
       "      <td>0.605922</td>\n",
       "      <td>0.784328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.301538</td>\n",
       "      <td>0.857091</td>\n",
       "      <td>0.610907</td>\n",
       "      <td>0.782171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0    0.579603         0.710768  0.495425             0.765636\n",
       "1    0.470900         0.772964  0.446285             0.795111\n",
       "2    0.438294         0.794895  0.428801             0.799425\n",
       "3    0.422316         0.803523  0.422482             0.803738\n",
       "4    0.414027         0.805860  0.416137             0.803738\n",
       "..        ...              ...       ...                  ...\n",
       "495  0.301637         0.857271  0.612771             0.780014\n",
       "496  0.301832         0.858170  0.606758             0.782890\n",
       "497  0.303559         0.854036  0.610206             0.785766\n",
       "498  0.301630         0.859249  0.605922             0.784328\n",
       "499  0.301538         0.857091  0.610907             0.782171\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901fb6c7",
   "metadata": {},
   "source": [
    "### Building the first random forest model with the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2a2e0fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_features=5, n_estimators=70,\n",
       "                       random_state=23)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=70,max_depth=8,max_features=5,criterion='gini',random_state=23)\n",
    "rf.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01701fa",
   "metadata": {},
   "source": [
    "### Reading the test data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c885623",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(r\"C:\\Users\\Govind S\\Downloads\\ds\\kaggle\\knowledge\\titanic\\spaceship-titanic\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99c98e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1496/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jeron Peter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>Matty Scheron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>D/296/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jayrin Pore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>D/297/P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>Kitakan Conale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1498/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lilace Leonzaley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0013_01      Earth      True     G/3/S    TRAPPIST-1e  27.0  False   \n",
       "1        0018_01      Earth     False     F/4/S    TRAPPIST-1e  19.0  False   \n",
       "2        0019_01     Europa      True     C/0/S    55 Cancri e  31.0  False   \n",
       "3        0021_01     Europa     False     C/1/S    TRAPPIST-1e  38.0  False   \n",
       "4        0023_01      Earth     False     F/5/S    TRAPPIST-1e  20.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "4272     9266_02      Earth      True  G/1496/S    TRAPPIST-1e  34.0  False   \n",
       "4273     9269_01      Earth     False       NaN    TRAPPIST-1e  42.0  False   \n",
       "4274     9271_01       Mars      True   D/296/P    55 Cancri e   NaN  False   \n",
       "4275     9273_01     Europa     False   D/297/P            NaN   NaN  False   \n",
       "4276     9277_01      Earth      True  G/1498/S  PSO J318.5-22  43.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0             0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1             0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2             0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3             0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4            10.0        0.0         635.0     0.0     0.0   Brence Harperez  \n",
       "...           ...        ...           ...     ...     ...               ...  \n",
       "4272          0.0        0.0           0.0     0.0     0.0       Jeron Peter  \n",
       "4273          0.0      847.0          17.0    10.0   144.0     Matty Scheron  \n",
       "4274          0.0        0.0           0.0     0.0     0.0       Jayrin Pore  \n",
       "4275          0.0     2680.0           0.0     0.0   523.0    Kitakan Conale  \n",
       "4276          0.0        0.0           0.0     0.0     0.0  Lilace Leonzaley  \n",
       "\n",
       "[4277 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed356b",
   "metadata": {},
   "source": [
    "### preparing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8808f8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  CryoSleep Cabin    Destination   Age    VIP  RoomService  \\\n",
       "0         Earth       True     G    TRAPPIST-1e  27.0  False          0.0   \n",
       "1         Earth      False     F    TRAPPIST-1e  19.0  False          0.0   \n",
       "2        Europa       True     C    55 Cancri e  31.0  False          0.0   \n",
       "3        Europa      False     C    TRAPPIST-1e  38.0  False          0.0   \n",
       "4         Earth      False     F    TRAPPIST-1e  20.0  False         10.0   \n",
       "...         ...        ...   ...            ...   ...    ...          ...   \n",
       "4272      Earth       True     G    TRAPPIST-1e  34.0  False          0.0   \n",
       "4273      Earth      False     F    TRAPPIST-1e  42.0  False          0.0   \n",
       "4274       Mars       True     D    55 Cancri e   NaN  False          0.0   \n",
       "4275     Europa      False     D    TRAPPIST-1e   NaN  False          0.0   \n",
       "4276      Earth       True     G  PSO J318.5-22  43.0  False          0.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0       S  \n",
       "1           9.0           0.0  2823.0     0.0       S  \n",
       "2           0.0           0.0     0.0     0.0       S  \n",
       "3        6652.0           0.0   181.0   585.0       S  \n",
       "4           0.0         635.0     0.0     0.0       S  \n",
       "...         ...           ...     ...     ...     ...  \n",
       "4272        0.0           0.0     0.0     0.0       S  \n",
       "4273      847.0          17.0    10.0   144.0       S  \n",
       "4274        0.0           0.0     0.0     0.0       P  \n",
       "4275     2680.0           0.0     0.0   523.0       P  \n",
       "4276        0.0           0.0     0.0     0.0       S  \n",
       "\n",
       "[4277 rows x 12 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID=test.PassengerId.copy()\n",
    "test.drop(['PassengerId'],axis=1,inplace=True)\n",
    "test.drop(['Name'],axis=1,inplace=True)\n",
    "test['Cabin_s']=test.Cabin.str[-1]\n",
    "test.Cabin=test.Cabin.str[0]\n",
    "categorical_columns=['HomePlanet', 'CryoSleep', 'Cabin', 'Destination','VIP','Cabin_s']\n",
    "for i in categorical_columns:\n",
    "    test[i].fillna(test[i].mode()[0],inplace=True)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54513c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  CryoSleep Cabin    Destination   Age  VIP  RoomService  \\\n",
       "0         Earth       True     G    TRAPPIST-1e  27.0    0          0.0   \n",
       "1         Earth      False     F    TRAPPIST-1e  19.0    0          0.0   \n",
       "2        Europa       True     C    55 Cancri e  31.0    0          0.0   \n",
       "3        Europa      False     C    TRAPPIST-1e  38.0    0          0.0   \n",
       "4         Earth      False     F    TRAPPIST-1e  20.0    0         10.0   \n",
       "...         ...        ...   ...            ...   ...  ...          ...   \n",
       "4272      Earth       True     G    TRAPPIST-1e  34.0    0          0.0   \n",
       "4273      Earth      False     F    TRAPPIST-1e  42.0    0          0.0   \n",
       "4274       Mars       True     D    55 Cancri e   NaN    0          0.0   \n",
       "4275     Europa      False     D    TRAPPIST-1e   NaN    0          0.0   \n",
       "4276      Earth       True     G  PSO J318.5-22  43.0    0          0.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0       S  \n",
       "1           9.0           0.0  2823.0     0.0       S  \n",
       "2           0.0           0.0     0.0     0.0       S  \n",
       "3        6652.0           0.0   181.0   585.0       S  \n",
       "4           0.0         635.0     0.0     0.0       S  \n",
       "...         ...           ...     ...     ...     ...  \n",
       "4272        0.0           0.0     0.0     0.0       S  \n",
       "4273      847.0          17.0    10.0   144.0       S  \n",
       "4274        0.0           0.0     0.0     0.0       P  \n",
       "4275     2680.0           0.0     0.0   523.0       P  \n",
       "4276        0.0           0.0     0.0     0.0       S  \n",
       "\n",
       "[4277 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.VIP=test.VIP.astype('int')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04b142db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VIP'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns.pop(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f2775e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              0          1      6            2  27.0    0          0.0   \n",
       "1              0          0      5            2  19.0    0          0.0   \n",
       "2              1          1      2            0  31.0    0          0.0   \n",
       "3              1          0      2            2  38.0    0          0.0   \n",
       "4              0          0      5            2  20.0    0         10.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "4272           0          1      6            2  34.0    0          0.0   \n",
       "4273           0          0      5            2  42.0    0          0.0   \n",
       "4274           2          1      3            0   NaN    0          0.0   \n",
       "4275           1          0      3            2   NaN    0          0.0   \n",
       "4276           0          1      6            1  43.0    0          0.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0        1  \n",
       "1           9.0           0.0  2823.0     0.0        1  \n",
       "2           0.0           0.0     0.0     0.0        1  \n",
       "3        6652.0           0.0   181.0   585.0        1  \n",
       "4           0.0         635.0     0.0     0.0        1  \n",
       "...         ...           ...     ...     ...      ...  \n",
       "4272        0.0           0.0     0.0     0.0        1  \n",
       "4273      847.0          17.0    10.0   144.0        1  \n",
       "4274        0.0           0.0     0.0     0.0        0  \n",
       "4275     2680.0           0.0     0.0   523.0        0  \n",
       "4276        0.0           0.0     0.0     0.0        1  \n",
       "\n",
       "[4277 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for i in categorical_columns:\n",
    "    le=LabelEncoder()\n",
    "    test[i]=le.fit_transform(test[i])\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac561a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    4277 non-null   int32  \n",
      " 1   CryoSleep     4277 non-null   int64  \n",
      " 2   Cabin         4277 non-null   int32  \n",
      " 3   Destination   4277 non-null   int32  \n",
      " 4   Age           4186 non-null   float64\n",
      " 5   VIP           4277 non-null   int32  \n",
      " 6   RoomService   4195 non-null   float64\n",
      " 7   FoodCourt     4171 non-null   float64\n",
      " 8   ShoppingMall  4179 non-null   float64\n",
      " 9   Spa           4176 non-null   float64\n",
      " 10  VRDeck        4197 non-null   float64\n",
      " 11  Cabin_s       4277 non-null   int32  \n",
      "dtypes: float64(6), int32(5), int64(1)\n",
      "memory usage: 317.6 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0c5c778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    4277 non-null   int32  \n",
      " 1   CryoSleep     4277 non-null   int64  \n",
      " 2   Cabin         4277 non-null   int32  \n",
      " 3   Destination   4277 non-null   int32  \n",
      " 4   Age           4277 non-null   float64\n",
      " 5   VIP           4277 non-null   int32  \n",
      " 6   RoomService   4277 non-null   float64\n",
      " 7   FoodCourt     4277 non-null   float64\n",
      " 8   ShoppingMall  4277 non-null   float64\n",
      " 9   Spa           4277 non-null   float64\n",
      " 10  VRDeck        4277 non-null   float64\n",
      " 11  Cabin_s       4277 non-null   int32  \n",
      "dtypes: float64(6), int32(5), int64(1)\n",
      "memory usage: 317.6 KB\n"
     ]
    }
   ],
   "source": [
    "test['Age'].fillna(data_1['Age'].mean(),inplace=True)\n",
    "cont_columns=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for i in cont_columns:\n",
    "    test[i].fillna(data_1[i].median(),inplace=True)\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9de351e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bf8fa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_s</th>\n",
       "      <th>HomePlanet_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_1</th>\n",
       "      <th>Cabin_2</th>\n",
       "      <th>Cabin_3</th>\n",
       "      <th>Cabin_4</th>\n",
       "      <th>Cabin_5</th>\n",
       "      <th>Cabin_6</th>\n",
       "      <th>Cabin_7</th>\n",
       "      <th>Destination_0</th>\n",
       "      <th>Destination_1</th>\n",
       "      <th>Destination_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>1</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>1</td>\n",
       "      <td>28.82793</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>0</td>\n",
       "      <td>28.82793</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>1</td>\n",
       "      <td>43.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CryoSleep       Age  VIP  RoomService  FoodCourt  ShoppingMall     Spa  \\\n",
       "0             1  27.00000    0          0.0        0.0           0.0     0.0   \n",
       "1             0  19.00000    0          0.0        9.0           0.0  2823.0   \n",
       "2             1  31.00000    0          0.0        0.0           0.0     0.0   \n",
       "3             0  38.00000    0          0.0     6652.0           0.0   181.0   \n",
       "4             0  20.00000    0         10.0        0.0         635.0     0.0   \n",
       "...         ...       ...  ...          ...        ...           ...     ...   \n",
       "4272          1  34.00000    0          0.0        0.0           0.0     0.0   \n",
       "4273          0  42.00000    0          0.0      847.0          17.0    10.0   \n",
       "4274          1  28.82793    0          0.0        0.0           0.0     0.0   \n",
       "4275          0  28.82793    0          0.0     2680.0           0.0     0.0   \n",
       "4276          1  43.00000    0          0.0        0.0           0.0     0.0   \n",
       "\n",
       "      VRDeck  Cabin_s  HomePlanet_0  ...  Cabin_1  Cabin_2  Cabin_3  Cabin_4  \\\n",
       "0        0.0        1             1  ...        0        0        0        0   \n",
       "1        0.0        1             1  ...        0        0        0        0   \n",
       "2        0.0        1             0  ...        0        1        0        0   \n",
       "3      585.0        1             0  ...        0        1        0        0   \n",
       "4        0.0        1             1  ...        0        0        0        0   \n",
       "...      ...      ...           ...  ...      ...      ...      ...      ...   \n",
       "4272     0.0        1             1  ...        0        0        0        0   \n",
       "4273   144.0        1             1  ...        0        0        0        0   \n",
       "4274     0.0        0             0  ...        0        0        1        0   \n",
       "4275   523.0        0             0  ...        0        0        1        0   \n",
       "4276     0.0        1             1  ...        0        0        0        0   \n",
       "\n",
       "      Cabin_5  Cabin_6  Cabin_7  Destination_0  Destination_1  Destination_2  \n",
       "0           0        1        0              0              0              1  \n",
       "1           1        0        0              0              0              1  \n",
       "2           0        0        0              1              0              0  \n",
       "3           0        0        0              0              0              1  \n",
       "4           1        0        0              0              0              1  \n",
       "...       ...      ...      ...            ...            ...            ...  \n",
       "4272        0        1        0              0              0              1  \n",
       "4273        1        0        0              0              0              1  \n",
       "4274        0        0        0              1              0              0  \n",
       "4275        0        0        0              0              0              1  \n",
       "4276        0        1        0              0              1              0  \n",
       "\n",
       "[4277 rows x 23 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dummies=pd.get_dummies(test_dummies,columns=['HomePlanet','Cabin','Destination'])\n",
    "test_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "25c83815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              1          0      1            2  39.0    0          0.0   \n",
       "1              0          0      5            2  24.0    0        109.0   \n",
       "2              1          0      0            2  58.0    1         43.0   \n",
       "3              1          0      0            2  33.0    0          0.0   \n",
       "4              0          0      5            2  16.0    0        303.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "8688           1          0      0            0  41.0    1          0.0   \n",
       "8689           0          1      6            1  18.0    0          0.0   \n",
       "8690           0          0      6            2  26.0    0          0.0   \n",
       "8691           1          0      4            0  32.0    0          0.0   \n",
       "8692           1          0      4            2  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0        0  \n",
       "1           9.0          25.0   549.0    44.0        1  \n",
       "2        3576.0           0.0  6715.0    49.0        1  \n",
       "3        1283.0         371.0  3329.0   193.0        1  \n",
       "4          70.0         151.0   565.0     2.0        1  \n",
       "...         ...           ...     ...     ...      ...  \n",
       "8688     6819.0           0.0  1643.0    74.0        0  \n",
       "8689        0.0           0.0     0.0     0.0        1  \n",
       "8690        0.0        1872.0     1.0     0.0        1  \n",
       "8691     1049.0           0.0   353.0  3235.0        1  \n",
       "8692     4688.0           0.0     0.0    12.0        1  \n",
       "\n",
       "[8693 rows x 12 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40ce96",
   "metadata": {},
   "source": [
    "### predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "314ee4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4d6ee9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a.astype('bool')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "32af9eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01         True\n",
       "1        0018_01        False\n",
       "2        0019_01         True\n",
       "3        0021_01         True\n",
       "4        0023_01        False\n",
       "...          ...          ...\n",
       "4272     9266_02         True\n",
       "4273     9269_01        False\n",
       "4274     9271_01         True\n",
       "4275     9273_01         True\n",
       "4276     9277_01         True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'PassengerId':ID,'Transported':a})\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b3a21",
   "metadata": {},
   "source": [
    "### Creating a csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "357aa5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1207a71",
   "metadata": {},
   "source": [
    "### Doing the same process with the initial lgbm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "44f754ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Govind S\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Govind S\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.07, max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lgb.LGBMClassifier(learning_rate=0.07,random_state=42,max_depth=5)\n",
    "lgb.fit(x,y,categorical_feature=[0,1,2,3,5,11],verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6bf5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=lgb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2f93eee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True, False,  True])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=b.astype('bool')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0e0e451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01         True\n",
       "1        0018_01        False\n",
       "2        0019_01         True\n",
       "3        0021_01         True\n",
       "4        0023_01         True\n",
       "...          ...          ...\n",
       "4272     9266_02         True\n",
       "4273     9269_01         True\n",
       "4274     9271_01         True\n",
       "4275     9273_01        False\n",
       "4276     9277_01         True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'PassengerId':ID,'Transported':b})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca0fa4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74270f9",
   "metadata": {},
   "source": [
    "### This model got the best accuracy in kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c1f52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final=ss.transform(test_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427454d7",
   "metadata": {},
   "source": [
    "### With the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ee63788",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=svm.predict(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63c658d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2217\n",
       "0    2060\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=pd.Series(c)\n",
    "d.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33737a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=c.astype('bool')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "717e4c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01         True\n",
       "1        0018_01        False\n",
       "2        0019_01         True\n",
       "3        0021_01         True\n",
       "4        0023_01         True\n",
       "...          ...          ...\n",
       "4272     9266_02         True\n",
       "4273     9269_01         True\n",
       "4274     9271_01         True\n",
       "4275     9273_01         True\n",
       "4276     9277_01         True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_c = pd.DataFrame({'PassengerId':ID,'Transported':c})\n",
    "submission_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c41eab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_c.to_csv('submission_c.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33afcc4f",
   "metadata": {},
   "source": [
    "### Trying different structures for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5a7d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "174/174 [==============================] - 2s 5ms/step - loss: 0.6243 - binary_accuracy: 0.6277 - val_loss: 0.4979 - val_binary_accuracy: 0.7699\n",
      "Epoch 2/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4674 - binary_accuracy: 0.7778 - val_loss: 0.4401 - val_binary_accuracy: 0.7958\n",
      "Epoch 3/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4314 - binary_accuracy: 0.7924 - val_loss: 0.4243 - val_binary_accuracy: 0.8052\n",
      "Epoch 4/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4192 - binary_accuracy: 0.7945 - val_loss: 0.4162 - val_binary_accuracy: 0.8023\n",
      "Epoch 5/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4128 - binary_accuracy: 0.7997 - val_loss: 0.4142 - val_binary_accuracy: 0.8081\n",
      "Epoch 6/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4088 - binary_accuracy: 0.7990 - val_loss: 0.4130 - val_binary_accuracy: 0.8045\n",
      "Epoch 7/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4061 - binary_accuracy: 0.8051 - val_loss: 0.4080 - val_binary_accuracy: 0.8138\n",
      "Epoch 8/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4031 - binary_accuracy: 0.8096 - val_loss: 0.4085 - val_binary_accuracy: 0.8066\n",
      "Epoch 9/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4013 - binary_accuracy: 0.8060 - val_loss: 0.4076 - val_binary_accuracy: 0.8109\n",
      "Epoch 10/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3998 - binary_accuracy: 0.8033 - val_loss: 0.4068 - val_binary_accuracy: 0.8081\n",
      "Epoch 11/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3984 - binary_accuracy: 0.8093 - val_loss: 0.4054 - val_binary_accuracy: 0.8059\n",
      "Epoch 12/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3967 - binary_accuracy: 0.8095 - val_loss: 0.4067 - val_binary_accuracy: 0.8023\n",
      "Epoch 13/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3952 - binary_accuracy: 0.8111 - val_loss: 0.4033 - val_binary_accuracy: 0.8167\n",
      "Epoch 14/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3944 - binary_accuracy: 0.8078 - val_loss: 0.4066 - val_binary_accuracy: 0.8037\n",
      "Epoch 15/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3925 - binary_accuracy: 0.8086 - val_loss: 0.4086 - val_binary_accuracy: 0.8052\n",
      "Epoch 16/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3921 - binary_accuracy: 0.8078 - val_loss: 0.4041 - val_binary_accuracy: 0.8131\n",
      "Epoch 17/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3907 - binary_accuracy: 0.8102 - val_loss: 0.4127 - val_binary_accuracy: 0.8059\n",
      "Epoch 18/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3901 - binary_accuracy: 0.8091 - val_loss: 0.4066 - val_binary_accuracy: 0.8081\n",
      "Epoch 19/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3878 - binary_accuracy: 0.8131 - val_loss: 0.4072 - val_binary_accuracy: 0.8037\n",
      "Epoch 20/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3879 - binary_accuracy: 0.8134 - val_loss: 0.4078 - val_binary_accuracy: 0.8066\n",
      "Epoch 21/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3872 - binary_accuracy: 0.8177 - val_loss: 0.4068 - val_binary_accuracy: 0.8030\n",
      "Epoch 22/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3867 - binary_accuracy: 0.8148 - val_loss: 0.4030 - val_binary_accuracy: 0.8116\n",
      "Epoch 23/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3858 - binary_accuracy: 0.8136 - val_loss: 0.4068 - val_binary_accuracy: 0.8059\n",
      "Epoch 24/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3853 - binary_accuracy: 0.8127 - val_loss: 0.4089 - val_binary_accuracy: 0.8045\n",
      "Epoch 25/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3843 - binary_accuracy: 0.8157 - val_loss: 0.4058 - val_binary_accuracy: 0.8066\n",
      "Epoch 26/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3843 - binary_accuracy: 0.8118 - val_loss: 0.4045 - val_binary_accuracy: 0.8059\n",
      "Epoch 27/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3839 - binary_accuracy: 0.8139 - val_loss: 0.4087 - val_binary_accuracy: 0.8037\n",
      "Epoch 28/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3831 - binary_accuracy: 0.8141 - val_loss: 0.4079 - val_binary_accuracy: 0.8001\n",
      "Epoch 29/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3823 - binary_accuracy: 0.8138 - val_loss: 0.4084 - val_binary_accuracy: 0.8030\n",
      "Epoch 30/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3819 - binary_accuracy: 0.8168 - val_loss: 0.4075 - val_binary_accuracy: 0.8059\n",
      "Epoch 31/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3816 - binary_accuracy: 0.8170 - val_loss: 0.4095 - val_binary_accuracy: 0.8045\n",
      "Epoch 32/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3811 - binary_accuracy: 0.8204 - val_loss: 0.4094 - val_binary_accuracy: 0.8009\n",
      "Epoch 33/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3797 - binary_accuracy: 0.8157 - val_loss: 0.4122 - val_binary_accuracy: 0.8045\n",
      "Epoch 34/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3795 - binary_accuracy: 0.8134 - val_loss: 0.4084 - val_binary_accuracy: 0.8016\n",
      "Epoch 35/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3795 - binary_accuracy: 0.8181 - val_loss: 0.4066 - val_binary_accuracy: 0.8052\n",
      "Epoch 36/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3777 - binary_accuracy: 0.8186 - val_loss: 0.4135 - val_binary_accuracy: 0.8052\n",
      "Epoch 37/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3785 - binary_accuracy: 0.8183 - val_loss: 0.4129 - val_binary_accuracy: 0.8023\n",
      "Epoch 38/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3779 - binary_accuracy: 0.8161 - val_loss: 0.4105 - val_binary_accuracy: 0.8045\n",
      "Epoch 39/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3766 - binary_accuracy: 0.8195 - val_loss: 0.4110 - val_binary_accuracy: 0.8109\n",
      "Epoch 40/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3759 - binary_accuracy: 0.8170 - val_loss: 0.4086 - val_binary_accuracy: 0.8102\n",
      "Epoch 41/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3768 - binary_accuracy: 0.8172 - val_loss: 0.4121 - val_binary_accuracy: 0.8066\n",
      "Epoch 42/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3755 - binary_accuracy: 0.8195 - val_loss: 0.4109 - val_binary_accuracy: 0.8073\n",
      "Epoch 43/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3749 - binary_accuracy: 0.8168 - val_loss: 0.4144 - val_binary_accuracy: 0.8030\n",
      "Epoch 44/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3745 - binary_accuracy: 0.8206 - val_loss: 0.4117 - val_binary_accuracy: 0.8037\n",
      "Epoch 45/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3741 - binary_accuracy: 0.8181 - val_loss: 0.4110 - val_binary_accuracy: 0.8059\n",
      "Epoch 46/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3737 - binary_accuracy: 0.8193 - val_loss: 0.4097 - val_binary_accuracy: 0.8095\n",
      "Epoch 47/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3735 - binary_accuracy: 0.8206 - val_loss: 0.4112 - val_binary_accuracy: 0.8081\n",
      "Epoch 48/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3728 - binary_accuracy: 0.8197 - val_loss: 0.4120 - val_binary_accuracy: 0.8073\n",
      "Epoch 49/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3718 - binary_accuracy: 0.8204 - val_loss: 0.4146 - val_binary_accuracy: 0.8052\n",
      "Epoch 50/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3711 - binary_accuracy: 0.8208 - val_loss: 0.4148 - val_binary_accuracy: 0.8037\n",
      "Epoch 51/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3715 - binary_accuracy: 0.8195 - val_loss: 0.4134 - val_binary_accuracy: 0.8030\n",
      "Epoch 52/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8195 - val_loss: 0.4140 - val_binary_accuracy: 0.8066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3697 - binary_accuracy: 0.8213 - val_loss: 0.4161 - val_binary_accuracy: 0.8001\n",
      "Epoch 54/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3695 - binary_accuracy: 0.8204 - val_loss: 0.4150 - val_binary_accuracy: 0.8059\n",
      "Epoch 55/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3696 - binary_accuracy: 0.8224 - val_loss: 0.4166 - val_binary_accuracy: 0.8016\n",
      "Epoch 56/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3694 - binary_accuracy: 0.8192 - val_loss: 0.4155 - val_binary_accuracy: 0.8001\n",
      "Epoch 57/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3681 - binary_accuracy: 0.8228 - val_loss: 0.4173 - val_binary_accuracy: 0.7951\n",
      "Epoch 58/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3675 - binary_accuracy: 0.8251 - val_loss: 0.4183 - val_binary_accuracy: 0.8016\n",
      "Epoch 59/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3685 - binary_accuracy: 0.8220 - val_loss: 0.4183 - val_binary_accuracy: 0.8052\n",
      "Epoch 60/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3684 - binary_accuracy: 0.8238 - val_loss: 0.4171 - val_binary_accuracy: 0.7987\n",
      "Epoch 61/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3661 - binary_accuracy: 0.8231 - val_loss: 0.4183 - val_binary_accuracy: 0.8023\n",
      "Epoch 62/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3664 - binary_accuracy: 0.8240 - val_loss: 0.4184 - val_binary_accuracy: 0.8037\n",
      "Epoch 63/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3659 - binary_accuracy: 0.8217 - val_loss: 0.4207 - val_binary_accuracy: 0.8009\n",
      "Epoch 64/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3649 - binary_accuracy: 0.8262 - val_loss: 0.4216 - val_binary_accuracy: 0.7994\n",
      "Epoch 65/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3665 - binary_accuracy: 0.8249 - val_loss: 0.4241 - val_binary_accuracy: 0.7994\n",
      "Epoch 66/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3659 - binary_accuracy: 0.8235 - val_loss: 0.4195 - val_binary_accuracy: 0.8052\n",
      "Epoch 67/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3645 - binary_accuracy: 0.8258 - val_loss: 0.4205 - val_binary_accuracy: 0.7951\n",
      "Epoch 68/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3652 - binary_accuracy: 0.8247 - val_loss: 0.4219 - val_binary_accuracy: 0.8037\n",
      "Epoch 69/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3647 - binary_accuracy: 0.8219 - val_loss: 0.4222 - val_binary_accuracy: 0.8023\n",
      "Epoch 70/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3639 - binary_accuracy: 0.8226 - val_loss: 0.4240 - val_binary_accuracy: 0.7987\n",
      "Epoch 71/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3638 - binary_accuracy: 0.8242 - val_loss: 0.4240 - val_binary_accuracy: 0.8009\n",
      "Epoch 72/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3637 - binary_accuracy: 0.8242 - val_loss: 0.4215 - val_binary_accuracy: 0.8009\n",
      "Epoch 73/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3627 - binary_accuracy: 0.8251 - val_loss: 0.4254 - val_binary_accuracy: 0.8016\n",
      "Epoch 74/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3622 - binary_accuracy: 0.8244 - val_loss: 0.4193 - val_binary_accuracy: 0.8037\n",
      "Epoch 75/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3639 - binary_accuracy: 0.8217 - val_loss: 0.4225 - val_binary_accuracy: 0.8009\n",
      "Epoch 76/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3631 - binary_accuracy: 0.8255 - val_loss: 0.4256 - val_binary_accuracy: 0.7994\n",
      "Epoch 77/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3617 - binary_accuracy: 0.8226 - val_loss: 0.4240 - val_binary_accuracy: 0.8023\n",
      "Epoch 78/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3633 - binary_accuracy: 0.8255 - val_loss: 0.4236 - val_binary_accuracy: 0.8023\n",
      "Epoch 79/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8244 - val_loss: 0.4244 - val_binary_accuracy: 0.8016\n",
      "Epoch 80/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3619 - binary_accuracy: 0.8251 - val_loss: 0.4227 - val_binary_accuracy: 0.8009\n",
      "Epoch 81/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3614 - binary_accuracy: 0.8237 - val_loss: 0.4272 - val_binary_accuracy: 0.7973\n",
      "Epoch 82/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3600 - binary_accuracy: 0.8240 - val_loss: 0.4281 - val_binary_accuracy: 0.7994\n",
      "Epoch 83/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3611 - binary_accuracy: 0.8264 - val_loss: 0.4284 - val_binary_accuracy: 0.7980\n",
      "Epoch 84/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3600 - binary_accuracy: 0.8249 - val_loss: 0.4248 - val_binary_accuracy: 0.8037\n",
      "Epoch 85/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3597 - binary_accuracy: 0.8235 - val_loss: 0.4292 - val_binary_accuracy: 0.8030\n",
      "Epoch 86/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3601 - binary_accuracy: 0.8238 - val_loss: 0.4248 - val_binary_accuracy: 0.8016\n",
      "Epoch 87/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3599 - binary_accuracy: 0.8249 - val_loss: 0.4308 - val_binary_accuracy: 0.8037\n",
      "Epoch 88/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3595 - binary_accuracy: 0.8242 - val_loss: 0.4290 - val_binary_accuracy: 0.8016\n",
      "Epoch 89/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3590 - binary_accuracy: 0.8269 - val_loss: 0.4294 - val_binary_accuracy: 0.8009\n",
      "Epoch 90/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3590 - binary_accuracy: 0.8255 - val_loss: 0.4307 - val_binary_accuracy: 0.8030\n",
      "Epoch 91/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3586 - binary_accuracy: 0.8280 - val_loss: 0.4258 - val_binary_accuracy: 0.7965\n",
      "Epoch 92/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3595 - binary_accuracy: 0.8251 - val_loss: 0.4285 - val_binary_accuracy: 0.7958\n",
      "Epoch 93/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3577 - binary_accuracy: 0.8264 - val_loss: 0.4371 - val_binary_accuracy: 0.7987\n",
      "Epoch 94/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3586 - binary_accuracy: 0.8267 - val_loss: 0.4283 - val_binary_accuracy: 0.8016\n",
      "Epoch 95/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3580 - binary_accuracy: 0.8237 - val_loss: 0.4301 - val_binary_accuracy: 0.7994\n",
      "Epoch 96/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3572 - binary_accuracy: 0.8271 - val_loss: 0.4299 - val_binary_accuracy: 0.8037\n",
      "Epoch 97/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3572 - binary_accuracy: 0.8258 - val_loss: 0.4347 - val_binary_accuracy: 0.8009\n",
      "Epoch 98/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3577 - binary_accuracy: 0.8258 - val_loss: 0.4351 - val_binary_accuracy: 0.7987\n",
      "Epoch 99/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3569 - binary_accuracy: 0.8262 - val_loss: 0.4395 - val_binary_accuracy: 0.7980\n",
      "Epoch 100/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3569 - binary_accuracy: 0.8265 - val_loss: 0.4348 - val_binary_accuracy: 0.7973\n",
      "Epoch 101/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3572 - binary_accuracy: 0.8260 - val_loss: 0.4406 - val_binary_accuracy: 0.7987\n",
      "Epoch 102/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3568 - binary_accuracy: 0.8282 - val_loss: 0.4352 - val_binary_accuracy: 0.8001\n",
      "Epoch 103/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3559 - binary_accuracy: 0.8269 - val_loss: 0.4333 - val_binary_accuracy: 0.8023\n",
      "Epoch 104/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3557 - binary_accuracy: 0.8271 - val_loss: 0.4339 - val_binary_accuracy: 0.8016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3571 - binary_accuracy: 0.8249 - val_loss: 0.4370 - val_binary_accuracy: 0.8030\n",
      "Epoch 106/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3548 - binary_accuracy: 0.8258 - val_loss: 0.4356 - val_binary_accuracy: 0.7987\n",
      "Epoch 107/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3553 - binary_accuracy: 0.8274 - val_loss: 0.4375 - val_binary_accuracy: 0.7951\n",
      "Epoch 108/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3551 - binary_accuracy: 0.8264 - val_loss: 0.4342 - val_binary_accuracy: 0.8052\n",
      "Epoch 109/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8289 - val_loss: 0.4367 - val_binary_accuracy: 0.7994\n",
      "Epoch 110/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3564 - binary_accuracy: 0.8282 - val_loss: 0.4436 - val_binary_accuracy: 0.7973\n",
      "Epoch 111/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3544 - binary_accuracy: 0.8321 - val_loss: 0.4416 - val_binary_accuracy: 0.8016\n",
      "Epoch 112/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3551 - binary_accuracy: 0.8274 - val_loss: 0.4426 - val_binary_accuracy: 0.7980\n",
      "Epoch 113/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3546 - binary_accuracy: 0.8299 - val_loss: 0.4391 - val_binary_accuracy: 0.8009\n",
      "Epoch 114/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3546 - binary_accuracy: 0.8289 - val_loss: 0.4384 - val_binary_accuracy: 0.7965\n",
      "Epoch 115/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3541 - binary_accuracy: 0.8267 - val_loss: 0.4439 - val_binary_accuracy: 0.7958\n",
      "Epoch 116/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3535 - binary_accuracy: 0.8305 - val_loss: 0.4436 - val_binary_accuracy: 0.8009\n",
      "Epoch 117/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3530 - binary_accuracy: 0.8280 - val_loss: 0.4405 - val_binary_accuracy: 0.8052\n",
      "Epoch 118/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3536 - binary_accuracy: 0.8287 - val_loss: 0.4429 - val_binary_accuracy: 0.8081\n",
      "Epoch 119/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3537 - binary_accuracy: 0.8285 - val_loss: 0.4391 - val_binary_accuracy: 0.8052\n",
      "Epoch 120/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3521 - binary_accuracy: 0.8289 - val_loss: 0.4478 - val_binary_accuracy: 0.7915\n",
      "Epoch 121/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3549 - binary_accuracy: 0.8274 - val_loss: 0.4422 - val_binary_accuracy: 0.7980\n",
      "Epoch 122/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3536 - binary_accuracy: 0.8289 - val_loss: 0.4424 - val_binary_accuracy: 0.8023\n",
      "Epoch 123/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3529 - binary_accuracy: 0.8305 - val_loss: 0.4421 - val_binary_accuracy: 0.7973\n",
      "Epoch 124/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3521 - binary_accuracy: 0.8326 - val_loss: 0.4430 - val_binary_accuracy: 0.8001\n",
      "Epoch 125/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3524 - binary_accuracy: 0.8262 - val_loss: 0.4409 - val_binary_accuracy: 0.8001\n",
      "Epoch 126/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3526 - binary_accuracy: 0.8278 - val_loss: 0.4410 - val_binary_accuracy: 0.7980\n",
      "Epoch 127/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3521 - binary_accuracy: 0.8258 - val_loss: 0.4440 - val_binary_accuracy: 0.8009\n",
      "Epoch 128/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3518 - binary_accuracy: 0.8310 - val_loss: 0.4443 - val_binary_accuracy: 0.7973\n",
      "Epoch 129/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3526 - binary_accuracy: 0.8274 - val_loss: 0.4466 - val_binary_accuracy: 0.7973\n",
      "Epoch 130/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3512 - binary_accuracy: 0.8296 - val_loss: 0.4476 - val_binary_accuracy: 0.8016\n",
      "Epoch 131/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3518 - binary_accuracy: 0.8296 - val_loss: 0.4445 - val_binary_accuracy: 0.7994\n",
      "Epoch 132/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3510 - binary_accuracy: 0.8299 - val_loss: 0.4421 - val_binary_accuracy: 0.7965\n",
      "Epoch 133/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3507 - binary_accuracy: 0.8285 - val_loss: 0.4488 - val_binary_accuracy: 0.7980\n",
      "Epoch 134/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3517 - binary_accuracy: 0.8314 - val_loss: 0.4464 - val_binary_accuracy: 0.8045\n",
      "Epoch 135/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3507 - binary_accuracy: 0.8289 - val_loss: 0.4464 - val_binary_accuracy: 0.7965\n",
      "Epoch 136/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8307 - val_loss: 0.4446 - val_binary_accuracy: 0.7987\n",
      "Epoch 137/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3501 - binary_accuracy: 0.8303 - val_loss: 0.4466 - val_binary_accuracy: 0.8045\n",
      "Epoch 138/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3501 - binary_accuracy: 0.8325 - val_loss: 0.4513 - val_binary_accuracy: 0.7958\n",
      "Epoch 139/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3500 - binary_accuracy: 0.8298 - val_loss: 0.4493 - val_binary_accuracy: 0.8023\n",
      "Epoch 140/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3498 - binary_accuracy: 0.8314 - val_loss: 0.4479 - val_binary_accuracy: 0.7980\n",
      "Epoch 141/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3500 - binary_accuracy: 0.8316 - val_loss: 0.4482 - val_binary_accuracy: 0.8059\n",
      "Epoch 142/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3496 - binary_accuracy: 0.8289 - val_loss: 0.4504 - val_binary_accuracy: 0.8001\n",
      "Epoch 143/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3490 - binary_accuracy: 0.8307 - val_loss: 0.4487 - val_binary_accuracy: 0.8016\n",
      "Epoch 144/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3492 - binary_accuracy: 0.8289 - val_loss: 0.4477 - val_binary_accuracy: 0.8073\n",
      "Epoch 145/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3481 - binary_accuracy: 0.8305 - val_loss: 0.4495 - val_binary_accuracy: 0.8009\n",
      "Epoch 146/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3491 - binary_accuracy: 0.8310 - val_loss: 0.4514 - val_binary_accuracy: 0.8023\n",
      "Epoch 147/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8303 - val_loss: 0.4545 - val_binary_accuracy: 0.8001\n",
      "Epoch 148/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3483 - binary_accuracy: 0.8296 - val_loss: 0.4450 - val_binary_accuracy: 0.8045\n",
      "Epoch 149/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3483 - binary_accuracy: 0.8326 - val_loss: 0.4537 - val_binary_accuracy: 0.7994\n",
      "Epoch 150/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3480 - binary_accuracy: 0.8316 - val_loss: 0.4501 - val_binary_accuracy: 0.8001\n",
      "Epoch 151/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3484 - binary_accuracy: 0.8335 - val_loss: 0.4520 - val_binary_accuracy: 0.8016\n",
      "Epoch 152/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3482 - binary_accuracy: 0.8321 - val_loss: 0.4498 - val_binary_accuracy: 0.8037\n",
      "Epoch 153/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3482 - binary_accuracy: 0.8352 - val_loss: 0.4513 - val_binary_accuracy: 0.7980\n",
      "Epoch 154/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3477 - binary_accuracy: 0.8294 - val_loss: 0.4506 - val_binary_accuracy: 0.8023\n",
      "Epoch 155/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3475 - binary_accuracy: 0.8326 - val_loss: 0.4503 - val_binary_accuracy: 0.8045\n",
      "Epoch 156/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3476 - binary_accuracy: 0.8298 - val_loss: 0.4542 - val_binary_accuracy: 0.7980\n",
      "Epoch 157/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3466 - binary_accuracy: 0.8310 - val_loss: 0.4535 - val_binary_accuracy: 0.7980\n",
      "Epoch 158/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3464 - binary_accuracy: 0.8308 - val_loss: 0.4501 - val_binary_accuracy: 0.8009\n",
      "Epoch 159/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3469 - binary_accuracy: 0.8307 - val_loss: 0.4494 - val_binary_accuracy: 0.7994\n",
      "Epoch 160/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3458 - binary_accuracy: 0.8312 - val_loss: 0.4582 - val_binary_accuracy: 0.7987\n",
      "Epoch 161/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3474 - binary_accuracy: 0.8310 - val_loss: 0.4538 - val_binary_accuracy: 0.7987\n",
      "Epoch 162/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3465 - binary_accuracy: 0.8307 - val_loss: 0.4540 - val_binary_accuracy: 0.8023\n",
      "Epoch 163/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3466 - binary_accuracy: 0.8323 - val_loss: 0.4579 - val_binary_accuracy: 0.7965\n",
      "Epoch 164/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3466 - binary_accuracy: 0.8325 - val_loss: 0.4538 - val_binary_accuracy: 0.7965\n",
      "Epoch 165/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3460 - binary_accuracy: 0.8314 - val_loss: 0.4520 - val_binary_accuracy: 0.8016\n",
      "Epoch 166/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3465 - binary_accuracy: 0.8283 - val_loss: 0.4510 - val_binary_accuracy: 0.8009\n",
      "Epoch 167/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3452 - binary_accuracy: 0.8346 - val_loss: 0.4533 - val_binary_accuracy: 0.7994\n",
      "Epoch 168/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3448 - binary_accuracy: 0.8332 - val_loss: 0.4571 - val_binary_accuracy: 0.7951\n",
      "Epoch 169/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3456 - binary_accuracy: 0.8312 - val_loss: 0.4553 - val_binary_accuracy: 0.7930\n",
      "Epoch 170/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3461 - binary_accuracy: 0.8334 - val_loss: 0.4591 - val_binary_accuracy: 0.8023\n",
      "Epoch 171/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3438 - binary_accuracy: 0.8337 - val_loss: 0.4592 - val_binary_accuracy: 0.7965\n",
      "Epoch 172/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3446 - binary_accuracy: 0.8328 - val_loss: 0.4556 - val_binary_accuracy: 0.7973\n",
      "Epoch 173/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3458 - binary_accuracy: 0.8328 - val_loss: 0.4544 - val_binary_accuracy: 0.8009\n",
      "Epoch 174/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3451 - binary_accuracy: 0.8339 - val_loss: 0.4556 - val_binary_accuracy: 0.7951\n",
      "Epoch 175/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3436 - binary_accuracy: 0.8341 - val_loss: 0.4578 - val_binary_accuracy: 0.7994\n",
      "Epoch 176/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3445 - binary_accuracy: 0.8319 - val_loss: 0.4615 - val_binary_accuracy: 0.8001\n",
      "Epoch 177/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3455 - binary_accuracy: 0.8321 - val_loss: 0.4573 - val_binary_accuracy: 0.8009\n",
      "Epoch 178/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3441 - binary_accuracy: 0.8321 - val_loss: 0.4545 - val_binary_accuracy: 0.7922\n",
      "Epoch 179/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3452 - binary_accuracy: 0.8337 - val_loss: 0.4568 - val_binary_accuracy: 0.7994\n",
      "Epoch 180/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3433 - binary_accuracy: 0.8368 - val_loss: 0.4549 - val_binary_accuracy: 0.7915\n",
      "Epoch 181/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3435 - binary_accuracy: 0.8328 - val_loss: 0.4559 - val_binary_accuracy: 0.7980\n",
      "Epoch 182/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3426 - binary_accuracy: 0.8330 - val_loss: 0.4551 - val_binary_accuracy: 0.7987\n",
      "Epoch 183/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3426 - binary_accuracy: 0.8316 - val_loss: 0.4581 - val_binary_accuracy: 0.7951\n",
      "Epoch 184/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8319 - val_loss: 0.4574 - val_binary_accuracy: 0.7980\n",
      "Epoch 185/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8339 - val_loss: 0.4554 - val_binary_accuracy: 0.8009\n",
      "Epoch 186/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8301 - val_loss: 0.4611 - val_binary_accuracy: 0.7958\n",
      "Epoch 187/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8319 - val_loss: 0.4577 - val_binary_accuracy: 0.7987\n",
      "Epoch 188/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8298 - val_loss: 0.4574 - val_binary_accuracy: 0.7965\n",
      "Epoch 189/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3424 - binary_accuracy: 0.8357 - val_loss: 0.4582 - val_binary_accuracy: 0.8016\n",
      "Epoch 190/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8348 - val_loss: 0.4607 - val_binary_accuracy: 0.8001\n",
      "Epoch 191/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3424 - binary_accuracy: 0.8355 - val_loss: 0.4616 - val_binary_accuracy: 0.7944\n",
      "Epoch 192/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8341 - val_loss: 0.4646 - val_binary_accuracy: 0.8009\n",
      "Epoch 193/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8344 - val_loss: 0.4625 - val_binary_accuracy: 0.8023\n",
      "Epoch 194/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3418 - binary_accuracy: 0.8328 - val_loss: 0.4657 - val_binary_accuracy: 0.7973\n",
      "Epoch 195/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8337 - val_loss: 0.4608 - val_binary_accuracy: 0.8016\n",
      "Epoch 196/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8362 - val_loss: 0.4600 - val_binary_accuracy: 0.7958\n",
      "Epoch 197/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3411 - binary_accuracy: 0.8361 - val_loss: 0.4633 - val_binary_accuracy: 0.7987\n",
      "Epoch 198/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3419 - binary_accuracy: 0.8326 - val_loss: 0.4610 - val_binary_accuracy: 0.7973\n",
      "Epoch 199/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3417 - binary_accuracy: 0.8344 - val_loss: 0.4606 - val_binary_accuracy: 0.8045\n",
      "Epoch 200/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3409 - binary_accuracy: 0.8325 - val_loss: 0.4637 - val_binary_accuracy: 0.8037\n",
      "Epoch 201/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8335 - val_loss: 0.4630 - val_binary_accuracy: 0.8030\n",
      "Epoch 202/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8344 - val_loss: 0.4622 - val_binary_accuracy: 0.8037\n",
      "Epoch 203/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3406 - binary_accuracy: 0.8334 - val_loss: 0.4687 - val_binary_accuracy: 0.7973\n",
      "Epoch 204/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3399 - binary_accuracy: 0.8337 - val_loss: 0.4666 - val_binary_accuracy: 0.7980\n",
      "Epoch 205/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3402 - binary_accuracy: 0.8344 - val_loss: 0.4682 - val_binary_accuracy: 0.8009\n",
      "Epoch 206/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3402 - binary_accuracy: 0.8330 - val_loss: 0.4690 - val_binary_accuracy: 0.7894\n",
      "Epoch 207/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3405 - binary_accuracy: 0.8384 - val_loss: 0.4644 - val_binary_accuracy: 0.8001\n",
      "Epoch 208/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8355 - val_loss: 0.4657 - val_binary_accuracy: 0.7937\n",
      "Epoch 209/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3411 - binary_accuracy: 0.8325 - val_loss: 0.4690 - val_binary_accuracy: 0.8037\n",
      "Epoch 210/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3404 - binary_accuracy: 0.8341 - val_loss: 0.4710 - val_binary_accuracy: 0.8030\n",
      "Epoch 211/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3384 - binary_accuracy: 0.8366 - val_loss: 0.4660 - val_binary_accuracy: 0.7994\n",
      "Epoch 212/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8350 - val_loss: 0.4643 - val_binary_accuracy: 0.7994\n",
      "Epoch 213/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3401 - binary_accuracy: 0.8330 - val_loss: 0.4655 - val_binary_accuracy: 0.8001\n",
      "Epoch 214/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3393 - binary_accuracy: 0.8339 - val_loss: 0.4655 - val_binary_accuracy: 0.7994\n",
      "Epoch 215/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3389 - binary_accuracy: 0.8348 - val_loss: 0.4645 - val_binary_accuracy: 0.7965\n",
      "Epoch 216/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3378 - binary_accuracy: 0.8377 - val_loss: 0.4689 - val_binary_accuracy: 0.8001\n",
      "Epoch 217/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3398 - binary_accuracy: 0.8332 - val_loss: 0.4648 - val_binary_accuracy: 0.8037\n",
      "Epoch 218/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3384 - binary_accuracy: 0.8375 - val_loss: 0.4632 - val_binary_accuracy: 0.7951\n",
      "Epoch 219/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3393 - binary_accuracy: 0.8380 - val_loss: 0.4695 - val_binary_accuracy: 0.7958\n",
      "Epoch 220/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3391 - binary_accuracy: 0.8355 - val_loss: 0.4672 - val_binary_accuracy: 0.7965\n",
      "Epoch 221/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3380 - binary_accuracy: 0.8364 - val_loss: 0.4688 - val_binary_accuracy: 0.8023\n",
      "Epoch 222/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3396 - binary_accuracy: 0.8316 - val_loss: 0.4672 - val_binary_accuracy: 0.7987\n",
      "Epoch 223/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3382 - binary_accuracy: 0.8357 - val_loss: 0.4684 - val_binary_accuracy: 0.7951\n",
      "Epoch 224/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3387 - binary_accuracy: 0.8352 - val_loss: 0.4706 - val_binary_accuracy: 0.7980\n",
      "Epoch 225/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3367 - binary_accuracy: 0.8407 - val_loss: 0.4676 - val_binary_accuracy: 0.7994\n",
      "Epoch 226/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3373 - binary_accuracy: 0.8353 - val_loss: 0.4673 - val_binary_accuracy: 0.8001\n",
      "Epoch 227/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3384 - binary_accuracy: 0.8375 - val_loss: 0.4648 - val_binary_accuracy: 0.7915\n",
      "Epoch 228/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3399 - binary_accuracy: 0.8334 - val_loss: 0.4675 - val_binary_accuracy: 0.8030\n",
      "Epoch 229/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3372 - binary_accuracy: 0.8348 - val_loss: 0.4730 - val_binary_accuracy: 0.7994\n",
      "Epoch 230/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3371 - binary_accuracy: 0.8355 - val_loss: 0.4731 - val_binary_accuracy: 0.8016\n",
      "Epoch 231/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3375 - binary_accuracy: 0.8362 - val_loss: 0.4690 - val_binary_accuracy: 0.7980\n",
      "Epoch 232/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3373 - binary_accuracy: 0.8332 - val_loss: 0.4693 - val_binary_accuracy: 0.7930\n",
      "Epoch 233/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3368 - binary_accuracy: 0.8380 - val_loss: 0.4745 - val_binary_accuracy: 0.8001\n",
      "Epoch 234/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8371 - val_loss: 0.4703 - val_binary_accuracy: 0.7937\n",
      "Epoch 235/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3366 - binary_accuracy: 0.8371 - val_loss: 0.4702 - val_binary_accuracy: 0.8001\n",
      "Epoch 236/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3380 - binary_accuracy: 0.8393 - val_loss: 0.4706 - val_binary_accuracy: 0.7994\n",
      "Epoch 237/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3364 - binary_accuracy: 0.8388 - val_loss: 0.4726 - val_binary_accuracy: 0.7980\n",
      "Epoch 238/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3368 - binary_accuracy: 0.8395 - val_loss: 0.4705 - val_binary_accuracy: 0.8030\n",
      "Epoch 239/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3374 - binary_accuracy: 0.8346 - val_loss: 0.4732 - val_binary_accuracy: 0.7965\n",
      "Epoch 240/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3368 - binary_accuracy: 0.8391 - val_loss: 0.4727 - val_binary_accuracy: 0.7973\n",
      "Epoch 241/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3360 - binary_accuracy: 0.8335 - val_loss: 0.4718 - val_binary_accuracy: 0.7987\n",
      "Epoch 242/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3359 - binary_accuracy: 0.8386 - val_loss: 0.4726 - val_binary_accuracy: 0.8016\n",
      "Epoch 243/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3357 - binary_accuracy: 0.8362 - val_loss: 0.4700 - val_binary_accuracy: 0.7973\n",
      "Epoch 244/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3352 - binary_accuracy: 0.8370 - val_loss: 0.4703 - val_binary_accuracy: 0.7980\n",
      "Epoch 245/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3359 - binary_accuracy: 0.8395 - val_loss: 0.4712 - val_binary_accuracy: 0.7987\n",
      "Epoch 246/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8357 - val_loss: 0.4740 - val_binary_accuracy: 0.7973\n",
      "Epoch 247/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3354 - binary_accuracy: 0.8371 - val_loss: 0.4748 - val_binary_accuracy: 0.7980\n",
      "Epoch 248/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3360 - binary_accuracy: 0.8379 - val_loss: 0.4756 - val_binary_accuracy: 0.7987\n",
      "Epoch 249/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3346 - binary_accuracy: 0.8386 - val_loss: 0.4752 - val_binary_accuracy: 0.7944\n",
      "Epoch 250/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3347 - binary_accuracy: 0.8373 - val_loss: 0.4756 - val_binary_accuracy: 0.7987\n",
      "Epoch 251/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3347 - binary_accuracy: 0.8352 - val_loss: 0.4808 - val_binary_accuracy: 0.7951\n",
      "Epoch 252/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3344 - binary_accuracy: 0.8388 - val_loss: 0.4767 - val_binary_accuracy: 0.7937\n",
      "Epoch 253/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3340 - binary_accuracy: 0.8380 - val_loss: 0.4796 - val_binary_accuracy: 0.7973\n",
      "Epoch 254/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3346 - binary_accuracy: 0.8370 - val_loss: 0.4771 - val_binary_accuracy: 0.7951\n",
      "Epoch 255/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3353 - binary_accuracy: 0.8350 - val_loss: 0.4788 - val_binary_accuracy: 0.7908\n",
      "Epoch 256/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3358 - binary_accuracy: 0.8420 - val_loss: 0.4720 - val_binary_accuracy: 0.7886\n",
      "Epoch 257/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3348 - binary_accuracy: 0.8379 - val_loss: 0.4745 - val_binary_accuracy: 0.7915\n",
      "Epoch 258/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3339 - binary_accuracy: 0.8389 - val_loss: 0.4807 - val_binary_accuracy: 0.7908\n",
      "Epoch 259/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3334 - binary_accuracy: 0.8404 - val_loss: 0.4739 - val_binary_accuracy: 0.7958\n",
      "Epoch 260/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3340 - binary_accuracy: 0.8371 - val_loss: 0.4777 - val_binary_accuracy: 0.7908\n",
      "Epoch 261/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3340 - binary_accuracy: 0.8382 - val_loss: 0.4832 - val_binary_accuracy: 0.7944\n",
      "Epoch 262/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3350 - binary_accuracy: 0.8371 - val_loss: 0.4827 - val_binary_accuracy: 0.7922\n",
      "Epoch 263/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3334 - binary_accuracy: 0.8368 - val_loss: 0.4802 - val_binary_accuracy: 0.7958\n",
      "Epoch 264/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3342 - binary_accuracy: 0.8377 - val_loss: 0.4807 - val_binary_accuracy: 0.7973\n",
      "Epoch 265/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3338 - binary_accuracy: 0.8379 - val_loss: 0.4800 - val_binary_accuracy: 0.7872\n",
      "Epoch 266/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3333 - binary_accuracy: 0.8339 - val_loss: 0.4789 - val_binary_accuracy: 0.7930\n",
      "Epoch 267/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3331 - binary_accuracy: 0.8391 - val_loss: 0.4810 - val_binary_accuracy: 0.7937\n",
      "Epoch 268/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3328 - binary_accuracy: 0.8391 - val_loss: 0.4828 - val_binary_accuracy: 0.7944\n",
      "Epoch 269/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3319 - binary_accuracy: 0.8389 - val_loss: 0.4861 - val_binary_accuracy: 0.7843\n",
      "Epoch 270/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3333 - binary_accuracy: 0.8384 - val_loss: 0.4825 - val_binary_accuracy: 0.7965\n",
      "Epoch 271/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3327 - binary_accuracy: 0.8379 - val_loss: 0.4808 - val_binary_accuracy: 0.7965\n",
      "Epoch 272/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3330 - binary_accuracy: 0.8384 - val_loss: 0.4870 - val_binary_accuracy: 0.7973\n",
      "Epoch 273/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3326 - binary_accuracy: 0.8386 - val_loss: 0.4814 - val_binary_accuracy: 0.7915\n",
      "Epoch 274/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3317 - binary_accuracy: 0.8415 - val_loss: 0.4822 - val_binary_accuracy: 0.7922\n",
      "Epoch 275/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3339 - binary_accuracy: 0.8382 - val_loss: 0.4849 - val_binary_accuracy: 0.7937\n",
      "Epoch 276/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3319 - binary_accuracy: 0.8397 - val_loss: 0.4880 - val_binary_accuracy: 0.7922\n",
      "Epoch 277/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3323 - binary_accuracy: 0.8382 - val_loss: 0.4837 - val_binary_accuracy: 0.7886\n",
      "Epoch 278/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3308 - binary_accuracy: 0.8404 - val_loss: 0.4884 - val_binary_accuracy: 0.7930\n",
      "Epoch 279/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3319 - binary_accuracy: 0.8382 - val_loss: 0.4854 - val_binary_accuracy: 0.7915\n",
      "Epoch 280/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3317 - binary_accuracy: 0.8380 - val_loss: 0.4859 - val_binary_accuracy: 0.7937\n",
      "Epoch 281/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3323 - binary_accuracy: 0.8413 - val_loss: 0.4905 - val_binary_accuracy: 0.7915\n",
      "Epoch 282/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3326 - binary_accuracy: 0.8379 - val_loss: 0.4856 - val_binary_accuracy: 0.7937\n",
      "Epoch 283/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8404 - val_loss: 0.4906 - val_binary_accuracy: 0.7937\n",
      "Epoch 284/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3308 - binary_accuracy: 0.8377 - val_loss: 0.4834 - val_binary_accuracy: 0.7836\n",
      "Epoch 285/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3312 - binary_accuracy: 0.8388 - val_loss: 0.4974 - val_binary_accuracy: 0.7886\n",
      "Epoch 286/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3313 - binary_accuracy: 0.8409 - val_loss: 0.4861 - val_binary_accuracy: 0.7894\n",
      "Epoch 287/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3315 - binary_accuracy: 0.8411 - val_loss: 0.4900 - val_binary_accuracy: 0.7886\n",
      "Epoch 288/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3296 - binary_accuracy: 0.8425 - val_loss: 0.4881 - val_binary_accuracy: 0.7908\n",
      "Epoch 289/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8379 - val_loss: 0.4954 - val_binary_accuracy: 0.7850\n",
      "Epoch 290/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3286 - binary_accuracy: 0.8377 - val_loss: 0.4917 - val_binary_accuracy: 0.7886\n",
      "Epoch 291/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3307 - binary_accuracy: 0.8393 - val_loss: 0.4881 - val_binary_accuracy: 0.7915\n",
      "Epoch 292/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3309 - binary_accuracy: 0.8395 - val_loss: 0.4892 - val_binary_accuracy: 0.7901\n",
      "Epoch 293/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3306 - binary_accuracy: 0.8382 - val_loss: 0.4931 - val_binary_accuracy: 0.7894\n",
      "Epoch 294/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3296 - binary_accuracy: 0.8425 - val_loss: 0.4876 - val_binary_accuracy: 0.7915\n",
      "Epoch 295/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3297 - binary_accuracy: 0.8397 - val_loss: 0.4928 - val_binary_accuracy: 0.7944\n",
      "Epoch 296/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3289 - binary_accuracy: 0.8427 - val_loss: 0.4955 - val_binary_accuracy: 0.7908\n",
      "Epoch 297/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3300 - binary_accuracy: 0.8400 - val_loss: 0.4974 - val_binary_accuracy: 0.7858\n",
      "Epoch 298/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3302 - binary_accuracy: 0.8406 - val_loss: 0.4956 - val_binary_accuracy: 0.7908\n",
      "Epoch 299/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3293 - binary_accuracy: 0.8429 - val_loss: 0.4903 - val_binary_accuracy: 0.7865\n",
      "Epoch 300/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3299 - binary_accuracy: 0.8393 - val_loss: 0.4953 - val_binary_accuracy: 0.7987\n",
      "Epoch 301/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3299 - binary_accuracy: 0.8393 - val_loss: 0.4924 - val_binary_accuracy: 0.7886\n",
      "Epoch 302/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3295 - binary_accuracy: 0.8411 - val_loss: 0.4994 - val_binary_accuracy: 0.7922\n",
      "Epoch 303/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3281 - binary_accuracy: 0.8404 - val_loss: 0.4963 - val_binary_accuracy: 0.7901\n",
      "Epoch 304/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3297 - binary_accuracy: 0.8422 - val_loss: 0.4997 - val_binary_accuracy: 0.7915\n",
      "Epoch 305/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3281 - binary_accuracy: 0.8427 - val_loss: 0.4968 - val_binary_accuracy: 0.7865\n",
      "Epoch 306/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3315 - binary_accuracy: 0.8375 - val_loss: 0.4936 - val_binary_accuracy: 0.7901\n",
      "Epoch 307/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3279 - binary_accuracy: 0.8380 - val_loss: 0.5028 - val_binary_accuracy: 0.7865\n",
      "Epoch 308/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3298 - binary_accuracy: 0.8400 - val_loss: 0.4989 - val_binary_accuracy: 0.7886\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3283 - binary_accuracy: 0.8375 - val_loss: 0.4960 - val_binary_accuracy: 0.7922\n",
      "Epoch 310/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3277 - binary_accuracy: 0.8413 - val_loss: 0.4975 - val_binary_accuracy: 0.7886\n",
      "Epoch 311/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3276 - binary_accuracy: 0.8418 - val_loss: 0.4962 - val_binary_accuracy: 0.7915\n",
      "Epoch 312/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3274 - binary_accuracy: 0.8398 - val_loss: 0.4988 - val_binary_accuracy: 0.7908\n",
      "Epoch 313/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3278 - binary_accuracy: 0.8406 - val_loss: 0.4928 - val_binary_accuracy: 0.7930\n",
      "Epoch 314/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3278 - binary_accuracy: 0.8407 - val_loss: 0.4962 - val_binary_accuracy: 0.7930\n",
      "Epoch 315/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3267 - binary_accuracy: 0.8454 - val_loss: 0.4990 - val_binary_accuracy: 0.7894\n",
      "Epoch 316/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3281 - binary_accuracy: 0.8413 - val_loss: 0.4923 - val_binary_accuracy: 0.7944\n",
      "Epoch 317/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3272 - binary_accuracy: 0.8438 - val_loss: 0.4954 - val_binary_accuracy: 0.7894\n",
      "Epoch 318/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3260 - binary_accuracy: 0.8447 - val_loss: 0.5010 - val_binary_accuracy: 0.7958\n",
      "Epoch 319/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3275 - binary_accuracy: 0.8398 - val_loss: 0.5004 - val_binary_accuracy: 0.7879\n",
      "Epoch 320/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3268 - binary_accuracy: 0.8443 - val_loss: 0.4982 - val_binary_accuracy: 0.7908\n",
      "Epoch 321/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3268 - binary_accuracy: 0.8413 - val_loss: 0.5007 - val_binary_accuracy: 0.7858\n",
      "Epoch 322/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3280 - binary_accuracy: 0.8413 - val_loss: 0.5005 - val_binary_accuracy: 0.7922\n",
      "Epoch 323/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3280 - binary_accuracy: 0.8406 - val_loss: 0.5069 - val_binary_accuracy: 0.7922\n",
      "Epoch 324/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3266 - binary_accuracy: 0.8406 - val_loss: 0.4981 - val_binary_accuracy: 0.7901\n",
      "Epoch 325/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3268 - binary_accuracy: 0.8402 - val_loss: 0.5025 - val_binary_accuracy: 0.7973\n",
      "Epoch 326/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3271 - binary_accuracy: 0.8422 - val_loss: 0.5046 - val_binary_accuracy: 0.7937\n",
      "Epoch 327/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3278 - binary_accuracy: 0.8440 - val_loss: 0.5021 - val_binary_accuracy: 0.7908\n",
      "Epoch 328/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3271 - binary_accuracy: 0.8418 - val_loss: 0.5075 - val_binary_accuracy: 0.7879\n",
      "Epoch 329/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3264 - binary_accuracy: 0.8443 - val_loss: 0.5032 - val_binary_accuracy: 0.7865\n",
      "Epoch 330/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3260 - binary_accuracy: 0.8420 - val_loss: 0.5006 - val_binary_accuracy: 0.7894\n",
      "Epoch 331/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3261 - binary_accuracy: 0.8400 - val_loss: 0.5050 - val_binary_accuracy: 0.7894\n",
      "Epoch 332/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3268 - binary_accuracy: 0.8438 - val_loss: 0.5105 - val_binary_accuracy: 0.7872\n",
      "Epoch 333/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3263 - binary_accuracy: 0.8404 - val_loss: 0.5023 - val_binary_accuracy: 0.7908\n",
      "Epoch 334/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3261 - binary_accuracy: 0.8429 - val_loss: 0.5034 - val_binary_accuracy: 0.7858\n",
      "Epoch 335/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3254 - binary_accuracy: 0.8420 - val_loss: 0.5045 - val_binary_accuracy: 0.7858\n",
      "Epoch 336/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3258 - binary_accuracy: 0.8400 - val_loss: 0.5045 - val_binary_accuracy: 0.7879\n",
      "Epoch 337/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3243 - binary_accuracy: 0.8441 - val_loss: 0.5119 - val_binary_accuracy: 0.7865\n",
      "Epoch 338/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3237 - binary_accuracy: 0.8458 - val_loss: 0.5129 - val_binary_accuracy: 0.7915\n",
      "Epoch 339/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3256 - binary_accuracy: 0.8402 - val_loss: 0.5027 - val_binary_accuracy: 0.7872\n",
      "Epoch 340/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3244 - binary_accuracy: 0.8427 - val_loss: 0.5135 - val_binary_accuracy: 0.7930\n",
      "Epoch 341/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3262 - binary_accuracy: 0.8395 - val_loss: 0.5029 - val_binary_accuracy: 0.7879\n",
      "Epoch 342/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3253 - binary_accuracy: 0.8429 - val_loss: 0.5100 - val_binary_accuracy: 0.7858\n",
      "Epoch 343/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3251 - binary_accuracy: 0.8424 - val_loss: 0.5069 - val_binary_accuracy: 0.7886\n",
      "Epoch 344/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3253 - binary_accuracy: 0.8431 - val_loss: 0.5132 - val_binary_accuracy: 0.7858\n",
      "Epoch 345/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3253 - binary_accuracy: 0.8407 - val_loss: 0.5064 - val_binary_accuracy: 0.7858\n",
      "Epoch 346/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3247 - binary_accuracy: 0.8420 - val_loss: 0.5106 - val_binary_accuracy: 0.7937\n",
      "Epoch 347/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3253 - binary_accuracy: 0.8407 - val_loss: 0.5099 - val_binary_accuracy: 0.7850\n",
      "Epoch 348/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3266 - binary_accuracy: 0.8418 - val_loss: 0.5060 - val_binary_accuracy: 0.7872\n",
      "Epoch 349/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3230 - binary_accuracy: 0.8434 - val_loss: 0.5059 - val_binary_accuracy: 0.7922\n",
      "Epoch 350/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3229 - binary_accuracy: 0.8447 - val_loss: 0.5054 - val_binary_accuracy: 0.7901\n",
      "Epoch 351/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3248 - binary_accuracy: 0.8416 - val_loss: 0.5110 - val_binary_accuracy: 0.7886\n",
      "Epoch 352/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3236 - binary_accuracy: 0.8429 - val_loss: 0.5167 - val_binary_accuracy: 0.7886\n",
      "Epoch 353/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3244 - binary_accuracy: 0.8438 - val_loss: 0.5097 - val_binary_accuracy: 0.7879\n",
      "Epoch 354/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3229 - binary_accuracy: 0.8450 - val_loss: 0.5082 - val_binary_accuracy: 0.7901\n",
      "Epoch 355/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3227 - binary_accuracy: 0.8415 - val_loss: 0.5164 - val_binary_accuracy: 0.7908\n",
      "Epoch 356/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3250 - binary_accuracy: 0.8388 - val_loss: 0.5144 - val_binary_accuracy: 0.7937\n",
      "Epoch 357/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3262 - binary_accuracy: 0.8443 - val_loss: 0.5060 - val_binary_accuracy: 0.7865\n",
      "Epoch 358/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3239 - binary_accuracy: 0.8438 - val_loss: 0.5158 - val_binary_accuracy: 0.7872\n",
      "Epoch 359/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3242 - binary_accuracy: 0.8420 - val_loss: 0.5209 - val_binary_accuracy: 0.7958\n",
      "Epoch 360/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3244 - binary_accuracy: 0.8443 - val_loss: 0.5140 - val_binary_accuracy: 0.7922\n",
      "Epoch 361/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3240 - binary_accuracy: 0.8424 - val_loss: 0.5138 - val_binary_accuracy: 0.7843\n",
      "Epoch 362/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3232 - binary_accuracy: 0.8433 - val_loss: 0.5228 - val_binary_accuracy: 0.7965\n",
      "Epoch 363/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3241 - binary_accuracy: 0.8440 - val_loss: 0.5159 - val_binary_accuracy: 0.7872\n",
      "Epoch 364/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3239 - binary_accuracy: 0.8429 - val_loss: 0.5143 - val_binary_accuracy: 0.7879\n",
      "Epoch 365/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3244 - binary_accuracy: 0.8440 - val_loss: 0.5202 - val_binary_accuracy: 0.7822\n",
      "Epoch 366/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3244 - binary_accuracy: 0.8429 - val_loss: 0.5085 - val_binary_accuracy: 0.7915\n",
      "Epoch 367/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3245 - binary_accuracy: 0.8425 - val_loss: 0.5123 - val_binary_accuracy: 0.7850\n",
      "Epoch 368/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3226 - binary_accuracy: 0.8443 - val_loss: 0.5301 - val_binary_accuracy: 0.7894\n",
      "Epoch 369/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3246 - binary_accuracy: 0.8422 - val_loss: 0.5126 - val_binary_accuracy: 0.7886\n",
      "Epoch 370/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3224 - binary_accuracy: 0.8416 - val_loss: 0.5109 - val_binary_accuracy: 0.7879\n",
      "Epoch 371/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3237 - binary_accuracy: 0.8424 - val_loss: 0.5171 - val_binary_accuracy: 0.7879\n",
      "Epoch 372/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3243 - binary_accuracy: 0.8436 - val_loss: 0.5167 - val_binary_accuracy: 0.7915\n",
      "Epoch 373/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3254 - binary_accuracy: 0.8443 - val_loss: 0.5099 - val_binary_accuracy: 0.7915\n",
      "Epoch 374/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3229 - binary_accuracy: 0.8389 - val_loss: 0.5162 - val_binary_accuracy: 0.7858\n",
      "Epoch 375/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3227 - binary_accuracy: 0.8418 - val_loss: 0.5157 - val_binary_accuracy: 0.7807\n",
      "Epoch 376/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3227 - binary_accuracy: 0.8447 - val_loss: 0.5209 - val_binary_accuracy: 0.7793\n",
      "Epoch 377/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3243 - binary_accuracy: 0.8420 - val_loss: 0.5168 - val_binary_accuracy: 0.7908\n",
      "Epoch 378/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3220 - binary_accuracy: 0.8424 - val_loss: 0.5182 - val_binary_accuracy: 0.7894\n",
      "Epoch 379/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3214 - binary_accuracy: 0.8436 - val_loss: 0.5137 - val_binary_accuracy: 0.7779\n",
      "Epoch 380/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3239 - binary_accuracy: 0.8416 - val_loss: 0.5185 - val_binary_accuracy: 0.7850\n",
      "Epoch 381/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3227 - binary_accuracy: 0.8474 - val_loss: 0.5211 - val_binary_accuracy: 0.7901\n",
      "Epoch 382/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3237 - binary_accuracy: 0.8407 - val_loss: 0.5207 - val_binary_accuracy: 0.7915\n",
      "Epoch 383/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3230 - binary_accuracy: 0.8420 - val_loss: 0.5141 - val_binary_accuracy: 0.7930\n",
      "Epoch 384/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3229 - binary_accuracy: 0.8427 - val_loss: 0.5220 - val_binary_accuracy: 0.7901\n",
      "Epoch 385/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3236 - binary_accuracy: 0.8409 - val_loss: 0.5217 - val_binary_accuracy: 0.7944\n",
      "Epoch 386/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3213 - binary_accuracy: 0.8434 - val_loss: 0.5130 - val_binary_accuracy: 0.7829\n",
      "Epoch 387/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3217 - binary_accuracy: 0.8441 - val_loss: 0.5149 - val_binary_accuracy: 0.7872\n",
      "Epoch 388/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3234 - binary_accuracy: 0.8406 - val_loss: 0.5236 - val_binary_accuracy: 0.7843\n",
      "Epoch 389/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3220 - binary_accuracy: 0.8445 - val_loss: 0.5174 - val_binary_accuracy: 0.7822\n",
      "Epoch 390/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3215 - binary_accuracy: 0.8418 - val_loss: 0.5251 - val_binary_accuracy: 0.7858\n",
      "Epoch 391/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3220 - binary_accuracy: 0.8452 - val_loss: 0.5194 - val_binary_accuracy: 0.7815\n",
      "Epoch 392/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3216 - binary_accuracy: 0.8440 - val_loss: 0.5266 - val_binary_accuracy: 0.7872\n",
      "Epoch 393/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3221 - binary_accuracy: 0.8441 - val_loss: 0.5269 - val_binary_accuracy: 0.7800\n",
      "Epoch 394/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3227 - binary_accuracy: 0.8422 - val_loss: 0.5205 - val_binary_accuracy: 0.7850\n",
      "Epoch 395/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3214 - binary_accuracy: 0.8449 - val_loss: 0.5212 - val_binary_accuracy: 0.7822\n",
      "Epoch 396/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3225 - binary_accuracy: 0.8452 - val_loss: 0.5181 - val_binary_accuracy: 0.7872\n",
      "Epoch 397/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3214 - binary_accuracy: 0.8433 - val_loss: 0.5231 - val_binary_accuracy: 0.7879\n",
      "Epoch 398/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3222 - binary_accuracy: 0.8447 - val_loss: 0.5254 - val_binary_accuracy: 0.7879\n",
      "Epoch 399/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3216 - binary_accuracy: 0.8450 - val_loss: 0.5259 - val_binary_accuracy: 0.7894\n",
      "Epoch 400/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3222 - binary_accuracy: 0.8438 - val_loss: 0.5244 - val_binary_accuracy: 0.7865\n",
      "Epoch 401/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3216 - binary_accuracy: 0.8441 - val_loss: 0.5164 - val_binary_accuracy: 0.7894\n",
      "Epoch 402/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3212 - binary_accuracy: 0.8425 - val_loss: 0.5279 - val_binary_accuracy: 0.7894\n",
      "Epoch 403/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3214 - binary_accuracy: 0.8441 - val_loss: 0.5257 - val_binary_accuracy: 0.7915\n",
      "Epoch 404/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3227 - binary_accuracy: 0.8420 - val_loss: 0.5220 - val_binary_accuracy: 0.7915\n",
      "Epoch 405/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8449 - val_loss: 0.5227 - val_binary_accuracy: 0.7951\n",
      "Epoch 406/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3197 - binary_accuracy: 0.8393 - val_loss: 0.5232 - val_binary_accuracy: 0.7829\n",
      "Epoch 407/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8450 - val_loss: 0.5219 - val_binary_accuracy: 0.7836\n",
      "Epoch 408/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3223 - binary_accuracy: 0.8479 - val_loss: 0.5247 - val_binary_accuracy: 0.7858\n",
      "Epoch 409/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8427 - val_loss: 0.5251 - val_binary_accuracy: 0.7793\n",
      "Epoch 410/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3218 - binary_accuracy: 0.8470 - val_loss: 0.5236 - val_binary_accuracy: 0.7879\n",
      "Epoch 411/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3213 - binary_accuracy: 0.8418 - val_loss: 0.5224 - val_binary_accuracy: 0.7829\n",
      "Epoch 412/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3226 - binary_accuracy: 0.8415 - val_loss: 0.5251 - val_binary_accuracy: 0.7930\n",
      "Epoch 413/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3212 - binary_accuracy: 0.8447 - val_loss: 0.5254 - val_binary_accuracy: 0.7829\n",
      "Epoch 414/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3202 - binary_accuracy: 0.8443 - val_loss: 0.5172 - val_binary_accuracy: 0.7836\n",
      "Epoch 415/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3211 - binary_accuracy: 0.8459 - val_loss: 0.5220 - val_binary_accuracy: 0.7836\n",
      "Epoch 416/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3212 - binary_accuracy: 0.8445 - val_loss: 0.5228 - val_binary_accuracy: 0.7858\n",
      "Epoch 417/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8427 - val_loss: 0.5256 - val_binary_accuracy: 0.7815\n",
      "Epoch 418/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3203 - binary_accuracy: 0.8438 - val_loss: 0.5255 - val_binary_accuracy: 0.7815\n",
      "Epoch 419/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3216 - binary_accuracy: 0.8418 - val_loss: 0.5270 - val_binary_accuracy: 0.7850\n",
      "Epoch 420/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3200 - binary_accuracy: 0.8467 - val_loss: 0.5209 - val_binary_accuracy: 0.7836\n",
      "Epoch 421/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3192 - binary_accuracy: 0.8476 - val_loss: 0.5310 - val_binary_accuracy: 0.7786\n",
      "Epoch 422/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3208 - binary_accuracy: 0.8441 - val_loss: 0.5179 - val_binary_accuracy: 0.7894\n",
      "Epoch 423/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3200 - binary_accuracy: 0.8458 - val_loss: 0.5314 - val_binary_accuracy: 0.7872\n",
      "Epoch 424/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3204 - binary_accuracy: 0.8472 - val_loss: 0.5254 - val_binary_accuracy: 0.7843\n",
      "Epoch 425/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3199 - binary_accuracy: 0.8438 - val_loss: 0.5331 - val_binary_accuracy: 0.7858\n",
      "Epoch 426/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3185 - binary_accuracy: 0.8481 - val_loss: 0.5268 - val_binary_accuracy: 0.7800\n",
      "Epoch 427/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3208 - binary_accuracy: 0.8429 - val_loss: 0.5278 - val_binary_accuracy: 0.7858\n",
      "Epoch 428/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3210 - binary_accuracy: 0.8443 - val_loss: 0.5279 - val_binary_accuracy: 0.7865\n",
      "Epoch 429/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3194 - binary_accuracy: 0.8438 - val_loss: 0.5201 - val_binary_accuracy: 0.7779\n",
      "Epoch 430/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3197 - binary_accuracy: 0.8441 - val_loss: 0.5282 - val_binary_accuracy: 0.7901\n",
      "Epoch 431/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3189 - binary_accuracy: 0.8483 - val_loss: 0.5281 - val_binary_accuracy: 0.7879\n",
      "Epoch 432/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3193 - binary_accuracy: 0.8420 - val_loss: 0.5287 - val_binary_accuracy: 0.7901\n",
      "Epoch 433/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3196 - binary_accuracy: 0.8422 - val_loss: 0.5236 - val_binary_accuracy: 0.7865\n",
      "Epoch 434/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3189 - binary_accuracy: 0.8438 - val_loss: 0.5253 - val_binary_accuracy: 0.7829\n",
      "Epoch 435/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3179 - binary_accuracy: 0.8445 - val_loss: 0.5357 - val_binary_accuracy: 0.7800\n",
      "Epoch 436/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3205 - binary_accuracy: 0.8461 - val_loss: 0.5331 - val_binary_accuracy: 0.7836\n",
      "Epoch 437/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8468 - val_loss: 0.5241 - val_binary_accuracy: 0.7930\n",
      "Epoch 438/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3199 - binary_accuracy: 0.8441 - val_loss: 0.5257 - val_binary_accuracy: 0.7901\n",
      "Epoch 439/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3185 - binary_accuracy: 0.8433 - val_loss: 0.5213 - val_binary_accuracy: 0.7807\n",
      "Epoch 440/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3190 - binary_accuracy: 0.8407 - val_loss: 0.5213 - val_binary_accuracy: 0.7793\n",
      "Epoch 441/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3194 - binary_accuracy: 0.8441 - val_loss: 0.5285 - val_binary_accuracy: 0.7865\n",
      "Epoch 442/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3177 - binary_accuracy: 0.8445 - val_loss: 0.5313 - val_binary_accuracy: 0.7793\n",
      "Epoch 443/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3206 - binary_accuracy: 0.8434 - val_loss: 0.5255 - val_binary_accuracy: 0.7786\n",
      "Epoch 444/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3192 - binary_accuracy: 0.8386 - val_loss: 0.5278 - val_binary_accuracy: 0.7879\n",
      "Epoch 445/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3182 - binary_accuracy: 0.8461 - val_loss: 0.5297 - val_binary_accuracy: 0.7829\n",
      "Epoch 446/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3195 - binary_accuracy: 0.8465 - val_loss: 0.5271 - val_binary_accuracy: 0.7800\n",
      "Epoch 447/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3187 - binary_accuracy: 0.8465 - val_loss: 0.5287 - val_binary_accuracy: 0.7858\n",
      "Epoch 448/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3207 - binary_accuracy: 0.8449 - val_loss: 0.5298 - val_binary_accuracy: 0.7843\n",
      "Epoch 449/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3184 - binary_accuracy: 0.8479 - val_loss: 0.5236 - val_binary_accuracy: 0.7807\n",
      "Epoch 450/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3203 - binary_accuracy: 0.8424 - val_loss: 0.5321 - val_binary_accuracy: 0.7886\n",
      "Epoch 451/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3194 - binary_accuracy: 0.8429 - val_loss: 0.5274 - val_binary_accuracy: 0.7829\n",
      "Epoch 452/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3166 - binary_accuracy: 0.8468 - val_loss: 0.5373 - val_binary_accuracy: 0.7800\n",
      "Epoch 453/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3177 - binary_accuracy: 0.8479 - val_loss: 0.5364 - val_binary_accuracy: 0.7807\n",
      "Epoch 454/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3198 - binary_accuracy: 0.8458 - val_loss: 0.5350 - val_binary_accuracy: 0.7822\n",
      "Epoch 455/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3178 - binary_accuracy: 0.8461 - val_loss: 0.5320 - val_binary_accuracy: 0.7850\n",
      "Epoch 456/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3164 - binary_accuracy: 0.8459 - val_loss: 0.5339 - val_binary_accuracy: 0.7850\n",
      "Epoch 457/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3177 - binary_accuracy: 0.8445 - val_loss: 0.5308 - val_binary_accuracy: 0.7843\n",
      "Epoch 458/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3180 - binary_accuracy: 0.8427 - val_loss: 0.5339 - val_binary_accuracy: 0.7850\n",
      "Epoch 459/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3173 - binary_accuracy: 0.8467 - val_loss: 0.5306 - val_binary_accuracy: 0.7879\n",
      "Epoch 460/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3163 - binary_accuracy: 0.8495 - val_loss: 0.5375 - val_binary_accuracy: 0.7800\n",
      "Epoch 461/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3191 - binary_accuracy: 0.8459 - val_loss: 0.5416 - val_binary_accuracy: 0.7843\n",
      "Epoch 462/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3190 - binary_accuracy: 0.8483 - val_loss: 0.5369 - val_binary_accuracy: 0.7843\n",
      "Epoch 463/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3188 - binary_accuracy: 0.8465 - val_loss: 0.5358 - val_binary_accuracy: 0.7793\n",
      "Epoch 464/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3174 - binary_accuracy: 0.8472 - val_loss: 0.5310 - val_binary_accuracy: 0.7829\n",
      "Epoch 465/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3167 - binary_accuracy: 0.8468 - val_loss: 0.5295 - val_binary_accuracy: 0.7800\n",
      "Epoch 466/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3159 - binary_accuracy: 0.8476 - val_loss: 0.5358 - val_binary_accuracy: 0.7771\n",
      "Epoch 467/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3177 - binary_accuracy: 0.8411 - val_loss: 0.5323 - val_binary_accuracy: 0.7829\n",
      "Epoch 468/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3177 - binary_accuracy: 0.8486 - val_loss: 0.5383 - val_binary_accuracy: 0.7886\n",
      "Epoch 469/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3172 - binary_accuracy: 0.8458 - val_loss: 0.5299 - val_binary_accuracy: 0.7764\n",
      "Epoch 470/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3169 - binary_accuracy: 0.8465 - val_loss: 0.5395 - val_binary_accuracy: 0.7858\n",
      "Epoch 471/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3172 - binary_accuracy: 0.8465 - val_loss: 0.5360 - val_binary_accuracy: 0.7829\n",
      "Epoch 472/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3175 - binary_accuracy: 0.8465 - val_loss: 0.5371 - val_binary_accuracy: 0.7836\n",
      "Epoch 473/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3163 - binary_accuracy: 0.8477 - val_loss: 0.5314 - val_binary_accuracy: 0.7822\n",
      "Epoch 474/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3180 - binary_accuracy: 0.8416 - val_loss: 0.5329 - val_binary_accuracy: 0.7930\n",
      "Epoch 475/500\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3165 - binary_accuracy: 0.8465 - val_loss: 0.5371 - val_binary_accuracy: 0.7836\n",
      "Epoch 476/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3175 - binary_accuracy: 0.8452 - val_loss: 0.5384 - val_binary_accuracy: 0.7843\n",
      "Epoch 477/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3175 - binary_accuracy: 0.8477 - val_loss: 0.5356 - val_binary_accuracy: 0.7872\n",
      "Epoch 478/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3176 - binary_accuracy: 0.8433 - val_loss: 0.5366 - val_binary_accuracy: 0.7793\n",
      "Epoch 479/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3151 - binary_accuracy: 0.8463 - val_loss: 0.5402 - val_binary_accuracy: 0.7865\n",
      "Epoch 480/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3165 - binary_accuracy: 0.8476 - val_loss: 0.5413 - val_binary_accuracy: 0.7865\n",
      "Epoch 481/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3175 - binary_accuracy: 0.8452 - val_loss: 0.5339 - val_binary_accuracy: 0.7807\n",
      "Epoch 482/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3171 - binary_accuracy: 0.8465 - val_loss: 0.5380 - val_binary_accuracy: 0.7894\n",
      "Epoch 483/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3158 - binary_accuracy: 0.8456 - val_loss: 0.5375 - val_binary_accuracy: 0.7865\n",
      "Epoch 484/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3161 - binary_accuracy: 0.8433 - val_loss: 0.5452 - val_binary_accuracy: 0.7886\n",
      "Epoch 485/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3172 - binary_accuracy: 0.8456 - val_loss: 0.5423 - val_binary_accuracy: 0.7807\n",
      "Epoch 486/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3174 - binary_accuracy: 0.8424 - val_loss: 0.5337 - val_binary_accuracy: 0.7872\n",
      "Epoch 487/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3173 - binary_accuracy: 0.8434 - val_loss: 0.5406 - val_binary_accuracy: 0.7850\n",
      "Epoch 488/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3162 - binary_accuracy: 0.8445 - val_loss: 0.5319 - val_binary_accuracy: 0.7850\n",
      "Epoch 489/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3175 - binary_accuracy: 0.8459 - val_loss: 0.5365 - val_binary_accuracy: 0.7815\n",
      "Epoch 490/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3162 - binary_accuracy: 0.8488 - val_loss: 0.5446 - val_binary_accuracy: 0.7850\n",
      "Epoch 491/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3165 - binary_accuracy: 0.8470 - val_loss: 0.5343 - val_binary_accuracy: 0.7872\n",
      "Epoch 492/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3150 - binary_accuracy: 0.8477 - val_loss: 0.5371 - val_binary_accuracy: 0.7894\n",
      "Epoch 493/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3159 - binary_accuracy: 0.8459 - val_loss: 0.5423 - val_binary_accuracy: 0.7872\n",
      "Epoch 494/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3172 - binary_accuracy: 0.8458 - val_loss: 0.5365 - val_binary_accuracy: 0.7865\n",
      "Epoch 495/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3165 - binary_accuracy: 0.8490 - val_loss: 0.5355 - val_binary_accuracy: 0.7872\n",
      "Epoch 496/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3170 - binary_accuracy: 0.8449 - val_loss: 0.5427 - val_binary_accuracy: 0.7815\n",
      "Epoch 497/500\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3157 - binary_accuracy: 0.8463 - val_loss: 0.5359 - val_binary_accuracy: 0.7815\n",
      "Epoch 498/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3166 - binary_accuracy: 0.8434 - val_loss: 0.5376 - val_binary_accuracy: 0.7836\n",
      "Epoch 499/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3176 - binary_accuracy: 0.8441 - val_loss: 0.5368 - val_binary_accuracy: 0.7836\n",
      "Epoch 500/500\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3147 - binary_accuracy: 0.8488 - val_loss: 0.5425 - val_binary_accuracy: 0.7879\n"
     ]
    }
   ],
   "source": [
    "model_4 = keras.Sequential([\n",
    "    # the hidden ReLU layers\n",
    "    layers.Dense(units=23, activation='relu', input_shape=[23]),\n",
    "    layers.Dense(units=15, activation='relu'),\n",
    "    layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model_4.compile(optimizer='adam',loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "history=model_4.fit(x_1train,y_1train,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e68c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.624344</td>\n",
       "      <td>0.627719</td>\n",
       "      <td>0.497918</td>\n",
       "      <td>0.769950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.467397</td>\n",
       "      <td>0.777818</td>\n",
       "      <td>0.440130</td>\n",
       "      <td>0.795830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431390</td>\n",
       "      <td>0.792378</td>\n",
       "      <td>0.424347</td>\n",
       "      <td>0.805176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.419205</td>\n",
       "      <td>0.794535</td>\n",
       "      <td>0.416160</td>\n",
       "      <td>0.802301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412766</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.414238</td>\n",
       "      <td>0.808052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.316993</td>\n",
       "      <td>0.844868</td>\n",
       "      <td>0.542680</td>\n",
       "      <td>0.781452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.315692</td>\n",
       "      <td>0.846306</td>\n",
       "      <td>0.535921</td>\n",
       "      <td>0.781452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.843430</td>\n",
       "      <td>0.537583</td>\n",
       "      <td>0.783609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.317576</td>\n",
       "      <td>0.844149</td>\n",
       "      <td>0.536754</td>\n",
       "      <td>0.783609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.314724</td>\n",
       "      <td>0.848823</td>\n",
       "      <td>0.542510</td>\n",
       "      <td>0.787922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0    0.624344         0.627719  0.497918             0.769950\n",
       "1    0.467397         0.777818  0.440130             0.795830\n",
       "2    0.431390         0.792378  0.424347             0.805176\n",
       "3    0.419205         0.794535  0.416160             0.802301\n",
       "4    0.412766         0.799748  0.414238             0.808052\n",
       "..        ...              ...       ...                  ...\n",
       "495  0.316993         0.844868  0.542680             0.781452\n",
       "496  0.315692         0.846306  0.535921             0.781452\n",
       "497  0.316593         0.843430  0.537583             0.783609\n",
       "498  0.317576         0.844149  0.536754             0.783609\n",
       "499  0.314724         0.848823  0.542510             0.787922\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94de2e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "174/174 [==============================] - 2s 4ms/step - loss: 0.6326 - binary_accuracy: 0.6689 - val_loss: 0.5325 - val_binary_accuracy: 0.7556\n",
      "Epoch 2/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4773 - binary_accuracy: 0.7681 - val_loss: 0.4537 - val_binary_accuracy: 0.7836\n",
      "Epoch 3/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4354 - binary_accuracy: 0.7873 - val_loss: 0.4359 - val_binary_accuracy: 0.7850\n",
      "Epoch 4/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4212 - binary_accuracy: 0.7940 - val_loss: 0.4293 - val_binary_accuracy: 0.8052\n",
      "Epoch 5/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.4129 - binary_accuracy: 0.7997 - val_loss: 0.4207 - val_binary_accuracy: 0.8030\n",
      "Epoch 6/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4086 - binary_accuracy: 0.8023 - val_loss: 0.4177 - val_binary_accuracy: 0.8059\n",
      "Epoch 7/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4056 - binary_accuracy: 0.8010 - val_loss: 0.4161 - val_binary_accuracy: 0.8095\n",
      "Epoch 8/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.4032 - binary_accuracy: 0.8082 - val_loss: 0.4110 - val_binary_accuracy: 0.8009\n",
      "Epoch 9/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.4008 - binary_accuracy: 0.8073 - val_loss: 0.4101 - val_binary_accuracy: 0.8052\n",
      "Epoch 10/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3982 - binary_accuracy: 0.8069 - val_loss: 0.4109 - val_binary_accuracy: 0.7980\n",
      "Epoch 11/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3975 - binary_accuracy: 0.8075 - val_loss: 0.4111 - val_binary_accuracy: 0.7994\n",
      "Epoch 12/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3958 - binary_accuracy: 0.8091 - val_loss: 0.4078 - val_binary_accuracy: 0.8023\n",
      "Epoch 13/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3942 - binary_accuracy: 0.8111 - val_loss: 0.4074 - val_binary_accuracy: 0.8052\n",
      "Epoch 14/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3936 - binary_accuracy: 0.8107 - val_loss: 0.4057 - val_binary_accuracy: 0.7994\n",
      "Epoch 15/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3923 - binary_accuracy: 0.8118 - val_loss: 0.4058 - val_binary_accuracy: 0.7987\n",
      "Epoch 16/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3914 - binary_accuracy: 0.8125 - val_loss: 0.4063 - val_binary_accuracy: 0.8001\n",
      "Epoch 17/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3902 - binary_accuracy: 0.8082 - val_loss: 0.4034 - val_binary_accuracy: 0.8066\n",
      "Epoch 18/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3891 - binary_accuracy: 0.8102 - val_loss: 0.4045 - val_binary_accuracy: 0.8081\n",
      "Epoch 19/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3890 - binary_accuracy: 0.8104 - val_loss: 0.4045 - val_binary_accuracy: 0.7980\n",
      "Epoch 20/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3874 - binary_accuracy: 0.8145 - val_loss: 0.4044 - val_binary_accuracy: 0.8016\n",
      "Epoch 21/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3866 - binary_accuracy: 0.8096 - val_loss: 0.4015 - val_binary_accuracy: 0.8023\n",
      "Epoch 22/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3861 - binary_accuracy: 0.8134 - val_loss: 0.4033 - val_binary_accuracy: 0.8023\n",
      "Epoch 23/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3853 - binary_accuracy: 0.8116 - val_loss: 0.4081 - val_binary_accuracy: 0.8045\n",
      "Epoch 24/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3853 - binary_accuracy: 0.8131 - val_loss: 0.4058 - val_binary_accuracy: 0.7994\n",
      "Epoch 25/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3838 - binary_accuracy: 0.8118 - val_loss: 0.4062 - val_binary_accuracy: 0.8030\n",
      "Epoch 26/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3838 - binary_accuracy: 0.8168 - val_loss: 0.4036 - val_binary_accuracy: 0.8009\n",
      "Epoch 27/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3832 - binary_accuracy: 0.8145 - val_loss: 0.4052 - val_binary_accuracy: 0.8016\n",
      "Epoch 28/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3828 - binary_accuracy: 0.8138 - val_loss: 0.4023 - val_binary_accuracy: 0.8037\n",
      "Epoch 29/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3820 - binary_accuracy: 0.8159 - val_loss: 0.4040 - val_binary_accuracy: 0.8030\n",
      "Epoch 30/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3813 - binary_accuracy: 0.8154 - val_loss: 0.4025 - val_binary_accuracy: 0.8066\n",
      "Epoch 31/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3813 - binary_accuracy: 0.8165 - val_loss: 0.4048 - val_binary_accuracy: 0.8016\n",
      "Epoch 32/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3803 - binary_accuracy: 0.8166 - val_loss: 0.4056 - val_binary_accuracy: 0.8066\n",
      "Epoch 33/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3805 - binary_accuracy: 0.8139 - val_loss: 0.4037 - val_binary_accuracy: 0.8030\n",
      "Epoch 34/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3794 - binary_accuracy: 0.8177 - val_loss: 0.4092 - val_binary_accuracy: 0.8009\n",
      "Epoch 35/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3794 - binary_accuracy: 0.8166 - val_loss: 0.4047 - val_binary_accuracy: 0.8009\n",
      "Epoch 36/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3789 - binary_accuracy: 0.8204 - val_loss: 0.4063 - val_binary_accuracy: 0.8016\n",
      "Epoch 37/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3788 - binary_accuracy: 0.8156 - val_loss: 0.4048 - val_binary_accuracy: 0.8037\n",
      "Epoch 38/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3783 - binary_accuracy: 0.8168 - val_loss: 0.4071 - val_binary_accuracy: 0.8037\n",
      "Epoch 39/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3783 - binary_accuracy: 0.8188 - val_loss: 0.4050 - val_binary_accuracy: 0.8059\n",
      "Epoch 40/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3775 - binary_accuracy: 0.8166 - val_loss: 0.4067 - val_binary_accuracy: 0.8037\n",
      "Epoch 41/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3764 - binary_accuracy: 0.8186 - val_loss: 0.4048 - val_binary_accuracy: 0.8023\n",
      "Epoch 42/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3765 - binary_accuracy: 0.8192 - val_loss: 0.4043 - val_binary_accuracy: 0.8030\n",
      "Epoch 43/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3766 - binary_accuracy: 0.8199 - val_loss: 0.4034 - val_binary_accuracy: 0.8045\n",
      "Epoch 44/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3751 - binary_accuracy: 0.8199 - val_loss: 0.4078 - val_binary_accuracy: 0.8037\n",
      "Epoch 45/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3751 - binary_accuracy: 0.8179 - val_loss: 0.4037 - val_binary_accuracy: 0.8059\n",
      "Epoch 46/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3746 - binary_accuracy: 0.8217 - val_loss: 0.4048 - val_binary_accuracy: 0.8045\n",
      "Epoch 47/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3740 - binary_accuracy: 0.8147 - val_loss: 0.4044 - val_binary_accuracy: 0.8059\n",
      "Epoch 48/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3733 - binary_accuracy: 0.8188 - val_loss: 0.4061 - val_binary_accuracy: 0.8016\n",
      "Epoch 49/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8188 - val_loss: 0.4044 - val_binary_accuracy: 0.8059\n",
      "Epoch 50/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3731 - binary_accuracy: 0.8179 - val_loss: 0.4073 - val_binary_accuracy: 0.8066\n",
      "Epoch 51/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3727 - binary_accuracy: 0.8195 - val_loss: 0.4126 - val_binary_accuracy: 0.8023\n",
      "Epoch 52/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3727 - binary_accuracy: 0.8188 - val_loss: 0.4042 - val_binary_accuracy: 0.8009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3722 - binary_accuracy: 0.8224 - val_loss: 0.4066 - val_binary_accuracy: 0.8052\n",
      "Epoch 54/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3718 - binary_accuracy: 0.8193 - val_loss: 0.4087 - val_binary_accuracy: 0.8030\n",
      "Epoch 55/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3719 - binary_accuracy: 0.8145 - val_loss: 0.4080 - val_binary_accuracy: 0.8030\n",
      "Epoch 56/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3703 - binary_accuracy: 0.8206 - val_loss: 0.4078 - val_binary_accuracy: 0.8023\n",
      "Epoch 57/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8193 - val_loss: 0.4089 - val_binary_accuracy: 0.7980\n",
      "Epoch 58/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3700 - binary_accuracy: 0.8208 - val_loss: 0.4067 - val_binary_accuracy: 0.8066\n",
      "Epoch 59/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3696 - binary_accuracy: 0.8219 - val_loss: 0.4081 - val_binary_accuracy: 0.8081\n",
      "Epoch 60/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3694 - binary_accuracy: 0.8215 - val_loss: 0.4070 - val_binary_accuracy: 0.8009\n",
      "Epoch 61/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3685 - binary_accuracy: 0.8215 - val_loss: 0.4092 - val_binary_accuracy: 0.8052\n",
      "Epoch 62/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3685 - binary_accuracy: 0.8269 - val_loss: 0.4106 - val_binary_accuracy: 0.8037\n",
      "Epoch 63/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3686 - binary_accuracy: 0.8215 - val_loss: 0.4084 - val_binary_accuracy: 0.8052\n",
      "Epoch 64/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3690 - binary_accuracy: 0.8228 - val_loss: 0.4072 - val_binary_accuracy: 0.8037\n",
      "Epoch 65/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3679 - binary_accuracy: 0.8219 - val_loss: 0.4093 - val_binary_accuracy: 0.7994\n",
      "Epoch 66/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3689 - binary_accuracy: 0.8204 - val_loss: 0.4056 - val_binary_accuracy: 0.8059\n",
      "Epoch 67/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3664 - binary_accuracy: 0.8249 - val_loss: 0.4122 - val_binary_accuracy: 0.8037\n",
      "Epoch 68/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3673 - binary_accuracy: 0.8210 - val_loss: 0.4103 - val_binary_accuracy: 0.8059\n",
      "Epoch 69/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3657 - binary_accuracy: 0.8246 - val_loss: 0.4156 - val_binary_accuracy: 0.7980\n",
      "Epoch 70/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3667 - binary_accuracy: 0.8233 - val_loss: 0.4088 - val_binary_accuracy: 0.8059\n",
      "Epoch 71/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3655 - binary_accuracy: 0.8255 - val_loss: 0.4151 - val_binary_accuracy: 0.8016\n",
      "Epoch 72/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3665 - binary_accuracy: 0.8222 - val_loss: 0.4082 - val_binary_accuracy: 0.8037\n",
      "Epoch 73/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3649 - binary_accuracy: 0.8222 - val_loss: 0.4139 - val_binary_accuracy: 0.8009\n",
      "Epoch 74/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3658 - binary_accuracy: 0.8204 - val_loss: 0.4100 - val_binary_accuracy: 0.8001\n",
      "Epoch 75/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3643 - binary_accuracy: 0.8247 - val_loss: 0.4132 - val_binary_accuracy: 0.8016\n",
      "Epoch 76/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3643 - binary_accuracy: 0.8192 - val_loss: 0.4174 - val_binary_accuracy: 0.8023\n",
      "Epoch 77/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3646 - binary_accuracy: 0.8242 - val_loss: 0.4104 - val_binary_accuracy: 0.8009\n",
      "Epoch 78/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3646 - binary_accuracy: 0.8242 - val_loss: 0.4088 - val_binary_accuracy: 0.8016\n",
      "Epoch 79/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3631 - binary_accuracy: 0.8233 - val_loss: 0.4123 - val_binary_accuracy: 0.8023\n",
      "Epoch 80/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3631 - binary_accuracy: 0.8235 - val_loss: 0.4091 - val_binary_accuracy: 0.8037\n",
      "Epoch 81/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3632 - binary_accuracy: 0.8219 - val_loss: 0.4132 - val_binary_accuracy: 0.7994\n",
      "Epoch 82/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3639 - binary_accuracy: 0.8247 - val_loss: 0.4112 - val_binary_accuracy: 0.8037\n",
      "Epoch 83/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3624 - binary_accuracy: 0.8265 - val_loss: 0.4145 - val_binary_accuracy: 0.8001\n",
      "Epoch 84/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8240 - val_loss: 0.4144 - val_binary_accuracy: 0.8001\n",
      "Epoch 85/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3627 - binary_accuracy: 0.8217 - val_loss: 0.4118 - val_binary_accuracy: 0.8045\n",
      "Epoch 86/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8264 - val_loss: 0.4097 - val_binary_accuracy: 0.8102\n",
      "Epoch 87/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3614 - binary_accuracy: 0.8251 - val_loss: 0.4102 - val_binary_accuracy: 0.8023\n",
      "Epoch 88/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3615 - binary_accuracy: 0.8242 - val_loss: 0.4087 - val_binary_accuracy: 0.8023\n",
      "Epoch 89/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8238 - val_loss: 0.4126 - val_binary_accuracy: 0.8059\n",
      "Epoch 90/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3611 - binary_accuracy: 0.8206 - val_loss: 0.4118 - val_binary_accuracy: 0.8016\n",
      "Epoch 91/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3599 - binary_accuracy: 0.8282 - val_loss: 0.4126 - val_binary_accuracy: 0.8001\n",
      "Epoch 92/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3599 - binary_accuracy: 0.8280 - val_loss: 0.4073 - val_binary_accuracy: 0.8030\n",
      "Epoch 93/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3593 - binary_accuracy: 0.8285 - val_loss: 0.4116 - val_binary_accuracy: 0.8081\n",
      "Epoch 94/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3594 - binary_accuracy: 0.8269 - val_loss: 0.4095 - val_binary_accuracy: 0.8059\n",
      "Epoch 95/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3597 - binary_accuracy: 0.8296 - val_loss: 0.4112 - val_binary_accuracy: 0.8066\n",
      "Epoch 96/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3584 - binary_accuracy: 0.8303 - val_loss: 0.4149 - val_binary_accuracy: 0.8037\n",
      "Epoch 97/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3588 - binary_accuracy: 0.8262 - val_loss: 0.4107 - val_binary_accuracy: 0.7980\n",
      "Epoch 98/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3590 - binary_accuracy: 0.8285 - val_loss: 0.4122 - val_binary_accuracy: 0.8016\n",
      "Epoch 99/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3580 - binary_accuracy: 0.8278 - val_loss: 0.4166 - val_binary_accuracy: 0.8023\n",
      "Epoch 100/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3586 - binary_accuracy: 0.8246 - val_loss: 0.4136 - val_binary_accuracy: 0.8001\n",
      "Epoch 101/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3582 - binary_accuracy: 0.8273 - val_loss: 0.4133 - val_binary_accuracy: 0.8059\n",
      "Epoch 102/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3575 - binary_accuracy: 0.8276 - val_loss: 0.4201 - val_binary_accuracy: 0.7937\n",
      "Epoch 103/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3580 - binary_accuracy: 0.8264 - val_loss: 0.4154 - val_binary_accuracy: 0.8023\n",
      "Epoch 104/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3576 - binary_accuracy: 0.8260 - val_loss: 0.4129 - val_binary_accuracy: 0.8016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3568 - binary_accuracy: 0.8280 - val_loss: 0.4170 - val_binary_accuracy: 0.8016\n",
      "Epoch 106/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3570 - binary_accuracy: 0.8276 - val_loss: 0.4146 - val_binary_accuracy: 0.8037\n",
      "Epoch 107/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3568 - binary_accuracy: 0.8287 - val_loss: 0.4140 - val_binary_accuracy: 0.8037\n",
      "Epoch 108/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3560 - binary_accuracy: 0.8305 - val_loss: 0.4141 - val_binary_accuracy: 0.8023\n",
      "Epoch 109/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3551 - binary_accuracy: 0.8290 - val_loss: 0.4176 - val_binary_accuracy: 0.8001\n",
      "Epoch 110/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3559 - binary_accuracy: 0.8271 - val_loss: 0.4164 - val_binary_accuracy: 0.8016\n",
      "Epoch 111/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3559 - binary_accuracy: 0.8282 - val_loss: 0.4159 - val_binary_accuracy: 0.7987\n",
      "Epoch 112/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3551 - binary_accuracy: 0.8326 - val_loss: 0.4191 - val_binary_accuracy: 0.7994\n",
      "Epoch 113/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3558 - binary_accuracy: 0.8299 - val_loss: 0.4178 - val_binary_accuracy: 0.7944\n",
      "Epoch 114/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3548 - binary_accuracy: 0.8283 - val_loss: 0.4163 - val_binary_accuracy: 0.8009\n",
      "Epoch 115/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8298 - val_loss: 0.4209 - val_binary_accuracy: 0.8001\n",
      "Epoch 116/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3545 - binary_accuracy: 0.8290 - val_loss: 0.4196 - val_binary_accuracy: 0.8001\n",
      "Epoch 117/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3544 - binary_accuracy: 0.8276 - val_loss: 0.4229 - val_binary_accuracy: 0.7944\n",
      "Epoch 118/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3552 - binary_accuracy: 0.8276 - val_loss: 0.4162 - val_binary_accuracy: 0.8037\n",
      "Epoch 119/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3545 - binary_accuracy: 0.8253 - val_loss: 0.4173 - val_binary_accuracy: 0.8052\n",
      "Epoch 120/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3534 - binary_accuracy: 0.8312 - val_loss: 0.4164 - val_binary_accuracy: 0.8045\n",
      "Epoch 121/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3531 - binary_accuracy: 0.8290 - val_loss: 0.4217 - val_binary_accuracy: 0.8037\n",
      "Epoch 122/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3532 - binary_accuracy: 0.8290 - val_loss: 0.4152 - val_binary_accuracy: 0.8102\n",
      "Epoch 123/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3532 - binary_accuracy: 0.8289 - val_loss: 0.4175 - val_binary_accuracy: 0.7930\n",
      "Epoch 124/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3527 - binary_accuracy: 0.8314 - val_loss: 0.4187 - val_binary_accuracy: 0.7965\n",
      "Epoch 125/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3529 - binary_accuracy: 0.8290 - val_loss: 0.4218 - val_binary_accuracy: 0.8001\n",
      "Epoch 126/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3535 - binary_accuracy: 0.8316 - val_loss: 0.4181 - val_binary_accuracy: 0.8037\n",
      "Epoch 127/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8301 - val_loss: 0.4213 - val_binary_accuracy: 0.7922\n",
      "Epoch 128/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3529 - binary_accuracy: 0.8323 - val_loss: 0.4205 - val_binary_accuracy: 0.7965\n",
      "Epoch 129/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3525 - binary_accuracy: 0.8296 - val_loss: 0.4200 - val_binary_accuracy: 0.7980\n",
      "Epoch 130/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8258 - val_loss: 0.4230 - val_binary_accuracy: 0.7965\n",
      "Epoch 131/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3525 - binary_accuracy: 0.8269 - val_loss: 0.4181 - val_binary_accuracy: 0.8023\n",
      "Epoch 132/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3522 - binary_accuracy: 0.8330 - val_loss: 0.4188 - val_binary_accuracy: 0.8052\n",
      "Epoch 133/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3524 - binary_accuracy: 0.8289 - val_loss: 0.4221 - val_binary_accuracy: 0.8066\n",
      "Epoch 134/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3512 - binary_accuracy: 0.8314 - val_loss: 0.4255 - val_binary_accuracy: 0.7994\n",
      "Epoch 135/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3517 - binary_accuracy: 0.8312 - val_loss: 0.4226 - val_binary_accuracy: 0.8045\n",
      "Epoch 136/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3510 - binary_accuracy: 0.8292 - val_loss: 0.4242 - val_binary_accuracy: 0.8009\n",
      "Epoch 137/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3520 - binary_accuracy: 0.8316 - val_loss: 0.4176 - val_binary_accuracy: 0.8066\n",
      "Epoch 138/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3510 - binary_accuracy: 0.8326 - val_loss: 0.4252 - val_binary_accuracy: 0.7987\n",
      "Epoch 139/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8303 - val_loss: 0.4231 - val_binary_accuracy: 0.8030\n",
      "Epoch 140/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8289 - val_loss: 0.4231 - val_binary_accuracy: 0.8030\n",
      "Epoch 141/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8310 - val_loss: 0.4260 - val_binary_accuracy: 0.7951\n",
      "Epoch 142/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3505 - binary_accuracy: 0.8308 - val_loss: 0.4224 - val_binary_accuracy: 0.7958\n",
      "Epoch 143/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3508 - binary_accuracy: 0.8310 - val_loss: 0.4206 - val_binary_accuracy: 0.7973\n",
      "Epoch 144/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8296 - val_loss: 0.4173 - val_binary_accuracy: 0.8045\n",
      "Epoch 145/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3490 - binary_accuracy: 0.8343 - val_loss: 0.4245 - val_binary_accuracy: 0.8016\n",
      "Epoch 146/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3515 - binary_accuracy: 0.8323 - val_loss: 0.4221 - val_binary_accuracy: 0.8023\n",
      "Epoch 147/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3499 - binary_accuracy: 0.8321 - val_loss: 0.4202 - val_binary_accuracy: 0.8088\n",
      "Epoch 148/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3504 - binary_accuracy: 0.8308 - val_loss: 0.4192 - val_binary_accuracy: 0.8052\n",
      "Epoch 149/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3486 - binary_accuracy: 0.8303 - val_loss: 0.4226 - val_binary_accuracy: 0.7994\n",
      "Epoch 150/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3486 - binary_accuracy: 0.8323 - val_loss: 0.4284 - val_binary_accuracy: 0.7980\n",
      "Epoch 151/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3501 - binary_accuracy: 0.8323 - val_loss: 0.4190 - val_binary_accuracy: 0.8016\n",
      "Epoch 152/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3485 - binary_accuracy: 0.8326 - val_loss: 0.4197 - val_binary_accuracy: 0.8037\n",
      "Epoch 153/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8308 - val_loss: 0.4272 - val_binary_accuracy: 0.7965\n",
      "Epoch 154/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3498 - binary_accuracy: 0.8321 - val_loss: 0.4184 - val_binary_accuracy: 0.8023\n",
      "Epoch 155/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3474 - binary_accuracy: 0.8301 - val_loss: 0.4248 - val_binary_accuracy: 0.7987\n",
      "Epoch 156/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3489 - binary_accuracy: 0.8312 - val_loss: 0.4214 - val_binary_accuracy: 0.8052\n",
      "Epoch 157/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3486 - binary_accuracy: 0.8314 - val_loss: 0.4244 - val_binary_accuracy: 0.7987\n",
      "Epoch 158/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8344 - val_loss: 0.4241 - val_binary_accuracy: 0.7951\n",
      "Epoch 159/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8307 - val_loss: 0.4198 - val_binary_accuracy: 0.8045\n",
      "Epoch 160/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3481 - binary_accuracy: 0.8298 - val_loss: 0.4222 - val_binary_accuracy: 0.8045\n",
      "Epoch 161/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3488 - binary_accuracy: 0.8343 - val_loss: 0.4220 - val_binary_accuracy: 0.7994\n",
      "Epoch 162/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3470 - binary_accuracy: 0.8343 - val_loss: 0.4249 - val_binary_accuracy: 0.8016\n",
      "Epoch 163/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8321 - val_loss: 0.4247 - val_binary_accuracy: 0.7973\n",
      "Epoch 164/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3471 - binary_accuracy: 0.8350 - val_loss: 0.4258 - val_binary_accuracy: 0.7958\n",
      "Epoch 165/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8344 - val_loss: 0.4247 - val_binary_accuracy: 0.8009\n",
      "Epoch 166/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8334 - val_loss: 0.4243 - val_binary_accuracy: 0.8009\n",
      "Epoch 167/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8298 - val_loss: 0.4302 - val_binary_accuracy: 0.7951\n",
      "Epoch 168/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8312 - val_loss: 0.4208 - val_binary_accuracy: 0.8023\n",
      "Epoch 169/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3469 - binary_accuracy: 0.8308 - val_loss: 0.4258 - val_binary_accuracy: 0.7930\n",
      "Epoch 170/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3470 - binary_accuracy: 0.8323 - val_loss: 0.4232 - val_binary_accuracy: 0.7922\n",
      "Epoch 171/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3473 - binary_accuracy: 0.8323 - val_loss: 0.4237 - val_binary_accuracy: 0.8023\n",
      "Epoch 172/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3471 - binary_accuracy: 0.8319 - val_loss: 0.4239 - val_binary_accuracy: 0.7987\n",
      "Epoch 173/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3462 - binary_accuracy: 0.8350 - val_loss: 0.4331 - val_binary_accuracy: 0.7922\n",
      "Epoch 174/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3454 - binary_accuracy: 0.8305 - val_loss: 0.4270 - val_binary_accuracy: 0.8001\n",
      "Epoch 175/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3461 - binary_accuracy: 0.8343 - val_loss: 0.4290 - val_binary_accuracy: 0.7965\n",
      "Epoch 176/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3460 - binary_accuracy: 0.8296 - val_loss: 0.4295 - val_binary_accuracy: 0.7987\n",
      "Epoch 177/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3462 - binary_accuracy: 0.8326 - val_loss: 0.4267 - val_binary_accuracy: 0.7994\n",
      "Epoch 178/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3458 - binary_accuracy: 0.8310 - val_loss: 0.4301 - val_binary_accuracy: 0.7994\n",
      "Epoch 179/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3471 - binary_accuracy: 0.8346 - val_loss: 0.4256 - val_binary_accuracy: 0.7980\n",
      "Epoch 180/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3469 - binary_accuracy: 0.8325 - val_loss: 0.4290 - val_binary_accuracy: 0.8016\n",
      "Epoch 181/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8344 - val_loss: 0.4278 - val_binary_accuracy: 0.7965\n",
      "Epoch 182/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3451 - binary_accuracy: 0.8335 - val_loss: 0.4340 - val_binary_accuracy: 0.7994\n",
      "Epoch 183/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8343 - val_loss: 0.4336 - val_binary_accuracy: 0.8023\n",
      "Epoch 184/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3459 - binary_accuracy: 0.8323 - val_loss: 0.4296 - val_binary_accuracy: 0.7987\n",
      "Epoch 185/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8343 - val_loss: 0.4274 - val_binary_accuracy: 0.7994\n",
      "Epoch 186/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8319 - val_loss: 0.4272 - val_binary_accuracy: 0.8081\n",
      "Epoch 187/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8352 - val_loss: 0.4233 - val_binary_accuracy: 0.8052\n",
      "Epoch 188/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3451 - binary_accuracy: 0.8326 - val_loss: 0.4323 - val_binary_accuracy: 0.8016\n",
      "Epoch 189/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3454 - binary_accuracy: 0.8344 - val_loss: 0.4268 - val_binary_accuracy: 0.7973\n",
      "Epoch 190/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8359 - val_loss: 0.4307 - val_binary_accuracy: 0.8001\n",
      "Epoch 191/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3450 - binary_accuracy: 0.8301 - val_loss: 0.4296 - val_binary_accuracy: 0.8016\n",
      "Epoch 192/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3448 - binary_accuracy: 0.8350 - val_loss: 0.4266 - val_binary_accuracy: 0.8037\n",
      "Epoch 193/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3435 - binary_accuracy: 0.8346 - val_loss: 0.4314 - val_binary_accuracy: 0.7958\n",
      "Epoch 194/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3451 - binary_accuracy: 0.8337 - val_loss: 0.4277 - val_binary_accuracy: 0.7987\n",
      "Epoch 195/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3440 - binary_accuracy: 0.8332 - val_loss: 0.4322 - val_binary_accuracy: 0.8009\n",
      "Epoch 196/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3448 - binary_accuracy: 0.8359 - val_loss: 0.4295 - val_binary_accuracy: 0.8030\n",
      "Epoch 197/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3440 - binary_accuracy: 0.8328 - val_loss: 0.4271 - val_binary_accuracy: 0.8066\n",
      "Epoch 198/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8352 - val_loss: 0.4227 - val_binary_accuracy: 0.8037\n",
      "Epoch 199/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8343 - val_loss: 0.4302 - val_binary_accuracy: 0.7987\n",
      "Epoch 200/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3428 - binary_accuracy: 0.8391 - val_loss: 0.4283 - val_binary_accuracy: 0.8016\n",
      "Epoch 201/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3452 - binary_accuracy: 0.8370 - val_loss: 0.4275 - val_binary_accuracy: 0.8001\n",
      "Epoch 202/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8379 - val_loss: 0.4289 - val_binary_accuracy: 0.8052\n",
      "Epoch 203/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8310 - val_loss: 0.4289 - val_binary_accuracy: 0.8001\n",
      "Epoch 204/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3438 - binary_accuracy: 0.8364 - val_loss: 0.4289 - val_binary_accuracy: 0.8052\n",
      "Epoch 205/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8326 - val_loss: 0.4308 - val_binary_accuracy: 0.8023\n",
      "Epoch 206/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8335 - val_loss: 0.4327 - val_binary_accuracy: 0.7965\n",
      "Epoch 207/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3434 - binary_accuracy: 0.8317 - val_loss: 0.4341 - val_binary_accuracy: 0.7958\n",
      "Epoch 208/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3426 - binary_accuracy: 0.8346 - val_loss: 0.4279 - val_binary_accuracy: 0.7965\n",
      "Epoch 209/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8355 - val_loss: 0.4276 - val_binary_accuracy: 0.8059\n",
      "Epoch 210/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3434 - binary_accuracy: 0.8332 - val_loss: 0.4258 - val_binary_accuracy: 0.8016\n",
      "Epoch 211/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8334 - val_loss: 0.4318 - val_binary_accuracy: 0.8001\n",
      "Epoch 212/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3435 - binary_accuracy: 0.8334 - val_loss: 0.4281 - val_binary_accuracy: 0.8037\n",
      "Epoch 213/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3448 - binary_accuracy: 0.8334 - val_loss: 0.4356 - val_binary_accuracy: 0.7994\n",
      "Epoch 214/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8314 - val_loss: 0.4351 - val_binary_accuracy: 0.7965\n",
      "Epoch 215/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8344 - val_loss: 0.4329 - val_binary_accuracy: 0.8037\n",
      "Epoch 216/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8335 - val_loss: 0.4343 - val_binary_accuracy: 0.8037\n",
      "Epoch 217/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8352 - val_loss: 0.4305 - val_binary_accuracy: 0.8016\n",
      "Epoch 218/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8341 - val_loss: 0.4331 - val_binary_accuracy: 0.8016\n",
      "Epoch 219/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3417 - binary_accuracy: 0.8330 - val_loss: 0.4371 - val_binary_accuracy: 0.7958\n",
      "Epoch 220/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8337 - val_loss: 0.4355 - val_binary_accuracy: 0.8066\n",
      "Epoch 221/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3424 - binary_accuracy: 0.8341 - val_loss: 0.4294 - val_binary_accuracy: 0.8016\n",
      "Epoch 222/250\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8357 - val_loss: 0.4314 - val_binary_accuracy: 0.8059\n",
      "Epoch 223/250\n",
      "174/174 [==============================] - 0s 3ms/step - loss: 0.3422 - binary_accuracy: 0.8334 - val_loss: 0.4340 - val_binary_accuracy: 0.7930\n",
      "Epoch 224/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3424 - binary_accuracy: 0.8339 - val_loss: 0.4332 - val_binary_accuracy: 0.7973\n",
      "Epoch 225/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3427 - binary_accuracy: 0.8344 - val_loss: 0.4300 - val_binary_accuracy: 0.8030\n",
      "Epoch 226/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3419 - binary_accuracy: 0.8397 - val_loss: 0.4336 - val_binary_accuracy: 0.7987\n",
      "Epoch 227/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3440 - binary_accuracy: 0.8317 - val_loss: 0.4287 - val_binary_accuracy: 0.8016\n",
      "Epoch 228/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3419 - binary_accuracy: 0.8368 - val_loss: 0.4340 - val_binary_accuracy: 0.8066\n",
      "Epoch 229/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3421 - binary_accuracy: 0.8330 - val_loss: 0.4331 - val_binary_accuracy: 0.7987\n",
      "Epoch 230/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3419 - binary_accuracy: 0.8371 - val_loss: 0.4314 - val_binary_accuracy: 0.8001\n",
      "Epoch 231/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3414 - binary_accuracy: 0.8346 - val_loss: 0.4419 - val_binary_accuracy: 0.8001\n",
      "Epoch 232/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3417 - binary_accuracy: 0.8377 - val_loss: 0.4361 - val_binary_accuracy: 0.7965\n",
      "Epoch 233/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3413 - binary_accuracy: 0.8370 - val_loss: 0.4374 - val_binary_accuracy: 0.7930\n",
      "Epoch 234/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3414 - binary_accuracy: 0.8375 - val_loss: 0.4328 - val_binary_accuracy: 0.8045\n",
      "Epoch 235/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3407 - binary_accuracy: 0.8364 - val_loss: 0.4328 - val_binary_accuracy: 0.8030\n",
      "Epoch 236/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3414 - binary_accuracy: 0.8362 - val_loss: 0.4360 - val_binary_accuracy: 0.7987\n",
      "Epoch 237/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3407 - binary_accuracy: 0.8371 - val_loss: 0.4388 - val_binary_accuracy: 0.7973\n",
      "Epoch 238/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3414 - binary_accuracy: 0.8359 - val_loss: 0.4389 - val_binary_accuracy: 0.7987\n",
      "Epoch 239/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3405 - binary_accuracy: 0.8359 - val_loss: 0.4369 - val_binary_accuracy: 0.8016\n",
      "Epoch 240/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3409 - binary_accuracy: 0.8353 - val_loss: 0.4360 - val_binary_accuracy: 0.8030\n",
      "Epoch 241/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3409 - binary_accuracy: 0.8380 - val_loss: 0.4322 - val_binary_accuracy: 0.8023\n",
      "Epoch 242/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3406 - binary_accuracy: 0.8332 - val_loss: 0.4363 - val_binary_accuracy: 0.8059\n",
      "Epoch 243/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3425 - binary_accuracy: 0.8368 - val_loss: 0.4332 - val_binary_accuracy: 0.8023\n",
      "Epoch 244/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3401 - binary_accuracy: 0.8353 - val_loss: 0.4355 - val_binary_accuracy: 0.8037\n",
      "Epoch 245/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3396 - binary_accuracy: 0.8400 - val_loss: 0.4380 - val_binary_accuracy: 0.8016\n",
      "Epoch 246/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3391 - binary_accuracy: 0.8368 - val_loss: 0.4358 - val_binary_accuracy: 0.7965\n",
      "Epoch 247/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3399 - binary_accuracy: 0.8359 - val_loss: 0.4389 - val_binary_accuracy: 0.8037\n",
      "Epoch 248/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3398 - binary_accuracy: 0.8346 - val_loss: 0.4399 - val_binary_accuracy: 0.7973\n",
      "Epoch 249/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3411 - binary_accuracy: 0.8346 - val_loss: 0.4378 - val_binary_accuracy: 0.8081\n",
      "Epoch 250/250\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.3403 - binary_accuracy: 0.8362 - val_loss: 0.4384 - val_binary_accuracy: 0.7980\n"
     ]
    }
   ],
   "source": [
    "model_5 = keras.Sequential([\n",
    "    # the hidden ReLU layers\n",
    "    layers.Dense(units=23, activation='relu', input_shape=[23]),\n",
    "    layers.Dense(units=10, activation='relu'),\n",
    "    layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model_5.compile(optimizer='adam',loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "history=model_5.fit(x_1train,y_1train,epochs=250,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db329132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.632622</td>\n",
       "      <td>0.668884</td>\n",
       "      <td>0.532456</td>\n",
       "      <td>0.755572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.477253</td>\n",
       "      <td>0.768111</td>\n",
       "      <td>0.453660</td>\n",
       "      <td>0.783609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.435405</td>\n",
       "      <td>0.787345</td>\n",
       "      <td>0.435887</td>\n",
       "      <td>0.785047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421234</td>\n",
       "      <td>0.793996</td>\n",
       "      <td>0.429259</td>\n",
       "      <td>0.805176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412916</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.420700</td>\n",
       "      <td>0.803019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.339101</td>\n",
       "      <td>0.836779</td>\n",
       "      <td>0.435755</td>\n",
       "      <td>0.796549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.339899</td>\n",
       "      <td>0.835880</td>\n",
       "      <td>0.438864</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.339814</td>\n",
       "      <td>0.834622</td>\n",
       "      <td>0.439901</td>\n",
       "      <td>0.797268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.341073</td>\n",
       "      <td>0.834622</td>\n",
       "      <td>0.437840</td>\n",
       "      <td>0.808052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.340329</td>\n",
       "      <td>0.836239</td>\n",
       "      <td>0.438388</td>\n",
       "      <td>0.797987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0    0.632622         0.668884  0.532456             0.755572\n",
       "1    0.477253         0.768111  0.453660             0.783609\n",
       "2    0.435405         0.787345  0.435887             0.785047\n",
       "3    0.421234         0.793996  0.429259             0.805176\n",
       "4    0.412916         0.799748  0.420700             0.803019\n",
       "..        ...              ...       ...                  ...\n",
       "245  0.339101         0.836779  0.435755             0.796549\n",
       "246  0.339899         0.835880  0.438864             0.803738\n",
       "247  0.339814         0.834622  0.439901             0.797268\n",
       "248  0.341073         0.834622  0.437840             0.808052\n",
       "249  0.340329         0.836239  0.438388             0.797987\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7c31ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step\n",
      "0.7918343875790684\n",
      "55/55 [==============================] - 0s 1ms/step\n",
      "0.8116438356164384\n",
      "55/55 [==============================] - 0s 871us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       863\n",
      "           1       0.78      0.81      0.80       876\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.79      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n",
      "55/55 [==============================] - 0s 1ms/step\n",
      "confusion matrix:\n",
      "\n",
      " [[666 197]\n",
      " [165 711]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_1test,np.round(model_5.predict(x_1test))))\n",
    "print(metrics.recall_score(y_1test,np.round(model_5.predict(x_1test))))\n",
    "print(metrics.classification_report(y_1test,np.round(model_5.predict(x_1test))))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_1test,np.round(model_5.predict(x_1test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e0093",
   "metadata": {},
   "source": [
    "### Creating a modelwith the whole data with the best model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d3be348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.5472 - binary_accuracy: 0.7114 - val_loss: 0.4647 - val_binary_accuracy: 0.7769\n",
      "Epoch 2/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4489 - binary_accuracy: 0.7844 - val_loss: 0.4247 - val_binary_accuracy: 0.7993\n",
      "Epoch 3/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4266 - binary_accuracy: 0.7949 - val_loss: 0.4140 - val_binary_accuracy: 0.8033\n",
      "Epoch 4/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4180 - binary_accuracy: 0.7982 - val_loss: 0.4057 - val_binary_accuracy: 0.8068\n",
      "Epoch 5/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4128 - binary_accuracy: 0.8030 - val_loss: 0.4059 - val_binary_accuracy: 0.8022\n",
      "Epoch 6/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4092 - binary_accuracy: 0.8057 - val_loss: 0.4049 - val_binary_accuracy: 0.8033\n",
      "Epoch 7/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4071 - binary_accuracy: 0.8059 - val_loss: 0.3996 - val_binary_accuracy: 0.8028\n",
      "Epoch 8/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4039 - binary_accuracy: 0.8051 - val_loss: 0.4000 - val_binary_accuracy: 0.8085\n",
      "Epoch 9/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4014 - binary_accuracy: 0.8079 - val_loss: 0.4065 - val_binary_accuracy: 0.8062\n",
      "Epoch 10/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.4014 - binary_accuracy: 0.8097 - val_loss: 0.4026 - val_binary_accuracy: 0.7976\n",
      "Epoch 11/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3999 - binary_accuracy: 0.8097 - val_loss: 0.3952 - val_binary_accuracy: 0.8068\n",
      "Epoch 12/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3985 - binary_accuracy: 0.8079 - val_loss: 0.4009 - val_binary_accuracy: 0.8022\n",
      "Epoch 13/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3975 - binary_accuracy: 0.8076 - val_loss: 0.4025 - val_binary_accuracy: 0.8005\n",
      "Epoch 14/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3970 - binary_accuracy: 0.8082 - val_loss: 0.3988 - val_binary_accuracy: 0.8045\n",
      "Epoch 15/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3965 - binary_accuracy: 0.8077 - val_loss: 0.3990 - val_binary_accuracy: 0.8010\n",
      "Epoch 16/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3949 - binary_accuracy: 0.8119 - val_loss: 0.3944 - val_binary_accuracy: 0.8022\n",
      "Epoch 17/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3948 - binary_accuracy: 0.8106 - val_loss: 0.4065 - val_binary_accuracy: 0.7982\n",
      "Epoch 18/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3939 - binary_accuracy: 0.8105 - val_loss: 0.3991 - val_binary_accuracy: 0.7982\n",
      "Epoch 19/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3926 - binary_accuracy: 0.8112 - val_loss: 0.3967 - val_binary_accuracy: 0.8039\n",
      "Epoch 20/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3922 - binary_accuracy: 0.8110 - val_loss: 0.4049 - val_binary_accuracy: 0.7976\n",
      "Epoch 21/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3925 - binary_accuracy: 0.8139 - val_loss: 0.4026 - val_binary_accuracy: 0.8016\n",
      "Epoch 22/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3910 - binary_accuracy: 0.8139 - val_loss: 0.4010 - val_binary_accuracy: 0.8039\n",
      "Epoch 23/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3904 - binary_accuracy: 0.8096 - val_loss: 0.3988 - val_binary_accuracy: 0.8039\n",
      "Epoch 24/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3899 - binary_accuracy: 0.8132 - val_loss: 0.3994 - val_binary_accuracy: 0.8045\n",
      "Epoch 25/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3894 - binary_accuracy: 0.8106 - val_loss: 0.3974 - val_binary_accuracy: 0.8045\n",
      "Epoch 26/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3888 - binary_accuracy: 0.8159 - val_loss: 0.3973 - val_binary_accuracy: 0.7993\n",
      "Epoch 27/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3888 - binary_accuracy: 0.8146 - val_loss: 0.4016 - val_binary_accuracy: 0.7993\n",
      "Epoch 28/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3876 - binary_accuracy: 0.8148 - val_loss: 0.3962 - val_binary_accuracy: 0.8022\n",
      "Epoch 29/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3864 - binary_accuracy: 0.8149 - val_loss: 0.4037 - val_binary_accuracy: 0.8010\n",
      "Epoch 30/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3868 - binary_accuracy: 0.8121 - val_loss: 0.4053 - val_binary_accuracy: 0.7999\n",
      "Epoch 31/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3861 - binary_accuracy: 0.8132 - val_loss: 0.4057 - val_binary_accuracy: 0.7982\n",
      "Epoch 32/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3859 - binary_accuracy: 0.8142 - val_loss: 0.4047 - val_binary_accuracy: 0.7999\n",
      "Epoch 33/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3853 - binary_accuracy: 0.8129 - val_loss: 0.3975 - val_binary_accuracy: 0.8062\n",
      "Epoch 34/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3848 - binary_accuracy: 0.8149 - val_loss: 0.3997 - val_binary_accuracy: 0.8022\n",
      "Epoch 35/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3848 - binary_accuracy: 0.8132 - val_loss: 0.4060 - val_binary_accuracy: 0.7987\n",
      "Epoch 36/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3851 - binary_accuracy: 0.8136 - val_loss: 0.4076 - val_binary_accuracy: 0.7982\n",
      "Epoch 37/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3841 - binary_accuracy: 0.8149 - val_loss: 0.4071 - val_binary_accuracy: 0.8010\n",
      "Epoch 38/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3831 - binary_accuracy: 0.8142 - val_loss: 0.4061 - val_binary_accuracy: 0.7982\n",
      "Epoch 39/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3830 - binary_accuracy: 0.8156 - val_loss: 0.4075 - val_binary_accuracy: 0.8010\n",
      "Epoch 40/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3828 - binary_accuracy: 0.8146 - val_loss: 0.4116 - val_binary_accuracy: 0.7953\n",
      "Epoch 41/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3824 - binary_accuracy: 0.8154 - val_loss: 0.4116 - val_binary_accuracy: 0.7993\n",
      "Epoch 42/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3811 - binary_accuracy: 0.8154 - val_loss: 0.3998 - val_binary_accuracy: 0.7987\n",
      "Epoch 43/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3816 - binary_accuracy: 0.8159 - val_loss: 0.4076 - val_binary_accuracy: 0.8010\n",
      "Epoch 44/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3815 - binary_accuracy: 0.8171 - val_loss: 0.4012 - val_binary_accuracy: 0.7987\n",
      "Epoch 45/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3799 - binary_accuracy: 0.8174 - val_loss: 0.4048 - val_binary_accuracy: 0.8028\n",
      "Epoch 46/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3799 - binary_accuracy: 0.8151 - val_loss: 0.4014 - val_binary_accuracy: 0.7999\n",
      "Epoch 47/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3805 - binary_accuracy: 0.8162 - val_loss: 0.4042 - val_binary_accuracy: 0.8056\n",
      "Epoch 48/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3793 - binary_accuracy: 0.8172 - val_loss: 0.4021 - val_binary_accuracy: 0.7976\n",
      "Epoch 49/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3791 - binary_accuracy: 0.8182 - val_loss: 0.4056 - val_binary_accuracy: 0.8005\n",
      "Epoch 50/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3791 - binary_accuracy: 0.8136 - val_loss: 0.4035 - val_binary_accuracy: 0.8022\n",
      "Epoch 51/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3788 - binary_accuracy: 0.8184 - val_loss: 0.4059 - val_binary_accuracy: 0.7993\n",
      "Epoch 52/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3783 - binary_accuracy: 0.8169 - val_loss: 0.4080 - val_binary_accuracy: 0.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3777 - binary_accuracy: 0.8174 - val_loss: 0.4016 - val_binary_accuracy: 0.8005\n",
      "Epoch 54/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3776 - binary_accuracy: 0.8162 - val_loss: 0.4050 - val_binary_accuracy: 0.7976\n",
      "Epoch 55/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3770 - binary_accuracy: 0.8191 - val_loss: 0.4016 - val_binary_accuracy: 0.8051\n",
      "Epoch 56/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3780 - binary_accuracy: 0.8164 - val_loss: 0.4055 - val_binary_accuracy: 0.7959\n",
      "Epoch 57/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3776 - binary_accuracy: 0.8188 - val_loss: 0.4002 - val_binary_accuracy: 0.8051\n",
      "Epoch 58/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3766 - binary_accuracy: 0.8172 - val_loss: 0.3966 - val_binary_accuracy: 0.8056\n",
      "Epoch 59/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3762 - binary_accuracy: 0.8162 - val_loss: 0.4106 - val_binary_accuracy: 0.7999\n",
      "Epoch 60/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3766 - binary_accuracy: 0.8177 - val_loss: 0.4028 - val_binary_accuracy: 0.8005\n",
      "Epoch 61/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3757 - binary_accuracy: 0.8158 - val_loss: 0.4091 - val_binary_accuracy: 0.8010\n",
      "Epoch 62/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3754 - binary_accuracy: 0.8188 - val_loss: 0.4083 - val_binary_accuracy: 0.7930\n",
      "Epoch 63/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3754 - binary_accuracy: 0.8177 - val_loss: 0.4054 - val_binary_accuracy: 0.7970\n",
      "Epoch 64/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3748 - binary_accuracy: 0.8174 - val_loss: 0.4049 - val_binary_accuracy: 0.8033\n",
      "Epoch 65/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3747 - binary_accuracy: 0.8165 - val_loss: 0.4029 - val_binary_accuracy: 0.8039\n",
      "Epoch 66/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3754 - binary_accuracy: 0.8174 - val_loss: 0.4045 - val_binary_accuracy: 0.8051\n",
      "Epoch 67/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3746 - binary_accuracy: 0.8191 - val_loss: 0.4094 - val_binary_accuracy: 0.7976\n",
      "Epoch 68/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3744 - binary_accuracy: 0.8168 - val_loss: 0.4068 - val_binary_accuracy: 0.7993\n",
      "Epoch 69/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3733 - binary_accuracy: 0.8175 - val_loss: 0.4091 - val_binary_accuracy: 0.7999\n",
      "Epoch 70/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3742 - binary_accuracy: 0.8191 - val_loss: 0.4045 - val_binary_accuracy: 0.7959\n",
      "Epoch 71/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3738 - binary_accuracy: 0.8167 - val_loss: 0.4106 - val_binary_accuracy: 0.7913\n",
      "Epoch 72/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3728 - binary_accuracy: 0.8207 - val_loss: 0.4129 - val_binary_accuracy: 0.7970\n",
      "Epoch 73/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3735 - binary_accuracy: 0.8179 - val_loss: 0.4112 - val_binary_accuracy: 0.7982\n",
      "Epoch 74/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3735 - binary_accuracy: 0.8185 - val_loss: 0.4008 - val_binary_accuracy: 0.8005\n",
      "Epoch 75/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3712 - binary_accuracy: 0.8205 - val_loss: 0.4100 - val_binary_accuracy: 0.7987\n",
      "Epoch 76/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3727 - binary_accuracy: 0.8169 - val_loss: 0.4151 - val_binary_accuracy: 0.7964\n",
      "Epoch 77/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3725 - binary_accuracy: 0.8162 - val_loss: 0.4031 - val_binary_accuracy: 0.8010\n",
      "Epoch 78/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3733 - binary_accuracy: 0.8174 - val_loss: 0.4030 - val_binary_accuracy: 0.7999\n",
      "Epoch 79/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3712 - binary_accuracy: 0.8214 - val_loss: 0.4046 - val_binary_accuracy: 0.8051\n",
      "Epoch 80/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3712 - binary_accuracy: 0.8194 - val_loss: 0.4088 - val_binary_accuracy: 0.7987\n",
      "Epoch 81/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3721 - binary_accuracy: 0.8174 - val_loss: 0.4173 - val_binary_accuracy: 0.7941\n",
      "Epoch 82/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3710 - binary_accuracy: 0.8179 - val_loss: 0.4043 - val_binary_accuracy: 0.7976\n",
      "Epoch 83/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3709 - binary_accuracy: 0.8192 - val_loss: 0.4137 - val_binary_accuracy: 0.7924\n",
      "Epoch 84/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3704 - binary_accuracy: 0.8213 - val_loss: 0.4112 - val_binary_accuracy: 0.7993\n",
      "Epoch 85/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3699 - binary_accuracy: 0.8167 - val_loss: 0.4053 - val_binary_accuracy: 0.7999\n",
      "Epoch 86/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3707 - binary_accuracy: 0.8194 - val_loss: 0.4174 - val_binary_accuracy: 0.7976\n",
      "Epoch 87/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3702 - binary_accuracy: 0.8187 - val_loss: 0.4083 - val_binary_accuracy: 0.7947\n",
      "Epoch 88/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3705 - binary_accuracy: 0.8171 - val_loss: 0.4094 - val_binary_accuracy: 0.8016\n",
      "Epoch 89/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3689 - binary_accuracy: 0.8197 - val_loss: 0.4038 - val_binary_accuracy: 0.7993\n",
      "Epoch 90/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3701 - binary_accuracy: 0.8184 - val_loss: 0.4085 - val_binary_accuracy: 0.7964\n",
      "Epoch 91/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3699 - binary_accuracy: 0.8201 - val_loss: 0.4213 - val_binary_accuracy: 0.7930\n",
      "Epoch 92/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3686 - binary_accuracy: 0.8175 - val_loss: 0.4156 - val_binary_accuracy: 0.7947\n",
      "Epoch 93/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3682 - binary_accuracy: 0.8215 - val_loss: 0.4082 - val_binary_accuracy: 0.8033\n",
      "Epoch 94/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3692 - binary_accuracy: 0.8228 - val_loss: 0.4242 - val_binary_accuracy: 0.7918\n",
      "Epoch 95/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3681 - binary_accuracy: 0.8204 - val_loss: 0.4057 - val_binary_accuracy: 0.7987\n",
      "Epoch 96/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3677 - binary_accuracy: 0.8178 - val_loss: 0.4084 - val_binary_accuracy: 0.7976\n",
      "Epoch 97/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3678 - binary_accuracy: 0.8200 - val_loss: 0.4229 - val_binary_accuracy: 0.7930\n",
      "Epoch 98/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3680 - binary_accuracy: 0.8198 - val_loss: 0.4207 - val_binary_accuracy: 0.7953\n",
      "Epoch 99/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3673 - binary_accuracy: 0.8220 - val_loss: 0.4079 - val_binary_accuracy: 0.8045\n",
      "Epoch 100/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3677 - binary_accuracy: 0.8215 - val_loss: 0.4140 - val_binary_accuracy: 0.7970\n",
      "Epoch 101/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3682 - binary_accuracy: 0.8177 - val_loss: 0.4208 - val_binary_accuracy: 0.7959\n",
      "Epoch 102/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3663 - binary_accuracy: 0.8197 - val_loss: 0.4156 - val_binary_accuracy: 0.7959\n",
      "Epoch 103/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3665 - binary_accuracy: 0.8195 - val_loss: 0.4228 - val_binary_accuracy: 0.7936\n",
      "Epoch 104/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3675 - binary_accuracy: 0.8195 - val_loss: 0.4139 - val_binary_accuracy: 0.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3664 - binary_accuracy: 0.8191 - val_loss: 0.4164 - val_binary_accuracy: 0.7999\n",
      "Epoch 106/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3674 - binary_accuracy: 0.8195 - val_loss: 0.4210 - val_binary_accuracy: 0.7976\n",
      "Epoch 107/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3668 - binary_accuracy: 0.8202 - val_loss: 0.4202 - val_binary_accuracy: 0.7999\n",
      "Epoch 108/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3670 - binary_accuracy: 0.8182 - val_loss: 0.4253 - val_binary_accuracy: 0.7930\n",
      "Epoch 109/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3661 - binary_accuracy: 0.8210 - val_loss: 0.4144 - val_binary_accuracy: 0.8022\n",
      "Epoch 110/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3655 - binary_accuracy: 0.8200 - val_loss: 0.4176 - val_binary_accuracy: 0.8005\n",
      "Epoch 111/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3648 - binary_accuracy: 0.8230 - val_loss: 0.4147 - val_binary_accuracy: 0.8005\n",
      "Epoch 112/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3653 - binary_accuracy: 0.8200 - val_loss: 0.4147 - val_binary_accuracy: 0.7987\n",
      "Epoch 113/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3659 - binary_accuracy: 0.8210 - val_loss: 0.4271 - val_binary_accuracy: 0.7976\n",
      "Epoch 114/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3652 - binary_accuracy: 0.8205 - val_loss: 0.4216 - val_binary_accuracy: 0.7959\n",
      "Epoch 115/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3658 - binary_accuracy: 0.8217 - val_loss: 0.4221 - val_binary_accuracy: 0.7993\n",
      "Epoch 116/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3650 - binary_accuracy: 0.8201 - val_loss: 0.4133 - val_binary_accuracy: 0.7999\n",
      "Epoch 117/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3654 - binary_accuracy: 0.8233 - val_loss: 0.4172 - val_binary_accuracy: 0.7953\n",
      "Epoch 118/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3649 - binary_accuracy: 0.8221 - val_loss: 0.4169 - val_binary_accuracy: 0.7982\n",
      "Epoch 119/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3644 - binary_accuracy: 0.8246 - val_loss: 0.4224 - val_binary_accuracy: 0.7959\n",
      "Epoch 120/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3650 - binary_accuracy: 0.8211 - val_loss: 0.4122 - val_binary_accuracy: 0.7913\n",
      "Epoch 121/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3655 - binary_accuracy: 0.8210 - val_loss: 0.4235 - val_binary_accuracy: 0.7964\n",
      "Epoch 122/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3647 - binary_accuracy: 0.8213 - val_loss: 0.4195 - val_binary_accuracy: 0.7941\n",
      "Epoch 123/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3637 - binary_accuracy: 0.8202 - val_loss: 0.4235 - val_binary_accuracy: 0.8005\n",
      "Epoch 124/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3642 - binary_accuracy: 0.8224 - val_loss: 0.4277 - val_binary_accuracy: 0.7953\n",
      "Epoch 125/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3641 - binary_accuracy: 0.8223 - val_loss: 0.4224 - val_binary_accuracy: 0.7953\n",
      "Epoch 126/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3636 - binary_accuracy: 0.8205 - val_loss: 0.4217 - val_binary_accuracy: 0.7936\n",
      "Epoch 127/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3636 - binary_accuracy: 0.8210 - val_loss: 0.4164 - val_binary_accuracy: 0.7953\n",
      "Epoch 128/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3641 - binary_accuracy: 0.8233 - val_loss: 0.4247 - val_binary_accuracy: 0.7936\n",
      "Epoch 129/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3632 - binary_accuracy: 0.8225 - val_loss: 0.4170 - val_binary_accuracy: 0.7964\n",
      "Epoch 130/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3627 - binary_accuracy: 0.8240 - val_loss: 0.4200 - val_binary_accuracy: 0.7930\n",
      "Epoch 131/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3634 - binary_accuracy: 0.8231 - val_loss: 0.4154 - val_binary_accuracy: 0.7959\n",
      "Epoch 132/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3627 - binary_accuracy: 0.8225 - val_loss: 0.4253 - val_binary_accuracy: 0.7913\n",
      "Epoch 133/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3623 - binary_accuracy: 0.8237 - val_loss: 0.4212 - val_binary_accuracy: 0.7953\n",
      "Epoch 134/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3623 - binary_accuracy: 0.8231 - val_loss: 0.4169 - val_binary_accuracy: 0.7976\n",
      "Epoch 135/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3639 - binary_accuracy: 0.8236 - val_loss: 0.4207 - val_binary_accuracy: 0.7982\n",
      "Epoch 136/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3633 - binary_accuracy: 0.8237 - val_loss: 0.4284 - val_binary_accuracy: 0.7936\n",
      "Epoch 137/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3625 - binary_accuracy: 0.8218 - val_loss: 0.4195 - val_binary_accuracy: 0.7976\n",
      "Epoch 138/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3614 - binary_accuracy: 0.8210 - val_loss: 0.4273 - val_binary_accuracy: 0.7884\n",
      "Epoch 139/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3631 - binary_accuracy: 0.8220 - val_loss: 0.4306 - val_binary_accuracy: 0.7993\n",
      "Epoch 140/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3629 - binary_accuracy: 0.8228 - val_loss: 0.4287 - val_binary_accuracy: 0.7947\n",
      "Epoch 141/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3620 - binary_accuracy: 0.8247 - val_loss: 0.4246 - val_binary_accuracy: 0.7936\n",
      "Epoch 142/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3620 - binary_accuracy: 0.8213 - val_loss: 0.4139 - val_binary_accuracy: 0.7959\n",
      "Epoch 143/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3611 - binary_accuracy: 0.8266 - val_loss: 0.4185 - val_binary_accuracy: 0.7982\n",
      "Epoch 144/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3615 - binary_accuracy: 0.8208 - val_loss: 0.4267 - val_binary_accuracy: 0.7953\n",
      "Epoch 145/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3614 - binary_accuracy: 0.8227 - val_loss: 0.4256 - val_binary_accuracy: 0.7936\n",
      "Epoch 146/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3610 - binary_accuracy: 0.8238 - val_loss: 0.4168 - val_binary_accuracy: 0.7976\n",
      "Epoch 147/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3613 - binary_accuracy: 0.8207 - val_loss: 0.4287 - val_binary_accuracy: 0.7976\n",
      "Epoch 148/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3625 - binary_accuracy: 0.8213 - val_loss: 0.4286 - val_binary_accuracy: 0.7947\n",
      "Epoch 149/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3625 - binary_accuracy: 0.8241 - val_loss: 0.4167 - val_binary_accuracy: 0.7959\n",
      "Epoch 150/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3616 - binary_accuracy: 0.8221 - val_loss: 0.4215 - val_binary_accuracy: 0.7987\n",
      "Epoch 151/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3606 - binary_accuracy: 0.8224 - val_loss: 0.4249 - val_binary_accuracy: 0.7895\n",
      "Epoch 152/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3623 - binary_accuracy: 0.8223 - val_loss: 0.4294 - val_binary_accuracy: 0.7959\n",
      "Epoch 153/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3608 - binary_accuracy: 0.8270 - val_loss: 0.4184 - val_binary_accuracy: 0.7982\n",
      "Epoch 154/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3620 - binary_accuracy: 0.8246 - val_loss: 0.4183 - val_binary_accuracy: 0.7930\n",
      "Epoch 155/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3604 - binary_accuracy: 0.8238 - val_loss: 0.4220 - val_binary_accuracy: 0.7895\n",
      "Epoch 156/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3625 - binary_accuracy: 0.8250 - val_loss: 0.4243 - val_binary_accuracy: 0.7947\n",
      "Epoch 157/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3612 - binary_accuracy: 0.8238 - val_loss: 0.4271 - val_binary_accuracy: 0.7970\n",
      "Epoch 158/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3602 - binary_accuracy: 0.8237 - val_loss: 0.4228 - val_binary_accuracy: 0.7953\n",
      "Epoch 159/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3615 - binary_accuracy: 0.8210 - val_loss: 0.4329 - val_binary_accuracy: 0.7924\n",
      "Epoch 160/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3601 - binary_accuracy: 0.8274 - val_loss: 0.4244 - val_binary_accuracy: 0.7941\n",
      "Epoch 161/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3605 - binary_accuracy: 0.8227 - val_loss: 0.4217 - val_binary_accuracy: 0.7941\n",
      "Epoch 162/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3602 - binary_accuracy: 0.8228 - val_loss: 0.4302 - val_binary_accuracy: 0.7976\n",
      "Epoch 163/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3608 - binary_accuracy: 0.8213 - val_loss: 0.4258 - val_binary_accuracy: 0.7970\n",
      "Epoch 164/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3597 - binary_accuracy: 0.8251 - val_loss: 0.4285 - val_binary_accuracy: 0.7924\n",
      "Epoch 165/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3602 - binary_accuracy: 0.8210 - val_loss: 0.4285 - val_binary_accuracy: 0.7941\n",
      "Epoch 166/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3606 - binary_accuracy: 0.8248 - val_loss: 0.4293 - val_binary_accuracy: 0.7890\n",
      "Epoch 167/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3610 - binary_accuracy: 0.8241 - val_loss: 0.4324 - val_binary_accuracy: 0.7924\n",
      "Epoch 168/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3593 - binary_accuracy: 0.8243 - val_loss: 0.4338 - val_binary_accuracy: 0.7901\n",
      "Epoch 169/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3599 - binary_accuracy: 0.8218 - val_loss: 0.4284 - val_binary_accuracy: 0.7907\n",
      "Epoch 170/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3596 - binary_accuracy: 0.8247 - val_loss: 0.4297 - val_binary_accuracy: 0.7936\n",
      "Epoch 171/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3587 - binary_accuracy: 0.8234 - val_loss: 0.4203 - val_binary_accuracy: 0.7930\n",
      "Epoch 172/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3590 - binary_accuracy: 0.8210 - val_loss: 0.4281 - val_binary_accuracy: 0.7964\n",
      "Epoch 173/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3595 - binary_accuracy: 0.8231 - val_loss: 0.4288 - val_binary_accuracy: 0.7907\n",
      "Epoch 174/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3590 - binary_accuracy: 0.8248 - val_loss: 0.4261 - val_binary_accuracy: 0.7936\n",
      "Epoch 175/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3588 - binary_accuracy: 0.8254 - val_loss: 0.4265 - val_binary_accuracy: 0.7936\n",
      "Epoch 176/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3587 - binary_accuracy: 0.8251 - val_loss: 0.4226 - val_binary_accuracy: 0.7964\n",
      "Epoch 177/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3587 - binary_accuracy: 0.8257 - val_loss: 0.4300 - val_binary_accuracy: 0.7964\n",
      "Epoch 178/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3597 - binary_accuracy: 0.8246 - val_loss: 0.4251 - val_binary_accuracy: 0.7930\n",
      "Epoch 179/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3591 - binary_accuracy: 0.8241 - val_loss: 0.4276 - val_binary_accuracy: 0.7964\n",
      "Epoch 180/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3591 - binary_accuracy: 0.8237 - val_loss: 0.4300 - val_binary_accuracy: 0.7930\n",
      "Epoch 181/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3586 - binary_accuracy: 0.8248 - val_loss: 0.4454 - val_binary_accuracy: 0.7878\n",
      "Epoch 182/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3576 - binary_accuracy: 0.8251 - val_loss: 0.4208 - val_binary_accuracy: 0.7976\n",
      "Epoch 183/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3598 - binary_accuracy: 0.8247 - val_loss: 0.4240 - val_binary_accuracy: 0.7959\n",
      "Epoch 184/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8250 - val_loss: 0.4316 - val_binary_accuracy: 0.7947\n",
      "Epoch 185/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8241 - val_loss: 0.4258 - val_binary_accuracy: 0.7982\n",
      "Epoch 186/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8236 - val_loss: 0.4200 - val_binary_accuracy: 0.7953\n",
      "Epoch 187/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3586 - binary_accuracy: 0.8231 - val_loss: 0.4266 - val_binary_accuracy: 0.7947\n",
      "Epoch 188/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3584 - binary_accuracy: 0.8233 - val_loss: 0.4306 - val_binary_accuracy: 0.7907\n",
      "Epoch 189/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3570 - binary_accuracy: 0.8271 - val_loss: 0.4283 - val_binary_accuracy: 0.7959\n",
      "Epoch 190/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3571 - binary_accuracy: 0.8250 - val_loss: 0.4284 - val_binary_accuracy: 0.7941\n",
      "Epoch 191/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3567 - binary_accuracy: 0.8257 - val_loss: 0.4251 - val_binary_accuracy: 0.7953\n",
      "Epoch 192/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3574 - binary_accuracy: 0.8250 - val_loss: 0.4329 - val_binary_accuracy: 0.7953\n",
      "Epoch 193/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3579 - binary_accuracy: 0.8236 - val_loss: 0.4286 - val_binary_accuracy: 0.7872\n",
      "Epoch 194/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3567 - binary_accuracy: 0.8241 - val_loss: 0.4288 - val_binary_accuracy: 0.7953\n",
      "Epoch 195/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3564 - binary_accuracy: 0.8259 - val_loss: 0.4345 - val_binary_accuracy: 0.7844\n",
      "Epoch 196/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3568 - binary_accuracy: 0.8248 - val_loss: 0.4311 - val_binary_accuracy: 0.7936\n",
      "Epoch 197/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3567 - binary_accuracy: 0.8246 - val_loss: 0.4321 - val_binary_accuracy: 0.7913\n",
      "Epoch 198/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3564 - binary_accuracy: 0.8256 - val_loss: 0.4283 - val_binary_accuracy: 0.7913\n",
      "Epoch 199/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3569 - binary_accuracy: 0.8243 - val_loss: 0.4309 - val_binary_accuracy: 0.7890\n",
      "Epoch 200/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3562 - binary_accuracy: 0.8246 - val_loss: 0.4421 - val_binary_accuracy: 0.7890\n",
      "Epoch 201/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3581 - binary_accuracy: 0.8253 - val_loss: 0.4285 - val_binary_accuracy: 0.7936\n",
      "Epoch 202/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3564 - binary_accuracy: 0.8250 - val_loss: 0.4320 - val_binary_accuracy: 0.7878\n",
      "Epoch 203/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3568 - binary_accuracy: 0.8234 - val_loss: 0.4293 - val_binary_accuracy: 0.7930\n",
      "Epoch 204/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3567 - binary_accuracy: 0.8243 - val_loss: 0.4399 - val_binary_accuracy: 0.7941\n",
      "Epoch 205/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3556 - binary_accuracy: 0.8271 - val_loss: 0.4347 - val_binary_accuracy: 0.7913\n",
      "Epoch 206/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3561 - binary_accuracy: 0.8247 - val_loss: 0.4335 - val_binary_accuracy: 0.7901\n",
      "Epoch 207/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3554 - binary_accuracy: 0.8267 - val_loss: 0.4379 - val_binary_accuracy: 0.7913\n",
      "Epoch 208/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3567 - binary_accuracy: 0.8264 - val_loss: 0.4332 - val_binary_accuracy: 0.7936\n",
      "Epoch 209/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3554 - binary_accuracy: 0.8259 - val_loss: 0.4403 - val_binary_accuracy: 0.7930\n",
      "Epoch 210/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3567 - binary_accuracy: 0.8250 - val_loss: 0.4485 - val_binary_accuracy: 0.7907\n",
      "Epoch 211/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3553 - binary_accuracy: 0.8287 - val_loss: 0.4372 - val_binary_accuracy: 0.7884\n",
      "Epoch 212/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3556 - binary_accuracy: 0.8277 - val_loss: 0.4269 - val_binary_accuracy: 0.7901\n",
      "Epoch 213/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3559 - binary_accuracy: 0.8241 - val_loss: 0.4342 - val_binary_accuracy: 0.7890\n",
      "Epoch 214/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3550 - binary_accuracy: 0.8266 - val_loss: 0.4301 - val_binary_accuracy: 0.7947\n",
      "Epoch 215/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3553 - binary_accuracy: 0.8267 - val_loss: 0.4382 - val_binary_accuracy: 0.7878\n",
      "Epoch 216/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3551 - binary_accuracy: 0.8250 - val_loss: 0.4276 - val_binary_accuracy: 0.7941\n",
      "Epoch 217/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3554 - binary_accuracy: 0.8266 - val_loss: 0.4316 - val_binary_accuracy: 0.7867\n",
      "Epoch 218/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3560 - binary_accuracy: 0.8241 - val_loss: 0.4418 - val_binary_accuracy: 0.7890\n",
      "Epoch 219/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3557 - binary_accuracy: 0.8259 - val_loss: 0.4362 - val_binary_accuracy: 0.7901\n",
      "Epoch 220/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3550 - binary_accuracy: 0.8247 - val_loss: 0.4372 - val_binary_accuracy: 0.7913\n",
      "Epoch 221/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3545 - binary_accuracy: 0.8276 - val_loss: 0.4425 - val_binary_accuracy: 0.7895\n",
      "Epoch 222/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3550 - binary_accuracy: 0.8260 - val_loss: 0.4285 - val_binary_accuracy: 0.7947\n",
      "Epoch 223/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3563 - binary_accuracy: 0.8246 - val_loss: 0.4394 - val_binary_accuracy: 0.7930\n",
      "Epoch 224/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3541 - binary_accuracy: 0.8257 - val_loss: 0.4437 - val_binary_accuracy: 0.7901\n",
      "Epoch 225/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3535 - binary_accuracy: 0.8276 - val_loss: 0.4300 - val_binary_accuracy: 0.7947\n",
      "Epoch 226/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3548 - binary_accuracy: 0.8241 - val_loss: 0.4336 - val_binary_accuracy: 0.7999\n",
      "Epoch 227/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3544 - binary_accuracy: 0.8254 - val_loss: 0.4443 - val_binary_accuracy: 0.7855\n",
      "Epoch 228/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3538 - binary_accuracy: 0.8254 - val_loss: 0.4385 - val_binary_accuracy: 0.7924\n",
      "Epoch 229/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3531 - binary_accuracy: 0.8292 - val_loss: 0.4442 - val_binary_accuracy: 0.7867\n",
      "Epoch 230/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3539 - binary_accuracy: 0.8241 - val_loss: 0.4407 - val_binary_accuracy: 0.7907\n",
      "Epoch 231/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3536 - binary_accuracy: 0.8276 - val_loss: 0.4368 - val_binary_accuracy: 0.7913\n",
      "Epoch 232/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3542 - binary_accuracy: 0.8238 - val_loss: 0.4328 - val_binary_accuracy: 0.7918\n",
      "Epoch 233/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3539 - binary_accuracy: 0.8270 - val_loss: 0.4316 - val_binary_accuracy: 0.7947\n",
      "Epoch 234/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3534 - binary_accuracy: 0.8279 - val_loss: 0.4323 - val_binary_accuracy: 0.7918\n",
      "Epoch 235/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3531 - binary_accuracy: 0.8269 - val_loss: 0.4601 - val_binary_accuracy: 0.7844\n",
      "Epoch 236/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3541 - binary_accuracy: 0.8256 - val_loss: 0.4477 - val_binary_accuracy: 0.7861\n",
      "Epoch 237/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3540 - binary_accuracy: 0.8269 - val_loss: 0.4320 - val_binary_accuracy: 0.8010\n",
      "Epoch 238/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3538 - binary_accuracy: 0.8240 - val_loss: 0.4586 - val_binary_accuracy: 0.7855\n",
      "Epoch 239/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3539 - binary_accuracy: 0.8279 - val_loss: 0.4399 - val_binary_accuracy: 0.7953\n",
      "Epoch 240/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3532 - binary_accuracy: 0.8277 - val_loss: 0.4450 - val_binary_accuracy: 0.7890\n",
      "Epoch 241/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3546 - binary_accuracy: 0.8248 - val_loss: 0.4428 - val_binary_accuracy: 0.7878\n",
      "Epoch 242/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3533 - binary_accuracy: 0.8253 - val_loss: 0.4419 - val_binary_accuracy: 0.7872\n",
      "Epoch 243/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3538 - binary_accuracy: 0.8271 - val_loss: 0.4472 - val_binary_accuracy: 0.7930\n",
      "Epoch 244/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3527 - binary_accuracy: 0.8303 - val_loss: 0.4348 - val_binary_accuracy: 0.7895\n",
      "Epoch 245/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3527 - binary_accuracy: 0.8276 - val_loss: 0.4428 - val_binary_accuracy: 0.7987\n",
      "Epoch 246/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3533 - binary_accuracy: 0.8256 - val_loss: 0.4323 - val_binary_accuracy: 0.8005\n",
      "Epoch 247/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3536 - binary_accuracy: 0.8269 - val_loss: 0.4398 - val_binary_accuracy: 0.7901\n",
      "Epoch 248/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3523 - binary_accuracy: 0.8282 - val_loss: 0.4485 - val_binary_accuracy: 0.7907\n",
      "Epoch 249/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3524 - binary_accuracy: 0.8271 - val_loss: 0.4419 - val_binary_accuracy: 0.7918\n",
      "Epoch 250/250\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3530 - binary_accuracy: 0.8250 - val_loss: 0.4421 - val_binary_accuracy: 0.7918\n"
     ]
    }
   ],
   "source": [
    "model_6 = keras.Sequential([\n",
    "    # the hidden ReLU layers\n",
    "    layers.Dense(units=23, activation='relu', input_shape=[23]),\n",
    "    layers.Dense(units=10, activation='relu'),\n",
    "    layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model_6.compile(optimizer='adam',loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "history=model_6.fit(x_1,y_1,epochs=250,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd1b5c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547219</td>\n",
       "      <td>0.711389</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.776883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.448853</td>\n",
       "      <td>0.784441</td>\n",
       "      <td>0.424687</td>\n",
       "      <td>0.799310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.426574</td>\n",
       "      <td>0.794938</td>\n",
       "      <td>0.413960</td>\n",
       "      <td>0.803335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.418030</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.405703</td>\n",
       "      <td>0.806786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412764</td>\n",
       "      <td>0.802991</td>\n",
       "      <td>0.405869</td>\n",
       "      <td>0.802185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.353255</td>\n",
       "      <td>0.825568</td>\n",
       "      <td>0.432310</td>\n",
       "      <td>0.800460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.353618</td>\n",
       "      <td>0.826862</td>\n",
       "      <td>0.439796</td>\n",
       "      <td>0.790109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.352328</td>\n",
       "      <td>0.828156</td>\n",
       "      <td>0.448487</td>\n",
       "      <td>0.790684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.352395</td>\n",
       "      <td>0.827150</td>\n",
       "      <td>0.441942</td>\n",
       "      <td>0.791834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.353003</td>\n",
       "      <td>0.824993</td>\n",
       "      <td>0.442078</td>\n",
       "      <td>0.791834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  binary_accuracy  val_loss  val_binary_accuracy\n",
       "0    0.547219         0.711389  0.464741             0.776883\n",
       "1    0.448853         0.784441  0.424687             0.799310\n",
       "2    0.426574         0.794938  0.413960             0.803335\n",
       "3    0.418030         0.798246  0.405703             0.806786\n",
       "4    0.412764         0.802991  0.405869             0.802185\n",
       "..        ...              ...       ...                  ...\n",
       "245  0.353255         0.825568  0.432310             0.800460\n",
       "246  0.353618         0.826862  0.439796             0.790109\n",
       "247  0.352328         0.828156  0.448487             0.790684\n",
       "248  0.352395         0.827150  0.441942             0.791834\n",
       "249  0.353003         0.824993  0.442078             0.791834\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5ba4a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36468464e+00, -1.27486483e-01, -1.53063067e-01, ...,\n",
       "        -5.11013194e-01, -3.17486647e-01,  6.52520630e-01],\n",
       "       [-7.32770025e-01, -6.85435421e-01, -1.53063067e-01, ...,\n",
       "        -5.11013194e-01, -3.17486647e-01,  6.52520630e-01],\n",
       "       [ 1.36468464e+00,  1.51487986e-01, -1.53063067e-01, ...,\n",
       "         1.95689664e+00, -3.17486647e-01, -1.53251860e+00],\n",
       "       ...,\n",
       "       [ 1.36468464e+00, -4.95558206e-16, -1.53063067e-01, ...,\n",
       "         1.95689664e+00, -3.17486647e-01, -1.53251860e+00],\n",
       "       [-7.32770025e-01, -4.95558206e-16, -1.53063067e-01, ...,\n",
       "        -5.11013194e-01, -3.17486647e-01,  6.52520630e-01],\n",
       "       [ 1.36468464e+00,  9.88411394e-01, -1.53063067e-01, ...,\n",
       "        -5.11013194e-01,  3.14973876e+00, -1.53251860e+00]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304945b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca8a97a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 977us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=model_6.predict(test_final)\n",
    "e=np.round(e).astype('bool')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da39112c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462420f8",
   "metadata": {},
   "source": [
    "### creating a csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9b17b9c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01         True\n",
       "1        0018_01        False\n",
       "2        0019_01         True\n",
       "3        0021_01         True\n",
       "4        0023_01         True\n",
       "...          ...          ...\n",
       "4272     9266_02         True\n",
       "4273     9269_01         True\n",
       "4274     9271_01         True\n",
       "4275     9273_01         True\n",
       "4276     9277_01         True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_e = pd.DataFrame({'PassengerId':ID,'Transported':e[:,0]})\n",
    "submission_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0bc0ca56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     2300\n",
       "False    1977\n",
       "Name: Transported, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_e.Transported.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5aec0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_e.to_csv('submission_e.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06c884fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              1          0      1            2  39.0    0          0.0   \n",
       "1              0          0      5            2  24.0    0        109.0   \n",
       "2              1          0      0            2  58.0    1         43.0   \n",
       "3              1          0      0            2  33.0    0          0.0   \n",
       "4              0          0      5            2  16.0    0        303.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "8688           1          0      0            0  41.0    1          0.0   \n",
       "8689           0          1      6            1  18.0    0          0.0   \n",
       "8690           0          0      6            2  26.0    0          0.0   \n",
       "8691           1          0      4            0  32.0    0          0.0   \n",
       "8692           1          0      4            2  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported  Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0            0        0  \n",
       "1           9.0          25.0   549.0    44.0            1        1  \n",
       "2        3576.0           0.0  6715.0    49.0            0        1  \n",
       "3        1283.0         371.0  3329.0   193.0            0        1  \n",
       "4          70.0         151.0   565.0     2.0            1        1  \n",
       "...         ...           ...     ...     ...          ...      ...  \n",
       "8688     6819.0           0.0  1643.0    74.0            0        0  \n",
       "8689        0.0           0.0     0.0     0.0            0        1  \n",
       "8690        0.0        1872.0     1.0     0.0            1        1  \n",
       "8691     1049.0           0.0   353.0  3235.0            0        1  \n",
       "8692     4688.0           0.0     0.0    12.0            1        1  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd1407",
   "metadata": {},
   "source": [
    "### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "483e427a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_1.RoomService.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d30aeeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_1.FoodCourt.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f238dd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_1.ShoppingMall.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98e510b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_1.Spa.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f230e1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_1.VRDeck.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "090b41de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8415</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>23492.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "8415           1          0      1            2  17.0    0          0.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall    Spa  VRDeck  Transported  Cabin_s  \n",
       "8415      366.0       23492.0  356.0     3.0            1        0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[data_1.ShoppingMall>20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e6a111ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27723.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3146.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27071.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>26830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "1213           1          0      1            0  31.0    1          0.0   \n",
       "2067           1          0      0            0  41.0    1          0.0   \n",
       "3198           1          0      1            0  33.0    0          0.0   \n",
       "3538           1          0      1            0  33.0    0         90.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported  Cabin_s  \n",
       "1213    27723.0           3.0   202.0  3146.0            1        1  \n",
       "2067    29813.0           0.0  1257.0     6.0            1        1  \n",
       "3198    27071.0           0.0    15.0     0.0            1        1  \n",
       "3538    26830.0           0.0    27.0   703.0            1        0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[data_1.FoodCourt>25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d78ff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14327.0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "4416           1          0      5            2  27.0    0      14327.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall  Spa  VRDeck  Transported  Cabin_s  \n",
       "4416     1487.0           0.0  1.0     0.0            0        1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_1[data_1.RoomService>12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8825fdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>13437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22408.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "5722           1          0      2            0  68.0    0        125.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall      Spa  VRDeck  Transported  Cabin_s  \n",
       "5722    13437.0           0.0  22408.0    17.0            0        0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[data_1.Spa>20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e50feccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6670.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>20336.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "4311           1          0      2            2  31.0    0          0.0   \n",
       "5619           1          0      1            0  57.0    0        200.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall    Spa   VRDeck  Transported  Cabin_s  \n",
       "4311     6670.0         217.0  625.0  20336.0            0        0  \n",
       "5619        9.0           0.0    0.0  24133.0            0        1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[data_1.VRDeck>20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8e095eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3=data_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ac5cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3=data_3[(data_3.ShoppingMall<20000) & (data_3.FoodCourt<25000) & (data_3.RoomService<12000) & (data_3.Spa<20000) & (data_3.VRDeck<20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "154b3456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8684 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              1          0      1            2  39.0    0          0.0   \n",
       "1              0          0      5            2  24.0    0        109.0   \n",
       "2              1          0      0            2  58.0    1         43.0   \n",
       "3              1          0      0            2  33.0    0          0.0   \n",
       "4              0          0      5            2  16.0    0        303.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "8688           1          0      0            0  41.0    1          0.0   \n",
       "8689           0          1      6            1  18.0    0          0.0   \n",
       "8690           0          0      6            2  26.0    0          0.0   \n",
       "8691           1          0      4            0  32.0    0          0.0   \n",
       "8692           1          0      4            2  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported  Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0            0        0  \n",
       "1           9.0          25.0   549.0    44.0            1        1  \n",
       "2        3576.0           0.0  6715.0    49.0            0        1  \n",
       "3        1283.0         371.0  3329.0   193.0            0        1  \n",
       "4          70.0         151.0   565.0     2.0            1        1  \n",
       "...         ...           ...     ...     ...          ...      ...  \n",
       "8688     6819.0           0.0  1643.0    74.0            0        0  \n",
       "8689        0.0           0.0     0.0     0.0            0        1  \n",
       "8690        0.0        1872.0     1.0     0.0            1        1  \n",
       "8691     1049.0           0.0   353.0  3235.0            0        1  \n",
       "8692     4688.0           0.0     0.0    12.0            1        1  \n",
       "\n",
       "[8684 rows x 13 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "24029e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  RoomService  \\\n",
       "0              1          0      1            2  39.0    0          0.0   \n",
       "1              0          0      5            2  24.0    0        109.0   \n",
       "2              1          0      0            2  58.0    1         43.0   \n",
       "3              1          0      0            2  33.0    0          0.0   \n",
       "4              0          0      5            2  16.0    0        303.0   \n",
       "...          ...        ...    ...          ...   ...  ...          ...   \n",
       "8688           1          0      0            0  41.0    1          0.0   \n",
       "8689           0          1      6            1  18.0    0          0.0   \n",
       "8690           0          0      6            2  26.0    0          0.0   \n",
       "8691           1          0      4            0  32.0    0          0.0   \n",
       "8692           1          0      4            2  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Transported  Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0            0        0  \n",
       "1           9.0          25.0   549.0    44.0            1        1  \n",
       "2        3576.0           0.0  6715.0    49.0            0        1  \n",
       "3        1283.0         371.0  3329.0   193.0            0        1  \n",
       "4          70.0         151.0   565.0     2.0            1        1  \n",
       "...         ...           ...     ...     ...          ...      ...  \n",
       "8688     6819.0           0.0  1643.0    74.0            0        0  \n",
       "8689        0.0           0.0     0.0     0.0            0        1  \n",
       "8690        0.0        1872.0     1.0     0.0            1        1  \n",
       "8691     1049.0           0.0   353.0  3235.0            0        1  \n",
       "8692     4688.0           0.0     0.0    12.0            1        1  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "18f47419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8684 entries, 0 to 8692\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    8684 non-null   int32  \n",
      " 1   CryoSleep     8684 non-null   int64  \n",
      " 2   Cabin         8684 non-null   int32  \n",
      " 3   Destination   8684 non-null   int32  \n",
      " 4   Age           8684 non-null   float64\n",
      " 5   VIP           8684 non-null   int32  \n",
      " 6   RoomService   8684 non-null   float64\n",
      " 7   FoodCourt     8684 non-null   float64\n",
      " 8   ShoppingMall  8684 non-null   float64\n",
      " 9   Spa           8684 non-null   float64\n",
      " 10  VRDeck        8684 non-null   float64\n",
      " 11  Transported   8684 non-null   int32  \n",
      " 12  Cabin_s       8684 non-null   int32  \n",
      "dtypes: float64(6), int32(6), int64(1)\n",
      "memory usage: 746.3 KB\n"
     ]
    }
   ],
   "source": [
    "data_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9be845ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2=data_3.drop(['Transported'],axis=1)\n",
    "ss=preprocessing.StandardScaler()\n",
    "x_2=ss.fit_transform(x_2)\n",
    "y_2=data_3.iloc[:,-2]\n",
    "x_2train,x_2test,y_2train,y_2test=train_test_split(x_2,y_2, test_size=0.2,random_state=0)\n",
    "kfold=KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4869a8",
   "metadata": {},
   "source": [
    "### Lgbm model with the new outlier-removed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "20226c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Govind S\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1487: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.1, 'max_depth': 3}, 0.7994854145502042)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "param_grid=[{'max_depth':[2,3,4,5,6,7,8,9,10,11,12],'learning_rate':[0.01,0.03,0.05,0.07,0.09,0.10,0.20]}]\n",
    "model_lgb_2 = lgb.LGBMClassifier(random_state=42,categorical_feature=[0,1,2,3,5,11])\n",
    "gslgb = GridSearchCV(model_lgb_2,param_grid,n_jobs=-1,cv=kfold)\n",
    "gslgb.fit(x_2train,y_2train)\n",
    "gslgb.best_params_ , gslgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eef03ef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7835348301669545\n",
      "0.8303886925795053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       888\n",
      "           1       0.75      0.83      0.79       849\n",
      "\n",
      "    accuracy                           0.78      1737\n",
      "   macro avg       0.79      0.78      0.78      1737\n",
      "weighted avg       0.79      0.78      0.78      1737\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[656 232]\n",
      " [144 705]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Govind S\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\Govind S\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMClassifier(learning_rate=0.1,random_state=42,max_depth=3)\n",
    "model_lgb.fit(x_2train,y_2train,categorical_feature=[0,1,2,3,5,11],verbose=20)\n",
    "print(metrics.accuracy_score(y_2test,model_lgb.predict(x_2test)))\n",
    "print(metrics.recall_score(y_2test,model_lgb.predict(x_2test)))\n",
    "print(metrics.classification_report(y_2test,model_lgb.predict(x_2test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_2test,model_lgb.predict(x_2test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436190cc",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "12d4375b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 11, 'max_features': 4, 'n_estimators': 88}, 0.8056724649099165)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid=[{'n_estimators':range(64,125),'max_depth':[2,3,4,5,6,7,8,9,10,11,12],'max_features':[3,4,5,6]}]\n",
    "rf = RandomForestClassifier(criterion='gini',random_state=23)\n",
    "gsrf = GridSearchCV(rf,param_grid,n_jobs=-1,cv=kfold)\n",
    "gsrf.fit(x_2train,y_2train)\n",
    "gsrf.best_params_ , gsrf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "470ea67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7887161773172136\n",
      "0.7856301531213192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       888\n",
      "           1       0.78      0.79      0.78       849\n",
      "\n",
      "    accuracy                           0.79      1737\n",
      "   macro avg       0.79      0.79      0.79      1737\n",
      "weighted avg       0.79      0.79      0.79      1737\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[703 185]\n",
      " [182 667]]\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=88,max_depth=11,max_features=4,criterion='gini',random_state=23)\n",
    "model_rf.fit(x_2train,y_2train)\n",
    "print(metrics.accuracy_score(y_2test,model_rf.predict(x_2test)))\n",
    "print(metrics.recall_score(y_2test,model_rf.predict(x_2test)))\n",
    "print(metrics.classification_report(y_2test,model_rf.predict(x_2test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_2test,model_rf.predict(x_2test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aefe94a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=11, max_features=4, n_estimators=88,\n",
       "                       random_state=23)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=88,max_depth=11,max_features=4,criterion='gini',random_state=23)\n",
    "rf.fit(x_2,y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9e664781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.82793</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>28.82793</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>43.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Cabin  Destination       Age  VIP  RoomService  \\\n",
       "0              0          1      6            2  27.00000    0          0.0   \n",
       "1              0          0      5            2  19.00000    0          0.0   \n",
       "2              1          1      2            0  31.00000    0          0.0   \n",
       "3              1          0      2            2  38.00000    0          0.0   \n",
       "4              0          0      5            2  20.00000    0         10.0   \n",
       "...          ...        ...    ...          ...       ...  ...          ...   \n",
       "4272           0          1      6            2  34.00000    0          0.0   \n",
       "4273           0          0      5            2  42.00000    0          0.0   \n",
       "4274           2          1      3            0  28.82793    0          0.0   \n",
       "4275           1          0      3            2  28.82793    0          0.0   \n",
       "4276           0          1      6            1  43.00000    0          0.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  Cabin_s  \n",
       "0           0.0           0.0     0.0     0.0        1  \n",
       "1           9.0           0.0  2823.0     0.0        1  \n",
       "2           0.0           0.0     0.0     0.0        1  \n",
       "3        6652.0           0.0   181.0   585.0        1  \n",
       "4           0.0         635.0     0.0     0.0        1  \n",
       "...         ...           ...     ...     ...      ...  \n",
       "4272        0.0           0.0     0.0     0.0        1  \n",
       "4273      847.0          17.0    10.0   144.0        1  \n",
       "4274        0.0           0.0     0.0     0.0        0  \n",
       "4275     2680.0           0.0     0.0   523.0        0  \n",
       "4276        0.0           0.0     0.0     0.0        1  \n",
       "\n",
       "[4277 rows x 12 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "97e64a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=rf.predict(ss.transform(test))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "71865f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=f.astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4b240a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d5f04b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01         True\n",
       "1        0018_01        False\n",
       "2        0019_01         True\n",
       "3        0021_01         True\n",
       "4        0023_01        False\n",
       "...          ...          ...\n",
       "4272     9266_02         True\n",
       "4273     9269_01        False\n",
       "4274     9271_01         True\n",
       "4275     9273_01         True\n",
       "4276     9277_01         True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_f = pd.DataFrame({'PassengerId':ID,'Transported':f})\n",
    "submission_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e57e7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_f.to_csv('submission_f.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4645a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
